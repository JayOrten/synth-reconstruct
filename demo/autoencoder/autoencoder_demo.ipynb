{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREDIT: Adapted from: https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/08-deep-autoencoders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import numpy \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import librosa.display\n",
    "import wave\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "# Tensorboard extension (for visualization purposes later)\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/audio_test\")\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDS(Dataset):\n",
    "    def __init__(self, presets_csv_path):\n",
    "        self.presets = pd.read_csv(presets_csv_path)\n",
    "        # Take only the first 100 for debugging\n",
    "        self.presets = self.presets.head(2999)\n",
    "        # Transformations applied on each image => only make them a tensor\n",
    "        self.transform = transforms.Compose([transforms.Normalize((0.5,), (0.5,))])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.presets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        preset = self.presets.iloc[idx]\n",
    "        preset_name = preset[0]\n",
    "\n",
    "        # First, check if the image has already been generated\n",
    "        if not Path(f'../spectrograms_small/{preset_name}.png').exists():\n",
    "            raise FileNotFoundError(f'../spectrograms_small/{preset_name}.png')\n",
    "\n",
    "        try:\n",
    "            # Load the image\n",
    "            image = torchvision.io.read_image(f'../spectrograms_small/{preset_name}.png')\n",
    "        except:\n",
    "            print('error loading image')\n",
    "            print(preset_name)\n",
    "\n",
    "        image = image.float() / 255\n",
    "        # print(image)\n",
    "        preset = torch.tensor(preset[1:-1])\n",
    "\n",
    "        return image, preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "dataset = AudioDS('..\\\\presets.csv')\n",
    "pl.seed_everything(42)\n",
    "num_train = int(0.9 * len(dataset))\n",
    "num_val = len(dataset) - num_train\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [num_train, num_val])\n",
    "batch_size = 256\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_train_images(num):\n",
    "    return torch.stack([train_dataset[i][0] for i in range(num)], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_11292\\986052091.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset_name = preset[0]\n",
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_11292\\986052091.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset = torch.tensor(preset[1:-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_train_images(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_input_channels: int, base_channel_size: int, latent_dim: int, act_fn: object = nn.GELU):\n",
    "        \"\"\"Encoder.\n",
    "\n",
    "        Args:\n",
    "           num_input_channels : Number of input channels of the image. For CIFAR, this parameter is 3\n",
    "           base_channel_size : Number of channels we use in the first convolutional layers. Deeper layers might use a duplicate of it.\n",
    "           latent_dim : Dimensionality of latent representation z\n",
    "           act_fn : Activation function used throughout the encoder network\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(num_input_channels, c_hid, kernel_size=3, padding=1, stride=2),  # 32x32 => 16x16\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, 2 * c_hid, kernel_size=3, padding=1, stride=2),  # 16x16 => 8x8\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1, stride=2),  # 8x8 => 4x4\n",
    "            act_fn(),\n",
    "            nn.Flatten(),  # Image grid to single feature vector\n",
    "            nn.Linear(2 * (16 * 16) * c_hid, latent_dim), # 50, 50\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_input_channels: int, base_channel_size: int, latent_dim: int, act_fn: object = nn.GELU):\n",
    "        \"\"\"Decoder.\n",
    "\n",
    "        Args:\n",
    "           num_input_channels : Number of channels of the image to reconstruct. For CIFAR, this parameter is 3\n",
    "           base_channel_size : Number of channels we use in the last convolutional layers. Early layers might use a duplicate of it.\n",
    "           latent_dim : Dimensionality of latent representation z\n",
    "           act_fn : Activation function used throughout the decoder network\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.linear = nn.Sequential(nn.Linear(latent_dim, 2 * (16 * 16) * c_hid), act_fn()) # 50, 50\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                2 * c_hid, 2 * c_hid, kernel_size=3, output_padding=1, padding=1, stride=2\n",
    "            ),  # 4x4 => 8x8\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.ConvTranspose2d(2 * c_hid, c_hid, kernel_size=3, output_padding=1, padding=1, stride=2),  # 8x8 => 16x16\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.ConvTranspose2d(\n",
    "                c_hid, num_input_channels, kernel_size=3, output_padding=1, padding=1, stride=2\n",
    "            ),  # 16x16 => 32x32\n",
    "            nn.Tanh(),  # The input images is scaled between -1 and 1, hence the output has to be bounded as well\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(x.shape[0], -1, 16, 16)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_channel_size: int,\n",
    "        latent_dim: int,\n",
    "        encoder_class: object = Encoder,\n",
    "        decoder_class: object = Decoder,\n",
    "        num_input_channels: int = 4,\n",
    "        width: int = 128,\n",
    "        height: int = 128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters of autoencoder\n",
    "        self.save_hyperparameters()\n",
    "        # Creating encoder and decoder\n",
    "        self.encoder = encoder_class(num_input_channels, base_channel_size, latent_dim)\n",
    "        self.decoder = decoder_class(num_input_channels, base_channel_size, latent_dim)\n",
    "        # Example input array needed for visualizing the graph of the network\n",
    "        self.example_input_array = torch.zeros(1, num_input_channels, width, height)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function takes in an image and returns the reconstructed image.\"\"\"\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def _get_reconstruction_loss(self, batch):\n",
    "        \"\"\"Given a batch of images, this function returns the reconstruction loss (MSE in our case).\"\"\"\n",
    "        x, _ = batch  # We do not need the labels\n",
    "        x_hat = self.forward(x)\n",
    "        # print('x.shape: ', x.shape)\n",
    "        # print('x_hat.shape: ', x_hat.shape)\n",
    "        loss = F.mse_loss(x, x_hat, reduction=\"none\")\n",
    "        loss = loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        # Using a scheduler is optional but can be helpful.\n",
    "        # The scheduler reduces the LR if the validation performance hasn't improved for the last N epochs\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=20, min_lr=5e-5)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        print('train_loss: ', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"test_loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateCallback(Callback):\n",
    "    def __init__(self, input_imgs, every_n_epochs=1):\n",
    "        super().__init__()\n",
    "        self.input_imgs = input_imgs  # Images to reconstruct during training\n",
    "        # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
    "        self.every_n_epochs = every_n_epochs\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if trainer.current_epoch % self.every_n_epochs == 0:\n",
    "            # Reconstruct images\n",
    "            input_imgs = self.input_imgs.to(pl_module.device)\n",
    "            with torch.no_grad():\n",
    "                pl_module.eval()\n",
    "                reconst_imgs = pl_module(input_imgs)\n",
    "                pl_module.train()\n",
    "\n",
    "            # print('input_imgs: ', input_imgs)\n",
    "            # print('reconst_imgs: ', reconst_imgs)\n",
    "            # Plot and add to tensorboard\n",
    "            imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0, 1)\n",
    "            grid = torchvision.utils.make_grid(imgs, nrow=2, normalize=True, value_range=(0, 1))\n",
    "            # trainer.logger.experiment.image(\"reconstruction\", grid, global_step=trainer.global_step)\n",
    "            # save image to disk\n",
    "            save_path = os.path.join(trainer.logger.log_dir, f\"reconstruction_{trainer.current_epoch}.png\")\n",
    "            torchvision.utils.save_image(grid, save_path, nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(latent_dim, max_epochs=50):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    print('creating trainer')\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, \"final_model_dim_%i\" % latent_dim),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True),\n",
    "            GenerateCallback(get_train_images(8), every_n_epochs=1),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    # pretrained_filename = os.path.join(CHECKPOINT_PATH, \"cifar10_%i.ckpt\" % latent_dim)\n",
    "    # if os.path.isfile(pretrained_filename):\n",
    "    #     print(\"Found pretrained model, loading...\")\n",
    "    #     model = Autoencoder.load_from_checkpoint(pretrained_filename)\n",
    "    # else:\n",
    "    print(\"creating model\")\n",
    "    model = Autoencoder(base_channel_size=32, latent_dim=latent_dim)\n",
    "    print(\"training model\")\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    # Test best model on validation and test set\n",
    "    print(\"testing model\")\n",
    "    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "    # test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    # result = {\"test\": test_result, \"val\": val_result}\n",
    "    result = {\"val\": val_result}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_17660\\986052091.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset_name = preset[0]\n",
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_17660\\986052091.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset = torch.tensor(preset[1:-1])\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes         | Out sizes       \n",
      "----------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 1.2 M  | train | [1, 4, 128, 128] | [1, 64]         \n",
      "1 | decoder | Decoder | 1.2 M  | train | [1, 64]          | [1, 4, 128, 128]\n",
      "----------------------------------------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.276     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating trainer\n",
      "creating model\n",
      "training model\n",
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s]                             train_loss:  tensor(34583.7656, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=47]train_loss:  tensor(34675.1094, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:02<00:09,  0.94it/s, v_num=47]train_loss:  tensor(33766.3086, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=47]train_loss:  tensor(33598.5625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=47]train_loss:  tensor(32166.3613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=47]train_loss:  tensor(29326.6328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=47]train_loss:  tensor(23466.4668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=47]train_loss:  tensor(19075.7188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:07<00:02,  1.13it/s, v_num=47]train_loss:  tensor(17987.9688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=47]train_loss:  tensor(14539.1758, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=47]train_loss:  tensor(11988.6416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(10652.1484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=47]train_loss:  tensor(9448.1846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=47]train_loss:  tensor(7830.0625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=47]train_loss:  tensor(6400.7100, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=47]train_loss:  tensor(5698.7637, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=47]train_loss:  tensor(5347.9980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=47]train_loss:  tensor(4786.2461, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=47]train_loss:  tensor(4459.7046, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=47]train_loss:  tensor(3980.9294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=47]train_loss:  tensor(3877.5681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=47]train_loss:  tensor(3770.9250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(3413.3867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=47]train_loss:  tensor(3339.7017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=47]train_loss:  tensor(3232.3433, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=47]train_loss:  tensor(3150.9272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=47]train_loss:  tensor(2943.1357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=47]train_loss:  tensor(2722.8154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=47]train_loss:  tensor(2699.0630, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=47]train_loss:  tensor(2630.2161, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=47]train_loss:  tensor(2590.2864, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=47]train_loss:  tensor(2451.2256, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=47]train_loss:  tensor(2425.0298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(2326.6785, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   9%|▉         | 1/11 [00:00<00:08,  1.15it/s, v_num=47]train_loss:  tensor(2246.8899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=47]train_loss:  tensor(2276.9951, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:02<00:06,  1.14it/s, v_num=47]train_loss:  tensor(2212.4004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=47]train_loss:  tensor(2230.2490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=47]train_loss:  tensor(2082.6479, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=47]train_loss:  tensor(2121.9646, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:06<00:03,  1.17it/s, v_num=47]train_loss:  tensor(2164.4380, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=47]train_loss:  tensor(1905.0342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=47]train_loss:  tensor(1970.1707, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=47]train_loss:  tensor(1863.6407, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(1881.4586, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=47]train_loss:  tensor(1973.1082, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=47]train_loss:  tensor(1861.4766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=47]train_loss:  tensor(1811.9086, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=47]train_loss:  tensor(1802.5193, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=47]train_loss:  tensor(1825.3546, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=47]train_loss:  tensor(1693.3115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=47]train_loss:  tensor(1828.9668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=47]train_loss:  tensor(1822.4410, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  82%|████████▏ | 9/11 [00:07<00:01,  1.13it/s, v_num=47]train_loss:  tensor(1648.1031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=47]train_loss:  tensor(1702.7184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(1646.9666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=47]train_loss:  tensor(1633.7920, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=47]train_loss:  tensor(1664.3186, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=47]train_loss:  tensor(1726.4176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:03<00:06,  1.08it/s, v_num=47]train_loss:  tensor(1579.6035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=47]train_loss:  tensor(1566.4304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=47]train_loss:  tensor(1681.3040, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=47]train_loss:  tensor(1606.6429, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=47]train_loss:  tensor(1536.8201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=47]train_loss:  tensor(1554.0791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=47]train_loss:  tensor(1591.9841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(1587.4662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   9%|▉         | 1/11 [00:00<00:08,  1.17it/s, v_num=47]train_loss:  tensor(1545.6631, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=47]train_loss:  tensor(1465.5862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=47]train_loss:  tensor(1562.1292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=47]train_loss:  tensor(1517.5625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:04<00:05,  1.05it/s, v_num=47]train_loss:  tensor(1494.8817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:05<00:04,  1.08it/s, v_num=47]train_loss:  tensor(1479.0879, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:06<00:03,  1.10it/s, v_num=47]train_loss:  tensor(1481.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=47]train_loss:  tensor(1464.8890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, v_num=47]train_loss:  tensor(1411.3711, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=47]train_loss:  tensor(1447.3784, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(1466.2543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=47]train_loss:  tensor(1439.0835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=47]train_loss:  tensor(1397.5673, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=47]train_loss:  tensor(1424.9691, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=47]train_loss:  tensor(1409.4189, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=47]train_loss:  tensor(1412.0576, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=47]train_loss:  tensor(1380.4069, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=47]train_loss:  tensor(1344.2559, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=47]train_loss:  tensor(1404.1140, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=47]train_loss:  tensor(1345.7112, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=47]train_loss:  tensor(1363.9532, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(1406.2363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   9%|▉         | 1/11 [00:00<00:09,  1.11it/s, v_num=47]train_loss:  tensor(1396.0614, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=47]train_loss:  tensor(1308.6412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=47]train_loss:  tensor(1273.9668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=47]train_loss:  tensor(1241.2612, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=47]train_loss:  tensor(1270.0742, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=47]train_loss:  tensor(1255.0186, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=47]train_loss:  tensor(1242.0586, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=47]train_loss:  tensor(1182.7432, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=47]train_loss:  tensor(1210.0413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=47]train_loss:  tensor(1136.2676, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(1140.1018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=47]train_loss:  tensor(1117.1936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=47]train_loss:  tensor(1091.1243, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=47]train_loss:  tensor(1112.8866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:03<00:06,  1.17it/s, v_num=47]train_loss:  tensor(1072.2454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=47]train_loss:  tensor(1028.7288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=47]train_loss:  tensor(1051.1248, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=47]train_loss:  tensor(1052.3722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=47]train_loss:  tensor(1042.1011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  82%|████████▏ | 9/11 [00:07<00:01,  1.13it/s, v_num=47]train_loss:  tensor(1005.9810, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=47]train_loss:  tensor(1050.7330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]        train_loss:  tensor(1032.3916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=47]train_loss:  tensor(1019.8888, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=47]train_loss:  tensor(959.0848, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=47]train_loss:  tensor(991.5985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=47]train_loss:  tensor(955.7909, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=47]train_loss:  tensor(1013.4257, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=47]train_loss:  tensor(961.5817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=47]train_loss:  tensor(951.8621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=47]train_loss:  tensor(952.3328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=47]train_loss:  tensor(985.0975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=47]train_loss:  tensor(1003.5726, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(972.1647, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:09,  1.11it/s, v_num=47]train_loss:  tensor(944.0273, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=47]train_loss:  tensor(901.9647, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=47]train_loss:  tensor(953.2567, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=47]train_loss:  tensor(921.0765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=47]train_loss:  tensor(914.7778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=47]train_loss:  tensor(951.3988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=47]train_loss:  tensor(928.5865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=47]train_loss:  tensor(886.8544, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=47]train_loss:  tensor(912.2703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=47]train_loss:  tensor(904.2732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(871.0447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   9%|▉         | 1/11 [00:00<00:08,  1.15it/s, v_num=47]train_loss:  tensor(865.9240, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=47]train_loss:  tensor(905.7384, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=47]train_loss:  tensor(901.1579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=47]train_loss:  tensor(896.2191, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=47]train_loss:  tensor(863.7828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=47]train_loss:  tensor(860.9713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=47]train_loss:  tensor(853.8387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=47]train_loss:  tensor(883.5624, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=47]train_loss:  tensor(827.2032, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=47]train_loss:  tensor(825.0115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(837.9114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   9%|▉         | 1/11 [00:00<00:08,  1.14it/s, v_num=47]train_loss:  tensor(817.2021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=47]train_loss:  tensor(795.4513, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=47]train_loss:  tensor(859.7458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=47]train_loss:  tensor(791.3883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=47]train_loss:  tensor(783.2427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=47]train_loss:  tensor(781.9916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=47]train_loss:  tensor(768.8079, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=47]train_loss:  tensor(781.5258, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=47]train_loss:  tensor(781.2079, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=47]train_loss:  tensor(816.0280, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(791.9641, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   9%|▉         | 1/11 [00:00<00:08,  1.14it/s, v_num=47]train_loss:  tensor(763.4860, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=47]train_loss:  tensor(755.8113, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=47]train_loss:  tensor(707.2151, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=47]train_loss:  tensor(769.7751, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=47]train_loss:  tensor(753.0070, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=47]train_loss:  tensor(728.3967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=47]train_loss:  tensor(773.1467, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=47]train_loss:  tensor(773.8207, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=47]train_loss:  tensor(748.9307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=47]train_loss:  tensor(706.2079, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(750.0150, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=47]train_loss:  tensor(728.2758, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=47]train_loss:  tensor(733.0317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:02<00:06,  1.14it/s, v_num=47]train_loss:  tensor(733.5481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=47]train_loss:  tensor(688.4427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=47]train_loss:  tensor(695.6672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=47]train_loss:  tensor(702.9031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=47]train_loss:  tensor(704.6521, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=47]train_loss:  tensor(702.7387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=47]train_loss:  tensor(715.9952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=47]train_loss:  tensor(701.4261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(671.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=47]train_loss:  tensor(711.4501, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=47]train_loss:  tensor(746.5627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:02<00:07,  1.09it/s, v_num=47]train_loss:  tensor(785.9450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:03<00:06,  1.08it/s, v_num=47]train_loss:  tensor(759.8900, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:05<00:06,  0.98it/s, v_num=47]train_loss:  tensor(681.9323, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:06<00:05,  1.00it/s, v_num=47]train_loss:  tensor(658.1194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=47]train_loss:  tensor(689.6085, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:07<00:02,  1.03it/s, v_num=47]train_loss:  tensor(668.4352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  82%|████████▏ | 9/11 [00:08<00:01,  1.05it/s, v_num=47]train_loss:  tensor(641.7635, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.05it/s, v_num=47]train_loss:  tensor(664.9416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(634.2493, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   9%|▉         | 1/11 [00:01<00:14,  0.68it/s, v_num=47]train_loss:  tensor(678.5045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:02<00:10,  0.86it/s, v_num=47]train_loss:  tensor(665.4755, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:03<00:08,  0.93it/s, v_num=47]train_loss:  tensor(638.6555, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:04<00:07,  0.96it/s, v_num=47]train_loss:  tensor(633.2292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.00it/s, v_num=47]train_loss:  tensor(681.0864, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=47]train_loss:  tensor(704.4698, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.05it/s, v_num=47]train_loss:  tensor(670.3936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:07<00:02,  1.06it/s, v_num=47]train_loss:  tensor(638.2232, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  82%|████████▏ | 9/11 [00:08<00:01,  1.08it/s, v_num=47]train_loss:  tensor(667.4139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=47]train_loss:  tensor(633.4347, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(622.9420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:09,  1.09it/s, v_num=47]train_loss:  tensor(600.8439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=47]train_loss:  tensor(678.3765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:03<00:08,  1.00it/s, v_num=47]train_loss:  tensor(703.3520, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=47]train_loss:  tensor(646.5490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.05it/s, v_num=47]train_loss:  tensor(630.9473, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.07it/s, v_num=47]train_loss:  tensor(611.5139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:06<00:03,  1.09it/s, v_num=47]train_loss:  tensor(629.5374, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:07<00:02,  1.09it/s, v_num=47]train_loss:  tensor(632.0942, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  82%|████████▏ | 9/11 [00:08<00:01,  1.09it/s, v_num=47]train_loss:  tensor(624.1491, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  91%|█████████ | 10/11 [00:09<00:00,  1.10it/s, v_num=47]train_loss:  tensor(654.7521, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(650.5309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=47]train_loss:  tensor(623.9762, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=47]train_loss:  tensor(620.7401, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=47]train_loss:  tensor(601.8109, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=47]train_loss:  tensor(622.3447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=47]train_loss:  tensor(656.6027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=47]train_loss:  tensor(607.8765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=47]train_loss:  tensor(605.8339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.14it/s, v_num=47]train_loss:  tensor(602.1731, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=47]train_loss:  tensor(628.7759, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=47]train_loss:  tensor(638.9174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(629.2819, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=47]train_loss:  tensor(609.3187, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=47]train_loss:  tensor(603.7986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=47]train_loss:  tensor(638.9191, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=47]train_loss:  tensor(632.2053, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=47]train_loss:  tensor(598.3329, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=47]train_loss:  tensor(574.7867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=47]train_loss:  tensor(574.4780, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=47]train_loss:  tensor(633.0161, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, v_num=47]train_loss:  tensor(624.0237, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=47]train_loss:  tensor(608.2381, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(584.4966, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=47]train_loss:  tensor(598.7750, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  18%|█▊        | 2/11 [00:02<00:10,  0.82it/s, v_num=47]train_loss:  tensor(577.7480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  27%|██▋       | 3/11 [00:03<00:09,  0.83it/s, v_num=47]train_loss:  tensor(595.0797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  36%|███▋      | 4/11 [00:04<00:08,  0.85it/s, v_num=47]train_loss:  tensor(572.7274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  45%|████▌     | 5/11 [00:05<00:07,  0.84it/s, v_num=47]train_loss:  tensor(589.6538, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  55%|█████▍    | 6/11 [00:06<00:05,  0.88it/s, v_num=47]train_loss:  tensor(603.0817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  64%|██████▎   | 7/11 [00:07<00:04,  0.92it/s, v_num=47]train_loss:  tensor(573.0179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  73%|███████▎  | 8/11 [00:08<00:03,  0.95it/s, v_num=47]train_loss:  tensor(601.8322, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  82%|████████▏ | 9/11 [00:09<00:02,  0.98it/s, v_num=47]train_loss:  tensor(588.0835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  91%|█████████ | 10/11 [00:09<00:00,  1.01it/s, v_num=47]train_loss:  tensor(577.0070, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(590.9075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=47]train_loss:  tensor(594.8654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=47]train_loss:  tensor(601.9392, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=47]train_loss:  tensor(568.5343, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  36%|███▋      | 4/11 [00:04<00:07,  0.91it/s, v_num=47]train_loss:  tensor(584.4446, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  45%|████▌     | 5/11 [00:05<00:06,  0.92it/s, v_num=47]train_loss:  tensor(567.5543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  55%|█████▍    | 6/11 [00:07<00:05,  0.85it/s, v_num=47]train_loss:  tensor(609.9747, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  64%|██████▎   | 7/11 [00:08<00:04,  0.86it/s, v_num=47]train_loss:  tensor(569.8796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  73%|███████▎  | 8/11 [00:09<00:03,  0.88it/s, v_num=47]train_loss:  tensor(583.3730, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  82%|████████▏ | 9/11 [00:10<00:02,  0.89it/s, v_num=47]train_loss:  tensor(598.9775, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  91%|█████████ | 10/11 [00:10<00:01,  0.92it/s, v_num=47]train_loss:  tensor(551.4906, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(568.7339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=47]train_loss:  tensor(625.0806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=47]train_loss:  tensor(627.7097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.09it/s, v_num=47]train_loss:  tensor(619.6017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=47]train_loss:  tensor(647.2484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=47]train_loss:  tensor(571.8477, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=47]train_loss:  tensor(577.6813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.04it/s, v_num=47]train_loss:  tensor(598.8484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  73%|███████▎  | 8/11 [00:07<00:02,  1.06it/s, v_num=47]train_loss:  tensor(589.2860, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  82%|████████▏ | 9/11 [00:08<00:01,  1.08it/s, v_num=47]train_loss:  tensor(619.1227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=47]train_loss:  tensor(570.6974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(564.2404, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=47]train_loss:  tensor(568.7321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=47]train_loss:  tensor(563.1230, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=47]train_loss:  tensor(551.0354, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=47]train_loss:  tensor(541.7172, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=47]train_loss:  tensor(566.9249, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=47]train_loss:  tensor(543.1757, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=47]train_loss:  tensor(523.5365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=47]train_loss:  tensor(575.4968, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=47]train_loss:  tensor(575.7369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=47]train_loss:  tensor(590.4420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(551.7931, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=47]train_loss:  tensor(532.6646, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, v_num=47]train_loss:  tensor(561.3357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=47]train_loss:  tensor(564.0299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  36%|███▋      | 4/11 [00:03<00:06,  1.06it/s, v_num=47]train_loss:  tensor(552.7461, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=47]train_loss:  tensor(606.8765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  55%|█████▍    | 6/11 [00:05<00:04,  1.07it/s, v_num=47]train_loss:  tensor(566.7630, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  64%|██████▎   | 7/11 [00:06<00:03,  1.07it/s, v_num=47]train_loss:  tensor(552.9598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  73%|███████▎  | 8/11 [00:07<00:02,  1.06it/s, v_num=47]train_loss:  tensor(535.2788, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  82%|████████▏ | 9/11 [00:08<00:01,  1.05it/s, v_num=47]train_loss:  tensor(587.0269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  91%|█████████ | 10/11 [00:09<00:00,  1.06it/s, v_num=47]train_loss:  tensor(557.7807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(550.1237, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=47]train_loss:  tensor(554.3892, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=47]train_loss:  tensor(507.4892, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=47]train_loss:  tensor(507.2621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=47]train_loss:  tensor(549.9233, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=47]train_loss:  tensor(555.9299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=47]train_loss:  tensor(549.7180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  64%|██████▎   | 7/11 [00:06<00:03,  1.10it/s, v_num=47]train_loss:  tensor(554.0671, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=47]train_loss:  tensor(548.8045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=47]train_loss:  tensor(528.7917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=47]train_loss:  tensor(564.6763, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(582.3636, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=47]train_loss:  tensor(537.2594, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=47]train_loss:  tensor(534.1014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=47]train_loss:  tensor(512.9196, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=47]train_loss:  tensor(507.7076, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=47]train_loss:  tensor(517.1310, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=47]train_loss:  tensor(529.3867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=47]train_loss:  tensor(529.6157, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=47]train_loss:  tensor(518.0765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=47]train_loss:  tensor(519.9749, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=47]train_loss:  tensor(500.0979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(507.9376, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=47]train_loss:  tensor(500.5289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=47]train_loss:  tensor(515.4722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=47]train_loss:  tensor(537.1458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=47]train_loss:  tensor(519.4076, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=47]train_loss:  tensor(519.3629, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=47]train_loss:  tensor(518.3890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=47]train_loss:  tensor(532.4445, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=47]train_loss:  tensor(549.3494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=47]train_loss:  tensor(577.0030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=47]train_loss:  tensor(559.4562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(498.6284, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=47]train_loss:  tensor(520.9897, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=47]train_loss:  tensor(528.0910, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=47]train_loss:  tensor(526.0694, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=47]train_loss:  tensor(501.8730, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=47]train_loss:  tensor(513.7787, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=47]train_loss:  tensor(534.0214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=47]train_loss:  tensor(510.3629, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=47]train_loss:  tensor(533.1602, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=47]train_loss:  tensor(495.8471, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=47]train_loss:  tensor(555.7244, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(565.1832, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=47]train_loss:  tensor(609.5846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=47]train_loss:  tensor(594.0571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=47]train_loss:  tensor(559.2124, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=47]train_loss:  tensor(528.2995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=47]train_loss:  tensor(501.1194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=47]train_loss:  tensor(538.1146, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=47]train_loss:  tensor(540.3543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=47]train_loss:  tensor(530.5920, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=47]train_loss:  tensor(493.7827, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=47]train_loss:  tensor(502.1138, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(491.1925, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=47]train_loss:  tensor(531.9359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=47]train_loss:  tensor(487.7954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=47]train_loss:  tensor(497.1700, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=47]train_loss:  tensor(475.7154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=47]train_loss:  tensor(523.9296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=47]train_loss:  tensor(505.2850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=47]train_loss:  tensor(492.8610, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=47]train_loss:  tensor(497.5752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=47]train_loss:  tensor(524.4801, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=47]train_loss:  tensor(505.4818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(509.6769, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=47]train_loss:  tensor(498.9634, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=47]train_loss:  tensor(520.4503, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=47]train_loss:  tensor(503.8091, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=47]train_loss:  tensor(478.7231, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=47]train_loss:  tensor(465.6266, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=47]train_loss:  tensor(485.7097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=47]train_loss:  tensor(503.1201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=47]train_loss:  tensor(509.4545, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=47]train_loss:  tensor(513.9071, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=47]train_loss:  tensor(507.5644, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(461.2737, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=47]train_loss:  tensor(492.7778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=47]train_loss:  tensor(506.1969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=47]train_loss:  tensor(485.8487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=47]train_loss:  tensor(477.6284, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=47]train_loss:  tensor(499.6004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=47]train_loss:  tensor(492.9485, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=47]train_loss:  tensor(510.4531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=47]train_loss:  tensor(505.5157, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=47]train_loss:  tensor(500.3939, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=47]train_loss:  tensor(504.4621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(501.6843, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=47]train_loss:  tensor(507.9267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=47]train_loss:  tensor(492.6954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=47]train_loss:  tensor(489.0859, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=47]train_loss:  tensor(503.4439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=47]train_loss:  tensor(526.6057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=47]train_loss:  tensor(523.3307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=47]train_loss:  tensor(526.2166, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  73%|███████▎  | 8/11 [00:07<00:02,  1.08it/s, v_num=47]train_loss:  tensor(537.1956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  82%|████████▏ | 9/11 [00:08<00:01,  1.08it/s, v_num=47]train_loss:  tensor(564.6520, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  91%|█████████ | 10/11 [00:09<00:00,  1.09it/s, v_num=47]train_loss:  tensor(518.6810, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(496.5849, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   9%|▉         | 1/11 [00:01<00:13,  0.76it/s, v_num=47]train_loss:  tensor(475.9022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  18%|█▊        | 2/11 [00:02<00:11,  0.76it/s, v_num=47]train_loss:  tensor(489.6491, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  27%|██▋       | 3/11 [00:03<00:09,  0.83it/s, v_num=47]train_loss:  tensor(533.6810, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  36%|███▋      | 4/11 [00:04<00:07,  0.89it/s, v_num=47]train_loss:  tensor(536.5654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  45%|████▌     | 5/11 [00:05<00:06,  0.95it/s, v_num=47]train_loss:  tensor(505.7820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  55%|█████▍    | 6/11 [00:06<00:05,  0.99it/s, v_num=47]train_loss:  tensor(458.7953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=47]train_loss:  tensor(496.7625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  73%|███████▎  | 8/11 [00:07<00:02,  1.04it/s, v_num=47]train_loss:  tensor(529.0917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  82%|████████▏ | 9/11 [00:08<00:01,  1.06it/s, v_num=47]train_loss:  tensor(528.7019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  91%|█████████ | 10/11 [00:09<00:00,  1.07it/s, v_num=47]train_loss:  tensor(492.2842, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(491.1739, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=47]train_loss:  tensor(462.1035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=47]train_loss:  tensor(537.2292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=47]train_loss:  tensor(496.9833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=47]train_loss:  tensor(491.6638, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=47]train_loss:  tensor(476.1790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=47]train_loss:  tensor(492.2788, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=47]train_loss:  tensor(471.3540, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=47]train_loss:  tensor(497.7799, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=47]train_loss:  tensor(476.8201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=47]train_loss:  tensor(470.3089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(476.1866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   9%|▉         | 1/11 [00:00<00:08,  1.14it/s, v_num=47]train_loss:  tensor(491.3079, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=47]train_loss:  tensor(507.1537, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=47]train_loss:  tensor(484.2459, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=47]train_loss:  tensor(465.7965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  45%|████▌     | 5/11 [00:03<00:04,  1.25it/s, v_num=47]train_loss:  tensor(504.3960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=47]train_loss:  tensor(450.8548, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=47]train_loss:  tensor(456.4216, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=47]train_loss:  tensor(489.5793, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=47]train_loss:  tensor(478.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=47]train_loss:  tensor(487.4772, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(471.0430, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=47]train_loss:  tensor(467.1653, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=47]train_loss:  tensor(462.4597, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=47]train_loss:  tensor(478.3130, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=47]train_loss:  tensor(483.0480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=47]train_loss:  tensor(482.0783, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=47]train_loss:  tensor(453.7459, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=47]train_loss:  tensor(492.7714, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=47]train_loss:  tensor(497.9166, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=47]train_loss:  tensor(479.1326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=47]train_loss:  tensor(476.1187, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(491.8441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=47]train_loss:  tensor(468.0123, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=47]train_loss:  tensor(477.8000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=47]train_loss:  tensor(476.1746, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=47]train_loss:  tensor(470.0661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  45%|████▌     | 5/11 [00:03<00:04,  1.25it/s, v_num=47]train_loss:  tensor(468.2137, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=47]train_loss:  tensor(482.2975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=47]train_loss:  tensor(477.1925, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=47]train_loss:  tensor(479.0814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=47]train_loss:  tensor(473.3843, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=47]train_loss:  tensor(463.4254, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(495.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   9%|▉         | 1/11 [00:01<00:13,  0.76it/s, v_num=47]train_loss:  tensor(498.4886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  18%|█▊        | 2/11 [00:02<00:09,  0.90it/s, v_num=47]train_loss:  tensor(495.7818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  27%|██▋       | 3/11 [00:03<00:08,  0.95it/s, v_num=47]train_loss:  tensor(493.3420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  36%|███▋      | 4/11 [00:04<00:07,  0.93it/s, v_num=47]train_loss:  tensor(494.1168, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  45%|████▌     | 5/11 [00:05<00:06,  0.95it/s, v_num=47]train_loss:  tensor(473.7854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  55%|█████▍    | 6/11 [00:06<00:05,  0.99it/s, v_num=47]train_loss:  tensor(476.2559, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=47]train_loss:  tensor(463.8858, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  73%|███████▎  | 8/11 [00:07<00:02,  1.05it/s, v_num=47]train_loss:  tensor(469.8129, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  82%|████████▏ | 9/11 [00:08<00:01,  1.07it/s, v_num=47]train_loss:  tensor(463.3171, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  91%|█████████ | 10/11 [00:09<00:00,  1.09it/s, v_num=47]train_loss:  tensor(467.2610, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(508.5750, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   9%|▉         | 1/11 [00:01<00:10,  0.95it/s, v_num=47]train_loss:  tensor(486.0073, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=47]train_loss:  tensor(480.4010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=47]train_loss:  tensor(492.5923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  36%|███▋      | 4/11 [00:03<00:06,  1.00it/s, v_num=47]train_loss:  tensor(473.7194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  45%|████▌     | 5/11 [00:04<00:05,  1.05it/s, v_num=47]train_loss:  tensor(465.7675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  55%|█████▍    | 6/11 [00:05<00:04,  1.07it/s, v_num=47]train_loss:  tensor(480.4263, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  64%|██████▎   | 7/11 [00:06<00:03,  1.08it/s, v_num=47]train_loss:  tensor(467.0341, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=47]train_loss:  tensor(493.0898, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=47]train_loss:  tensor(480.8524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=47]train_loss:  tensor(487.5852, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(476.5787, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=47]train_loss:  tensor(487.9464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=47]train_loss:  tensor(485.2458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=47]train_loss:  tensor(470.5767, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=47]train_loss:  tensor(459.9154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=47]train_loss:  tensor(471.8811, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=47]train_loss:  tensor(464.6610, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=47]train_loss:  tensor(472.5033, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=47]train_loss:  tensor(452.0057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=47]train_loss:  tensor(471.0906, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=47]train_loss:  tensor(419.8174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(466.8108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   9%|▉         | 1/11 [00:00<00:08,  1.14it/s, v_num=47]train_loss:  tensor(452.5854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  18%|█▊        | 2/11 [00:02<00:09,  0.99it/s, v_num=47]train_loss:  tensor(472.4410, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=47]train_loss:  tensor(456.2155, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  36%|███▋      | 4/11 [00:03<00:06,  1.01it/s, v_num=47]train_loss:  tensor(463.3325, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  45%|████▌     | 5/11 [00:04<00:05,  1.04it/s, v_num=47]train_loss:  tensor(434.5936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  55%|█████▍    | 6/11 [00:06<00:05,  0.90it/s, v_num=47]train_loss:  tensor(474.6495, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  64%|██████▎   | 7/11 [00:07<00:04,  0.91it/s, v_num=47]train_loss:  tensor(464.6912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  73%|███████▎  | 8/11 [00:08<00:03,  0.90it/s, v_num=47]train_loss:  tensor(470.2550, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  82%|████████▏ | 9/11 [00:09<00:02,  0.91it/s, v_num=47]train_loss:  tensor(482.5942, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  91%|█████████ | 10/11 [00:11<00:01,  0.88it/s, v_num=47]train_loss:  tensor(466.5039, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(453.7778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=47]train_loss:  tensor(462.6249, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=47]train_loss:  tensor(457.9198, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  27%|██▋       | 3/11 [00:02<00:07,  1.09it/s, v_num=47]train_loss:  tensor(470.2045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=47]train_loss:  tensor(464.8820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=47]train_loss:  tensor(524.2639, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=47]train_loss:  tensor(489.1514, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=47]train_loss:  tensor(533.3188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=47]train_loss:  tensor(556.3144, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=47]train_loss:  tensor(520.2377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=47]train_loss:  tensor(475.6433, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(450.3158, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   9%|▉         | 1/11 [00:00<00:08,  1.17it/s, v_num=47]train_loss:  tensor(486.0926, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=47]train_loss:  tensor(545.6219, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=47]train_loss:  tensor(525.5922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=47]train_loss:  tensor(502.4052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=47]train_loss:  tensor(455.9711, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=47]train_loss:  tensor(486.4613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=47]train_loss:  tensor(513.7670, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=47]train_loss:  tensor(467.1571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=47]train_loss:  tensor(453.8110, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=47]train_loss:  tensor(456.7679, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(498.4718, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=47]train_loss:  tensor(522.3853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=47]train_loss:  tensor(454.5088, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  27%|██▋       | 3/11 [00:03<00:08,  0.92it/s, v_num=47]train_loss:  tensor(438.4487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  36%|███▋      | 4/11 [00:04<00:07,  0.98it/s, v_num=47]train_loss:  tensor(459.4836, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=47]train_loss:  tensor(487.0012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  55%|█████▍    | 6/11 [00:05<00:04,  1.06it/s, v_num=47]train_loss:  tensor(455.3082, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  64%|██████▎   | 7/11 [00:06<00:03,  1.09it/s, v_num=47]train_loss:  tensor(442.0215, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=47]train_loss:  tensor(463.2570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=47]train_loss:  tensor(467.8883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=47]train_loss:  tensor(464.4425, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(481.6996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=47]train_loss:  tensor(446.5724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=47]train_loss:  tensor(470.7316, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=47]train_loss:  tensor(468.1300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=47]train_loss:  tensor(458.2900, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=47]train_loss:  tensor(438.3140, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=47]train_loss:  tensor(459.2258, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=47]train_loss:  tensor(433.1411, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=47]train_loss:  tensor(428.8270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=47]train_loss:  tensor(466.2633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=47]train_loss:  tensor(454.1849, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(461.5223, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=47]train_loss:  tensor(451.5231, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=47]train_loss:  tensor(439.3633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=47]train_loss:  tensor(457.9441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=47]train_loss:  tensor(448.3163, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=47]train_loss:  tensor(444.3568, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=47]train_loss:  tensor(449.2305, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=47]train_loss:  tensor(453.7835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=47]train_loss:  tensor(447.7964, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=47]train_loss:  tensor(464.2769, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=47]train_loss:  tensor(433.7771, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s, v_num=47]         train_loss:  tensor(418.7315, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=47]train_loss:  tensor(439.0497, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=47]train_loss:  tensor(448.2741, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=47]train_loss:  tensor(432.5635, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=47]train_loss:  tensor(456.5988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=47]train_loss:  tensor(466.6227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=47]train_loss:  tensor(452.3470, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=47]train_loss:  tensor(428.3579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=47]train_loss:  tensor(478.0751, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=47]train_loss:  tensor(448.4075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=47]train_loss:  tensor(446.3447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49: 100%|██████████| 11/11 [00:09<00:00,  1.17it/s, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 11/11 [00:09<00:00,  1.17it/s, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing model\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 14.02it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes         | Out sizes       \n",
      "----------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 2.2 M  | train | [1, 4, 128, 128] | [1, 128]        \n",
      "1 | decoder | Decoder | 2.2 M  | train | [1, 128]         | [1, 4, 128, 128]\n",
      "----------------------------------------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.665    Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "training model\n",
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s]                             train_loss:  tensor(36051.4609, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=1]train_loss:  tensor(35818.8164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=1]train_loss:  tensor(35124.3516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=1]train_loss:  tensor(34334.6719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=1]train_loss:  tensor(33067.2188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=1]train_loss:  tensor(31721.4297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=1]train_loss:  tensor(24544.2539, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=1]train_loss:  tensor(28967.8828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=1]train_loss:  tensor(24228.1934, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=1]train_loss:  tensor(19676.1211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=1]train_loss:  tensor(20222.2383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(19276.0391, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   9%|▉         | 1/11 [00:01<00:13,  0.74it/s, v_num=1]train_loss:  tensor(17380.1035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:02<00:09,  0.92it/s, v_num=1]train_loss:  tensor(15193.8955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:03<00:08,  0.99it/s, v_num=1]train_loss:  tensor(14111.0381, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=1]train_loss:  tensor(13380.4512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=1]train_loss:  tensor(11001.6377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=1]train_loss:  tensor(9166.1660, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=1]train_loss:  tensor(8054.3955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=1]train_loss:  tensor(7176.7305, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=1]train_loss:  tensor(6117.9268, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=1]train_loss:  tensor(5012.3555, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(4554.3506, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=1]train_loss:  tensor(4222.6064, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=1]train_loss:  tensor(3927.1943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=1]train_loss:  tensor(3539.9136, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=1]train_loss:  tensor(3476.0601, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=1]train_loss:  tensor(3613.4453, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=1]train_loss:  tensor(3442.5803, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=1]train_loss:  tensor(3207.8645, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=1]train_loss:  tensor(3072.7085, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(2813.5881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=1]train_loss:  tensor(2757.5046, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(2638.1743, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=1]train_loss:  tensor(2456.0801, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=1]train_loss:  tensor(2318.2625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=1]train_loss:  tensor(2473.8789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=1]train_loss:  tensor(2311.1943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=1]train_loss:  tensor(2401.8228, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=1]train_loss:  tensor(2371.1267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=1]train_loss:  tensor(2391.7427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=1]train_loss:  tensor(2528.6499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=1]train_loss:  tensor(2358.1245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=1]train_loss:  tensor(2210.4587, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(2169.7529, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=1]train_loss:  tensor(2161.1094, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=1]train_loss:  tensor(2156.6479, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=1]train_loss:  tensor(2127.8975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=1]train_loss:  tensor(2081.8818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(2062.5139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(2017.6240, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=1]train_loss:  tensor(1967.8494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=1]train_loss:  tensor(1902.1641, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=1]train_loss:  tensor(1905.0170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=1]train_loss:  tensor(1748.9912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(1825.6821, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=1]train_loss:  tensor(1752.2501, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=1]train_loss:  tensor(1843.9702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=1]train_loss:  tensor(1799.7896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=1]train_loss:  tensor(1794.6606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=1]train_loss:  tensor(1876.5178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=1]train_loss:  tensor(1701.7664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=1]train_loss:  tensor(1594.5562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=1]train_loss:  tensor(1630.2932, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(1708.9104, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=1]train_loss:  tensor(1694.0171, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(1667.8774, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=1]train_loss:  tensor(1684.4347, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=1]train_loss:  tensor(1621.3264, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=1]train_loss:  tensor(1593.2043, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=1]train_loss:  tensor(1615.0835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=1]train_loss:  tensor(1558.6572, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(1636.6995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=1]train_loss:  tensor(1547.0060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=1]train_loss:  tensor(1502.7598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, v_num=1]train_loss:  tensor(1597.2031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=1]train_loss:  tensor(1593.7765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(1560.1768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   9%|▉         | 1/11 [00:00<00:09,  1.08it/s, v_num=1]train_loss:  tensor(1524.5820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=1]train_loss:  tensor(1505.8037, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=1]train_loss:  tensor(1504.8281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=1]train_loss:  tensor(1487.9586, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=1]train_loss:  tensor(1461.5342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=1]train_loss:  tensor(1447.1923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=1]train_loss:  tensor(1417.2184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=1]train_loss:  tensor(1450.5156, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=1]train_loss:  tensor(1441.5615, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=1]train_loss:  tensor(1387.9928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(1378.0415, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=1]train_loss:  tensor(1384.0328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=1]train_loss:  tensor(1403.5154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=1]train_loss:  tensor(1368.5178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=1]train_loss:  tensor(1331.9912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=1]train_loss:  tensor(1305.3188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=1]train_loss:  tensor(1203.8196, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=1]train_loss:  tensor(1228.7661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=1]train_loss:  tensor(1192.2623, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(1141.7180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=1]train_loss:  tensor(1132.3220, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(1154.1167, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=1]train_loss:  tensor(1091.3391, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=1]train_loss:  tensor(1117.1083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:02<00:07,  1.02it/s, v_num=1]train_loss:  tensor(1111.5236, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=1]train_loss:  tensor(1155.0317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=1]train_loss:  tensor(1066.3599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=1]train_loss:  tensor(1081.3402, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=1]train_loss:  tensor(1057.4753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=1]train_loss:  tensor(1061.1608, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=1]train_loss:  tensor(1061.6396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=1]train_loss:  tensor(1068.2678, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]        train_loss:  tensor(1089.0808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=1]train_loss:  tensor(1010.2927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=1]train_loss:  tensor(980.0013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=1]train_loss:  tensor(1027.5967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=1]train_loss:  tensor(993.2355, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(950.1421, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=1]train_loss:  tensor(976.3381, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=1]train_loss:  tensor(989.9492, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=1]train_loss:  tensor(959.4238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(939.0035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=1]train_loss:  tensor(1027.2332, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(976.3068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=1]train_loss:  tensor(944.5363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=1]train_loss:  tensor(944.0908, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=1]train_loss:  tensor(918.4524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=1]train_loss:  tensor(947.1217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=1]train_loss:  tensor(953.7953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(888.1696, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=1]train_loss:  tensor(884.6217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=1]train_loss:  tensor(909.4083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=1]train_loss:  tensor(882.6313, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=1]train_loss:  tensor(788.4152, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(855.2078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=1]train_loss:  tensor(866.2722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=1]train_loss:  tensor(845.9460, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=1]train_loss:  tensor(866.1637, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=1]train_loss:  tensor(856.8900, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=1]train_loss:  tensor(803.8181, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=1]train_loss:  tensor(784.2253, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=1]train_loss:  tensor(803.1180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=1]train_loss:  tensor(802.4178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=1]train_loss:  tensor(849.4146, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=1]train_loss:  tensor(817.1791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(779.0884, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=1]train_loss:  tensor(770.8531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=1]train_loss:  tensor(763.6950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=1]train_loss:  tensor(786.4965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=1]train_loss:  tensor(826.6694, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=1]train_loss:  tensor(797.4371, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(768.1562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=1]train_loss:  tensor(737.7828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=1]train_loss:  tensor(761.9896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=1]train_loss:  tensor(742.6979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=1]train_loss:  tensor(739.4672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(759.7478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=1]train_loss:  tensor(716.5253, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=1]train_loss:  tensor(725.4281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=1]train_loss:  tensor(698.3812, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=1]train_loss:  tensor(687.4780, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=1]train_loss:  tensor(729.8413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=1]train_loss:  tensor(729.6933, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=1]train_loss:  tensor(707.5876, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=1]train_loss:  tensor(756.3350, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=1]train_loss:  tensor(756.0078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=1]train_loss:  tensor(780.8776, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(740.9370, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=1]train_loss:  tensor(727.8610, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=1]train_loss:  tensor(683.5635, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:02<00:06,  1.14it/s, v_num=1]train_loss:  tensor(689.8132, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=1]train_loss:  tensor(714.7115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=1]train_loss:  tensor(709.5032, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(705.6539, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=1]train_loss:  tensor(693.1953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=1]train_loss:  tensor(663.0057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=1]train_loss:  tensor(679.0856, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=1]train_loss:  tensor(675.9988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(686.6192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=1]train_loss:  tensor(714.0422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=1]train_loss:  tensor(646.9794, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=1]train_loss:  tensor(661.8165, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=1]train_loss:  tensor(669.3118, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=1]train_loss:  tensor(667.8270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=1]train_loss:  tensor(666.8807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=1]train_loss:  tensor(668.9666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=1]train_loss:  tensor(687.2204, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(683.2593, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=1]train_loss:  tensor(607.5854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(630.7477, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   9%|▉         | 1/11 [00:00<00:09,  1.08it/s, v_num=1]train_loss:  tensor(652.0778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=1]train_loss:  tensor(665.2406, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=1]train_loss:  tensor(672.9093, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=1]train_loss:  tensor(640.4019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(606.5068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(646.2620, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=1]train_loss:  tensor(654.5057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=1]train_loss:  tensor(647.2194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=1]train_loss:  tensor(629.1652, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=1]train_loss:  tensor(579.1603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(637.6066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:08,  1.19it/s, v_num=1]train_loss:  tensor(658.4871, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=1]train_loss:  tensor(619.5651, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=1]train_loss:  tensor(656.8583, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=1]train_loss:  tensor(657.0297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=1]train_loss:  tensor(685.5860, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=1]train_loss:  tensor(655.7396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=1]train_loss:  tensor(702.8281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=1]train_loss:  tensor(703.5791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=1]train_loss:  tensor(697.5414, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=1]train_loss:  tensor(640.1451, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(589.6536, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=1]train_loss:  tensor(617.5923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=1]train_loss:  tensor(677.2365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=1]train_loss:  tensor(617.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=1]train_loss:  tensor(600.8910, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(627.1782, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=1]train_loss:  tensor(622.7162, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=1]train_loss:  tensor(633.3501, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=1]train_loss:  tensor(614.9174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=1]train_loss:  tensor(601.7401, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=1]train_loss:  tensor(587.2203, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(618.2668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=1]train_loss:  tensor(625.8546, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=1]train_loss:  tensor(621.6368, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=1]train_loss:  tensor(646.6227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=1]train_loss:  tensor(571.4068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=1]train_loss:  tensor(578.3872, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=1]train_loss:  tensor(583.1782, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=1]train_loss:  tensor(623.4821, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=1]train_loss:  tensor(591.7245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=1]train_loss:  tensor(603.7643, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=1]train_loss:  tensor(592.4075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(581.5893, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   9%|▉         | 1/11 [00:00<00:08,  1.17it/s, v_num=1]train_loss:  tensor(572.6458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=1]train_loss:  tensor(562.5949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=1]train_loss:  tensor(570.9193, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=1]train_loss:  tensor(565.6512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(586.6950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=1]train_loss:  tensor(599.8205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=1]train_loss:  tensor(603.6260, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=1]train_loss:  tensor(608.8253, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=1]train_loss:  tensor(608.1777, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=1]train_loss:  tensor(596.3211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(611.2026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=1]train_loss:  tensor(636.1376, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=1]train_loss:  tensor(626.5341, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=1]train_loss:  tensor(574.7085, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=1]train_loss:  tensor(573.6722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=1]train_loss:  tensor(576.1562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=1]train_loss:  tensor(568.9491, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=1]train_loss:  tensor(610.8377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=1]train_loss:  tensor(585.6582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=1]train_loss:  tensor(553.5953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=1]train_loss:  tensor(550.8786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(545.2163, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=1]train_loss:  tensor(580.5234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  18%|█▊        | 2/11 [00:02<00:09,  0.96it/s, v_num=1]train_loss:  tensor(602.6448, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.03it/s, v_num=1]train_loss:  tensor(582.0358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.08it/s, v_num=1]train_loss:  tensor(584.1217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=1]train_loss:  tensor(547.0172, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=1]train_loss:  tensor(532.0049, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=1]train_loss:  tensor(553.9240, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  73%|███████▎  | 8/11 [00:06<00:02,  1.14it/s, v_num=1]train_loss:  tensor(554.2202, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=1]train_loss:  tensor(555.3297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=1]train_loss:  tensor(546.5921, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(566.8198, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   9%|▉         | 1/11 [00:01<00:10,  0.95it/s, v_num=1]train_loss:  tensor(536.6599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  18%|█▊        | 2/11 [00:02<00:09,  1.00it/s, v_num=1]train_loss:  tensor(537.1647, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=1]train_loss:  tensor(568.5602, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=1]train_loss:  tensor(524.9672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=1]train_loss:  tensor(576.4338, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=1]train_loss:  tensor(548.6783, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=1]train_loss:  tensor(547.7962, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=1]train_loss:  tensor(539.7598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=1]train_loss:  tensor(526.4370, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=1]train_loss:  tensor(554.8674, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(536.9350, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=1]train_loss:  tensor(538.0344, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=1]train_loss:  tensor(543.1095, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=1]train_loss:  tensor(517.9179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=1]train_loss:  tensor(495.9306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=1]train_loss:  tensor(487.7916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  55%|█████▍    | 6/11 [00:05<00:04,  1.08it/s, v_num=1]train_loss:  tensor(492.7089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  64%|██████▎   | 7/11 [00:06<00:03,  1.07it/s, v_num=1]train_loss:  tensor(552.3571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  73%|███████▎  | 8/11 [00:07<00:02,  1.09it/s, v_num=1]train_loss:  tensor(552.5369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  82%|████████▏ | 9/11 [00:08<00:01,  1.09it/s, v_num=1]train_loss:  tensor(529.2206, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  91%|█████████ | 10/11 [00:09<00:00,  1.10it/s, v_num=1]train_loss:  tensor(535.3156, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(558.2285, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   9%|▉         | 1/11 [00:01<00:12,  0.80it/s, v_num=1]train_loss:  tensor(660.8857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  18%|█▊        | 2/11 [00:02<00:10,  0.83it/s, v_num=1]train_loss:  tensor(757.8060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  27%|██▋       | 3/11 [00:03<00:08,  0.93it/s, v_num=1]train_loss:  tensor(968.3127, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  36%|███▋      | 4/11 [00:04<00:07,  0.97it/s, v_num=1]train_loss:  tensor(799.0066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  45%|████▌     | 5/11 [00:05<00:06,  0.99it/s, v_num=1]train_loss:  tensor(559.1569, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=1]train_loss:  tensor(713.4768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  64%|██████▎   | 7/11 [00:06<00:03,  1.06it/s, v_num=1]train_loss:  tensor(732.8440, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  73%|███████▎  | 8/11 [00:07<00:02,  1.08it/s, v_num=1]train_loss:  tensor(544.4846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=1]train_loss:  tensor(599.7218, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  91%|█████████ | 10/11 [00:08<00:00,  1.12it/s, v_num=1]train_loss:  tensor(632.4894, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(533.6801, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   9%|▉         | 1/11 [00:00<00:09,  1.11it/s, v_num=1]train_loss:  tensor(603.5001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=1]train_loss:  tensor(549.1503, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=1]train_loss:  tensor(552.1356, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=1]train_loss:  tensor(573.4092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=1]train_loss:  tensor(547.0136, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=1]train_loss:  tensor(583.5039, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=1]train_loss:  tensor(540.6686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=1]train_loss:  tensor(518.6066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=1]train_loss:  tensor(535.9915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=1]train_loss:  tensor(513.1049, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(519.9825, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=1]train_loss:  tensor(512.3834, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=1]train_loss:  tensor(559.1407, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=1]train_loss:  tensor(530.8333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=1]train_loss:  tensor(513.6289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  45%|████▌     | 5/11 [00:04<00:05,  1.13it/s, v_num=1]train_loss:  tensor(489.9180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=1]train_loss:  tensor(512.2584, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=1]train_loss:  tensor(515.1498, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=1]train_loss:  tensor(526.4203, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=1]train_loss:  tensor(502.7547, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=1]train_loss:  tensor(496.2895, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(518.0378, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=1]train_loss:  tensor(490.8575, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=1]train_loss:  tensor(503.5377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=1]train_loss:  tensor(527.3576, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=1]train_loss:  tensor(515.2114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=1]train_loss:  tensor(496.4478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=1]train_loss:  tensor(501.0806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=1]train_loss:  tensor(486.9756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=1]train_loss:  tensor(500.9352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=1]train_loss:  tensor(497.7127, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=1]train_loss:  tensor(460.8333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(495.0429, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=1]train_loss:  tensor(518.4861, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=1]train_loss:  tensor(492.6217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=1]train_loss:  tensor(479.1426, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=1]train_loss:  tensor(495.2495, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=1]train_loss:  tensor(472.5438, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=1]train_loss:  tensor(470.2084, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=1]train_loss:  tensor(526.6275, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=1]train_loss:  tensor(490.3215, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=1]train_loss:  tensor(484.1318, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=1]train_loss:  tensor(492.0100, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(475.2946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=1]train_loss:  tensor(468.8622, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=1]train_loss:  tensor(476.4558, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=1]train_loss:  tensor(503.1686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=1]train_loss:  tensor(496.5071, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=1]train_loss:  tensor(498.5029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=1]train_loss:  tensor(501.0010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=1]train_loss:  tensor(473.5958, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=1]train_loss:  tensor(461.4478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=1]train_loss:  tensor(486.9527, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=1]train_loss:  tensor(498.2635, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(494.3158, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   9%|▉         | 1/11 [00:01<00:10,  0.96it/s, v_num=1]train_loss:  tensor(491.6127, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=1]train_loss:  tensor(458.6194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=1]train_loss:  tensor(460.9954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=1]train_loss:  tensor(475.5787, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=1]train_loss:  tensor(494.2525, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=1]train_loss:  tensor(473.7598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=1]train_loss:  tensor(496.2259, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=1]train_loss:  tensor(469.6642, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=1]train_loss:  tensor(455.6128, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=1]train_loss:  tensor(486.8640, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(459.8559, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=1]train_loss:  tensor(465.7651, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  18%|█▊        | 2/11 [00:01<00:08,  1.02it/s, v_num=1]train_loss:  tensor(466.5704, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=1]train_loss:  tensor(466.6969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  36%|███▋      | 4/11 [00:04<00:07,  0.97it/s, v_num=1]train_loss:  tensor(485.2581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  45%|████▌     | 5/11 [00:05<00:06,  0.95it/s, v_num=1]train_loss:  tensor(501.0889, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  55%|█████▍    | 6/11 [00:06<00:05,  0.96it/s, v_num=1]train_loss:  tensor(519.0996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  64%|██████▎   | 7/11 [00:07<00:04,  0.98it/s, v_num=1]train_loss:  tensor(564.9214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  73%|███████▎  | 8/11 [00:07<00:02,  1.01it/s, v_num=1]train_loss:  tensor(655.7510, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  82%|████████▏ | 9/11 [00:08<00:01,  1.02it/s, v_num=1]train_loss:  tensor(756.8040, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  91%|█████████ | 10/11 [00:09<00:00,  1.03it/s, v_num=1]train_loss:  tensor(712.6172, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(549.1338, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=1]train_loss:  tensor(491.0044, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=1]train_loss:  tensor(587.6276, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=1]train_loss:  tensor(635.9235, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=1]train_loss:  tensor(478.1490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=1]train_loss:  tensor(516.0991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=1]train_loss:  tensor(563.8464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=1]train_loss:  tensor(488.9194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=1]train_loss:  tensor(512.0870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=1]train_loss:  tensor(525.8678, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=1]train_loss:  tensor(474.6444, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(485.4637, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   9%|▉         | 1/11 [00:01<00:12,  0.78it/s, v_num=1]train_loss:  tensor(519.4340, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  18%|█▊        | 2/11 [00:02<00:09,  0.91it/s, v_num=1]train_loss:  tensor(467.2360, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  27%|██▋       | 3/11 [00:03<00:08,  1.00it/s, v_num=1]train_loss:  tensor(481.7960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=1]train_loss:  tensor(493.0125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=1]train_loss:  tensor(485.6774, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=1]train_loss:  tensor(475.1578, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=1]train_loss:  tensor(477.6728, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=1]train_loss:  tensor(481.2345, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=1]train_loss:  tensor(491.0231, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=1]train_loss:  tensor(493.1135, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(466.4890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=1]train_loss:  tensor(505.0908, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=1]train_loss:  tensor(473.9514, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=1]train_loss:  tensor(440.7523, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=1]train_loss:  tensor(463.9144, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(477.5430, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(461.3574, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=1]train_loss:  tensor(466.7838, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=1]train_loss:  tensor(477.0373, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=1]train_loss:  tensor(463.4293, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=1]train_loss:  tensor(459.5674, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(463.9323, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=1]train_loss:  tensor(461.3799, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=1]train_loss:  tensor(461.2269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=1]train_loss:  tensor(469.8675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=1]train_loss:  tensor(471.2452, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=1]train_loss:  tensor(428.3097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=1]train_loss:  tensor(464.7950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=1]train_loss:  tensor(454.0148, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=1]train_loss:  tensor(466.1329, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=1]train_loss:  tensor(448.3925, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=1]train_loss:  tensor(472.3317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(439.0115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=1]train_loss:  tensor(483.3063, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=1]train_loss:  tensor(461.8868, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=1]train_loss:  tensor(454.1066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=1]train_loss:  tensor(434.6946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=1]train_loss:  tensor(469.6603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(470.0647, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=1]train_loss:  tensor(474.3201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=1]train_loss:  tensor(430.8321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=1]train_loss:  tensor(428.4670, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=1]train_loss:  tensor(444.1206, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(447.4475, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=1]train_loss:  tensor(445.8558, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=1]train_loss:  tensor(478.5595, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=1]train_loss:  tensor(446.9969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  36%|███▋      | 4/11 [00:03<00:05,  1.32it/s, v_num=1]train_loss:  tensor(462.2291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=1]train_loss:  tensor(441.1031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=1]train_loss:  tensor(468.0871, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=1]train_loss:  tensor(433.4662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  73%|███████▎  | 8/11 [00:06<00:02,  1.32it/s, v_num=1]train_loss:  tensor(434.4176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=1]train_loss:  tensor(428.8631, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s, v_num=1]train_loss:  tensor(443.9744, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(453.5259, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=1]train_loss:  tensor(455.3898, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=1]train_loss:  tensor(444.2502, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=1]train_loss:  tensor(446.1872, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=1]train_loss:  tensor(436.5469, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=1]train_loss:  tensor(443.1435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=1]train_loss:  tensor(441.5254, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=1]train_loss:  tensor(436.4585, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=1]train_loss:  tensor(454.3875, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=1]train_loss:  tensor(458.5873, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s, v_num=1]train_loss:  tensor(392.4409, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(447.1369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=1]train_loss:  tensor(441.0954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=1]train_loss:  tensor(433.2031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=1]train_loss:  tensor(456.9022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=1]train_loss:  tensor(440.3175, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=1]train_loss:  tensor(462.3563, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=1]train_loss:  tensor(430.2447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=1]train_loss:  tensor(427.6036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=1]train_loss:  tensor(469.4747, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=1]train_loss:  tensor(436.0021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=1]train_loss:  tensor(446.1434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(451.7544, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=1]train_loss:  tensor(464.0915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=1]train_loss:  tensor(431.2572, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=1]train_loss:  tensor(450.7456, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=1]train_loss:  tensor(439.8985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=1]train_loss:  tensor(434.5047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=1]train_loss:  tensor(447.7137, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=1]train_loss:  tensor(430.6295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=1]train_loss:  tensor(441.0729, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=1]train_loss:  tensor(447.3349, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=1]train_loss:  tensor(465.1902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(442.8393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=1]train_loss:  tensor(440.9366, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=1]train_loss:  tensor(449.6546, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=1]train_loss:  tensor(438.5113, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=1]train_loss:  tensor(437.3799, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=1]train_loss:  tensor(492.8927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=1]train_loss:  tensor(486.7534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=1]train_loss:  tensor(494.9890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  73%|███████▎  | 8/11 [00:06<00:02,  1.32it/s, v_num=1]train_loss:  tensor(496.1752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=1]train_loss:  tensor(462.9366, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s, v_num=1]train_loss:  tensor(464.5590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(420.7578, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=1]train_loss:  tensor(448.8928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18: 100%|██████████| 11/11 [30:17<00:00,  0.01it/s, v_num=43]\n",
      "Epoch 57:   0%|          | 0/11 [19:49<?, ?it/s, v_num=44]\n",
      "train_loss:  tensor(472.1243, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=1]train_loss:  tensor(461.5905, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=1]train_loss:  tensor(465.4314, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=1]train_loss:  tensor(442.7946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=1]train_loss:  tensor(425.6390, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=1]train_loss:  tensor(431.5292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=1]train_loss:  tensor(436.0702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=1]train_loss:  tensor(440.5512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=1]train_loss:  tensor(423.9456, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(407.8843, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=1]train_loss:  tensor(453.0616, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=1]train_loss:  tensor(450.1699, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=1]train_loss:  tensor(439.6480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=1]train_loss:  tensor(428.1289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=1]train_loss:  tensor(429.1906, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=1]train_loss:  tensor(444.6469, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=1]train_loss:  tensor(444.3997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=1]train_loss:  tensor(429.1752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(422.5295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=1]train_loss:  tensor(439.7998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(441.7675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=1]train_loss:  tensor(441.2912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=1]train_loss:  tensor(417.0119, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=1]train_loss:  tensor(417.1140, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=1]train_loss:  tensor(413.9380, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=1]train_loss:  tensor(427.2858, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=1]train_loss:  tensor(456.0075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=1]train_loss:  tensor(423.0592, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=1]train_loss:  tensor(445.9471, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=1]train_loss:  tensor(425.9495, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=1]train_loss:  tensor(397.7395, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(421.8878, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   9%|▉         | 1/11 [00:00<00:09,  1.00it/s, v_num=1]train_loss:  tensor(403.5481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=1]train_loss:  tensor(428.5475, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=1]train_loss:  tensor(443.5967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=1]train_loss:  tensor(420.2365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=1]train_loss:  tensor(417.5936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=1]train_loss:  tensor(429.4210, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=1]train_loss:  tensor(432.5519, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=1]train_loss:  tensor(437.3826, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=1]train_loss:  tensor(432.3949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=1]train_loss:  tensor(437.9120, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(417.9704, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=1]train_loss:  tensor(441.8823, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=1]train_loss:  tensor(433.6633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=1]train_loss:  tensor(409.0919, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=1]train_loss:  tensor(445.8188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=1]train_loss:  tensor(415.2732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=1]train_loss:  tensor(414.6841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=1]train_loss:  tensor(421.9673, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=1]train_loss:  tensor(435.9074, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=1]train_loss:  tensor(423.7394, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=1]train_loss:  tensor(394.7197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s, v_num=1]         train_loss:  tensor(426.3150, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=1]train_loss:  tensor(433.2582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=1]train_loss:  tensor(431.7634, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=1]train_loss:  tensor(411.6424, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=1]train_loss:  tensor(474.6609, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=1]train_loss:  tensor(482.1709, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=1]train_loss:  tensor(510.0395, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=1]train_loss:  tensor(571.8535, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=1]train_loss:  tensor(615.8571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=1]train_loss:  tensor(549.1752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=1]train_loss:  tensor(420.4961, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49: 100%|██████████| 11/11 [00:09<00:00,  1.20it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 11/11 [00:09<00:00,  1.20it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing model\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 14.05it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes         | Out sizes       \n",
      "----------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 4.3 M  | train | [1, 4, 128, 128] | [1, 256]        \n",
      "1 | decoder | Decoder | 4.3 M  | train | [1, 256]         | [1, 4, 128, 128]\n",
      "----------------------------------------------------------------------------------\n",
      "8.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 M     Total params\n",
      "34.443    Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "training model\n",
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s]                             train_loss:  tensor(36817.2148, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=0]train_loss:  tensor(36812.0938, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=0]train_loss:  tensor(35957.9648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(35277.0234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=0]train_loss:  tensor(33675.5664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(30544.9922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(23073.9141, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(12655.3369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(10970.2588, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(9928.9209, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(8506.8369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(6432.1147, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(4820.6758, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(5735.1274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(5318.4268, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=0]train_loss:  tensor(4025.1155, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(3636.1929, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(4188.8765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(3987.9805, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(3011.2588, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(3118.6089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(3083.8940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(3018.4272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=0]train_loss:  tensor(2682.0894, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(2695.6528, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(2607.2051, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(2788.8069, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(2505.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(2432.5276, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(2465.7603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(2460.8640, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(2308.8833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(2408.3926, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(2218.4177, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(2072.6301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=0]train_loss:  tensor(2109.2922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=0]train_loss:  tensor(1950.1111, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(1947.4935, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=0]train_loss:  tensor(1938.5726, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=0]train_loss:  tensor(1858.4148, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=0]train_loss:  tensor(1870.2241, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:06<00:02,  1.32it/s, v_num=0]train_loss:  tensor(1796.9994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=0]train_loss:  tensor(1775.3882, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s, v_num=0]train_loss:  tensor(1700.6432, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1765.2175, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(1755.9191, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(1710.8813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(1615.2612, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(1616.8734, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(1697.0557, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(1584.8345, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(1612.6606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(1597.3098, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(1652.5554, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(1603.9598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1563.2874, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(1470.8685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(1689.6581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=0]train_loss:  tensor(1482.3401, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(1512.4548, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=0]train_loss:  tensor(1459.2192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=0]train_loss:  tensor(1467.5693, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=0]train_loss:  tensor(1361.3674, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(1380.4357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(1450.9753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(1460.9359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1348.0181, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(1397.3157, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(1269.2509, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(1318.9141, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(1282.6854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(1245.0093, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(1246.4756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(1222.0452, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(1192.7684, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(1124.0127, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(1180.4684, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1185.5028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(1117.7063, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(1059.4576, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(1093.6694, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(1080.9373, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=0]train_loss:  tensor(1112.3265, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=0]train_loss:  tensor(1063.9542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=0]train_loss:  tensor(1092.2915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(1061.2651, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(1045.5907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(1046.9191, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1037.1138, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=0]train_loss:  tensor(1028.5737, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(1028.2380, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(1008.6025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(1075.0793, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(1002.5162, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(1009.5422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(1032.8479, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(998.5318, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(1002.7402, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(952.4321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(975.2352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(992.8669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(921.4683, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(968.1465, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(934.0740, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(992.5880, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(952.3562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(949.2839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(912.6724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(933.9188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(935.6724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]        train_loss:  tensor(920.4368, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=0]train_loss:  tensor(903.7756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(878.7030, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=0]train_loss:  tensor(871.9525, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(909.3547, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(923.7330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(852.9279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(828.8340, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(847.2245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(868.9980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(826.4971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(852.4427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(829.8850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(845.8542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(814.2560, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(826.9034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(761.5895, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(809.6608, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(756.9817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(753.4902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(799.4417, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(787.9352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(782.0755, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(796.2203, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:01<00:08,  1.10it/s, v_num=0]train_loss:  tensor(783.8530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(737.3217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(759.5883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(714.8140, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(755.6870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(710.2314, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(766.2319, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(732.1636, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(732.1222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(752.9777, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(732.3937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(710.8420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(700.0227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(720.7006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=0]train_loss:  tensor(667.6460, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(682.7269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(680.7902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(703.5387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(675.6379, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(708.6238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(677.5231, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(687.0870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(665.6886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(677.7947, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(679.9694, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(646.9174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(667.7266, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(674.0907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(657.7571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(702.2501, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(661.6302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(676.7407, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(637.5792, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(633.6000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=0]train_loss:  tensor(641.8138, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=0]train_loss:  tensor(663.6531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(653.2440, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(655.2784, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(671.0298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(615.4139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(680.0697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(653.0927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(651.4376, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   9%|▉         | 1/11 [00:01<00:11,  0.87it/s, v_num=0]train_loss:  tensor(646.9455, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(622.4963, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:03<00:08,  0.92it/s, v_num=0]train_loss:  tensor(617.7972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:04<00:07,  0.90it/s, v_num=0]train_loss:  tensor(654.7324, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:05<00:06,  0.96it/s, v_num=0]train_loss:  tensor(626.7770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:05<00:04,  1.00it/s, v_num=0]train_loss:  tensor(632.3688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=0]train_loss:  tensor(618.5378, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:07<00:02,  1.04it/s, v_num=0]train_loss:  tensor(629.8398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  82%|████████▏ | 9/11 [00:08<00:01,  1.06it/s, v_num=0]train_loss:  tensor(622.2393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=0]train_loss:  tensor(573.2342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(616.9874, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   9%|▉         | 1/11 [00:01<00:10,  0.96it/s, v_num=0]train_loss:  tensor(626.3951, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:01<00:08,  1.02it/s, v_num=0]train_loss:  tensor(625.4989, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(654.4790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(658.9097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.01it/s, v_num=0]train_loss:  tensor(690.2026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:06<00:05,  0.99it/s, v_num=0]train_loss:  tensor(746.5358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.03it/s, v_num=0]train_loss:  tensor(623.0081, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:07<00:02,  1.05it/s, v_num=0]train_loss:  tensor(615.1089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  82%|████████▏ | 9/11 [00:08<00:01,  1.08it/s, v_num=0]train_loss:  tensor(653.4905, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  91%|█████████ | 10/11 [00:09<00:00,  1.09it/s, v_num=0]train_loss:  tensor(635.6945, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(595.5104, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(641.6962, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=0]train_loss:  tensor(607.9742, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(582.8429, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(589.6940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(619.9247, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(599.1270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(594.0809, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(590.8130, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(601.9289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(619.6645, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(610.4640, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(571.8126, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=0]train_loss:  tensor(574.8988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(598.1320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(575.3531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(552.4435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(574.8108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=0]train_loss:  tensor(582.2781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(568.0588, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(589.4955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(552.7385, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(585.2162, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   9%|▉         | 1/11 [00:03<00:31,  0.32it/s, v_num=0]train_loss:  tensor(576.3696, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  18%|█▊        | 2/11 [00:04<00:20,  0.43it/s, v_num=0]train_loss:  tensor(580.5534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  27%|██▋       | 3/11 [00:05<00:14,  0.54it/s, v_num=0]train_loss:  tensor(583.5809, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  36%|███▋      | 4/11 [00:06<00:11,  0.63it/s, v_num=0]train_loss:  tensor(576.6782, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  45%|████▌     | 5/11 [00:07<00:08,  0.69it/s, v_num=0]train_loss:  tensor(560.7369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  55%|█████▍    | 6/11 [00:08<00:06,  0.74it/s, v_num=0]train_loss:  tensor(556.0568, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  64%|██████▎   | 7/11 [00:08<00:05,  0.78it/s, v_num=0]train_loss:  tensor(527.2527, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  73%|███████▎  | 8/11 [00:10<00:03,  0.79it/s, v_num=0]train_loss:  tensor(533.5850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  82%|████████▏ | 9/11 [00:11<00:02,  0.81it/s, v_num=0]train_loss:  tensor(563.9015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  91%|█████████ | 10/11 [00:12<00:01,  0.83it/s, v_num=0]train_loss:  tensor(552.0449, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(568.3776, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   9%|▉         | 1/11 [00:01<00:16,  0.60it/s, v_num=0]train_loss:  tensor(584.4567, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  18%|█▊        | 2/11 [00:03<00:14,  0.64it/s, v_num=0]train_loss:  tensor(544.9633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  27%|██▋       | 3/11 [00:04<00:10,  0.73it/s, v_num=0]train_loss:  tensor(561.8585, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  36%|███▋      | 4/11 [00:04<00:08,  0.80it/s, v_num=0]train_loss:  tensor(532.4768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  45%|████▌     | 5/11 [00:05<00:06,  0.86it/s, v_num=0]train_loss:  tensor(560.8576, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  55%|█████▍    | 6/11 [00:06<00:05,  0.89it/s, v_num=0]train_loss:  tensor(545.7072, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  64%|██████▎   | 7/11 [00:07<00:04,  0.91it/s, v_num=0]train_loss:  tensor(533.0296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  73%|███████▎  | 8/11 [00:08<00:03,  0.93it/s, v_num=0]train_loss:  tensor(548.4966, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  82%|████████▏ | 9/11 [00:09<00:02,  0.95it/s, v_num=0]train_loss:  tensor(538.2454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  91%|█████████ | 10/11 [00:10<00:01,  0.97it/s, v_num=0]train_loss:  tensor(499.6468, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(530.8245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   9%|▉         | 1/11 [00:01<00:11,  0.88it/s, v_num=0]train_loss:  tensor(535.8838, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  18%|█▊        | 2/11 [00:02<00:09,  0.97it/s, v_num=0]train_loss:  tensor(546.5400, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=0]train_loss:  tensor(545.2556, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(528.1143, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  45%|████▌     | 5/11 [00:04<00:05,  1.04it/s, v_num=0]train_loss:  tensor(544.6624, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  55%|█████▍    | 6/11 [00:06<00:05,  0.93it/s, v_num=0]train_loss:  tensor(518.6179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  64%|██████▎   | 7/11 [00:07<00:04,  0.94it/s, v_num=0]train_loss:  tensor(521.5950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  73%|███████▎  | 8/11 [00:08<00:03,  0.97it/s, v_num=0]train_loss:  tensor(547.9205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  82%|████████▏ | 9/11 [00:09<00:02,  0.95it/s, v_num=0]train_loss:  tensor(526.4058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  91%|█████████ | 10/11 [00:10<00:01,  0.97it/s, v_num=0]train_loss:  tensor(560.2299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(545.8047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   9%|▉         | 1/11 [00:01<00:11,  0.85it/s, v_num=0]train_loss:  tensor(507.6705, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  18%|█▊        | 2/11 [00:02<00:09,  0.98it/s, v_num=0]train_loss:  tensor(524.7760, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.03it/s, v_num=0]train_loss:  tensor(514.5396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(538.2385, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=0]train_loss:  tensor(515.8894, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=0]train_loss:  tensor(542.5990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.10it/s, v_num=0]train_loss:  tensor(602.5918, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=0]train_loss:  tensor(694.6910, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=0]train_loss:  tensor(699.9066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  91%|█████████ | 10/11 [00:09<00:00,  1.10it/s, v_num=0]train_loss:  tensor(622.9238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(522.9151, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   9%|▉         | 1/11 [00:00<00:09,  1.09it/s, v_num=0]train_loss:  tensor(570.5472, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(584.4232, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(534.8777, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(545.5344, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(594.0384, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(541.9430, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=0]train_loss:  tensor(530.6722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  73%|███████▎  | 8/11 [00:07<00:02,  1.13it/s, v_num=0]train_loss:  tensor(546.0541, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(546.6763, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=0]train_loss:  tensor(529.7051, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(535.7405, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   9%|▉         | 1/11 [00:01<00:10,  0.93it/s, v_num=0]train_loss:  tensor(504.3835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=0]train_loss:  tensor(525.8242, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(533.6421, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=0]train_loss:  tensor(537.7925, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(491.2307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(526.1883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(537.2023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  73%|███████▎  | 8/11 [00:07<00:02,  1.12it/s, v_num=0]train_loss:  tensor(551.1060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  82%|████████▏ | 9/11 [00:07<00:01,  1.13it/s, v_num=0]train_loss:  tensor(505.9689, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=0]train_loss:  tensor(502.8682, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(528.4922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   9%|▉         | 1/11 [00:01<00:11,  0.88it/s, v_num=0]train_loss:  tensor(489.2270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(505.4706, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(523.1580, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=0]train_loss:  tensor(504.6712, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(508.6494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(511.6002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(507.7830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=0]train_loss:  tensor(504.0202, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  82%|████████▏ | 9/11 [00:08<00:01,  1.09it/s, v_num=0]train_loss:  tensor(515.2031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=0]train_loss:  tensor(517.2402, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(491.1160, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   9%|▉         | 1/11 [00:00<00:08,  1.19it/s, v_num=0]train_loss:  tensor(497.1770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(490.9769, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(512.4471, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(488.4932, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  45%|████▌     | 5/11 [00:04<00:05,  1.06it/s, v_num=0]train_loss:  tensor(497.9121, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  55%|█████▍    | 6/11 [00:05<00:04,  1.08it/s, v_num=0]train_loss:  tensor(509.9333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  64%|██████▎   | 7/11 [00:06<00:03,  1.09it/s, v_num=0]train_loss:  tensor(470.9632, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  73%|███████▎  | 8/11 [00:07<00:02,  1.08it/s, v_num=0]train_loss:  tensor(508.9516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  82%|████████▏ | 9/11 [00:08<00:01,  1.09it/s, v_num=0]train_loss:  tensor(526.2520, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  91%|█████████ | 10/11 [00:09<00:00,  1.11it/s, v_num=0]train_loss:  tensor(497.0948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(496.8524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(483.2395, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(498.5657, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  27%|██▋       | 3/11 [00:03<00:09,  0.88it/s, v_num=0]train_loss:  tensor(513.1718, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  36%|███▋      | 4/11 [00:04<00:07,  0.95it/s, v_num=0]train_loss:  tensor(489.4619, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  45%|████▌     | 5/11 [00:05<00:06,  0.98it/s, v_num=0]train_loss:  tensor(480.5438, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  55%|█████▍    | 6/11 [00:05<00:04,  1.01it/s, v_num=0]train_loss:  tensor(485.7868, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  64%|██████▎   | 7/11 [00:06<00:03,  1.03it/s, v_num=0]train_loss:  tensor(503.8912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  73%|███████▎  | 8/11 [00:07<00:02,  1.06it/s, v_num=0]train_loss:  tensor(477.3298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  82%|████████▏ | 9/11 [00:08<00:01,  1.07it/s, v_num=0]train_loss:  tensor(499.0261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=0]train_loss:  tensor(472.2401, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(467.7952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=0]train_loss:  tensor(473.0334, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(478.0052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(496.8357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(503.2454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(472.7797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(492.4820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(484.0653, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(501.1837, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(485.8211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  91%|█████████ | 10/11 [00:09<00:00,  1.11it/s, v_num=0]train_loss:  tensor(479.7423, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(483.8839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   9%|▉         | 1/11 [00:01<00:18,  0.55it/s, v_num=0]train_loss:  tensor(484.1476, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  18%|█▊        | 2/11 [00:02<00:13,  0.69it/s, v_num=0]train_loss:  tensor(489.0211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  27%|██▋       | 3/11 [00:03<00:10,  0.77it/s, v_num=0]train_loss:  tensor(471.8190, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  36%|███▋      | 4/11 [00:04<00:08,  0.85it/s, v_num=0]train_loss:  tensor(473.9968, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  45%|████▌     | 5/11 [00:05<00:06,  0.89it/s, v_num=0]train_loss:  tensor(495.6487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  55%|█████▍    | 6/11 [00:06<00:05,  0.94it/s, v_num=0]train_loss:  tensor(487.0936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  64%|██████▎   | 7/11 [00:07<00:04,  0.97it/s, v_num=0]train_loss:  tensor(504.5281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  73%|███████▎  | 8/11 [00:08<00:03,  1.00it/s, v_num=0]train_loss:  tensor(465.5350, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  82%|████████▏ | 9/11 [00:08<00:01,  1.02it/s, v_num=0]train_loss:  tensor(460.6095, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  91%|█████████ | 10/11 [00:09<00:00,  1.05it/s, v_num=0]train_loss:  tensor(445.8221, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(487.6053, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(452.8628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(466.5634, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(469.0719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(483.1099, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(507.5357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(459.0390, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(494.1685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(471.1883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(467.7214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(470.4538, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(485.2625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=0]train_loss:  tensor(490.4334, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(515.1927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, v_num=0]train_loss:  tensor(511.4695, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(551.5089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(541.7739, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=0]train_loss:  tensor(512.8202, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(505.0963, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(452.5853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(474.4720, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(484.1461, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(501.1160, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(479.9339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(465.9431, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(472.0781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(511.3781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(467.4301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(447.6143, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(482.0715, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=0]train_loss:  tensor(489.7015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(465.5632, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(464.3948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(461.3201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(506.4977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(463.0944, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(464.2184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(470.4209, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=0]train_loss:  tensor(468.2399, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(464.1450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(466.1178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=0]train_loss:  tensor(434.2186, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(463.8064, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(457.5321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(470.3024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(447.5352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(458.0530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(447.1222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(453.2795, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(451.3499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(466.4124, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(451.5815, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(464.9974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(453.1319, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(451.6510, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(425.0907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(446.5949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(447.9050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(467.7604, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(441.4622, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(483.9178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=0]train_loss:  tensor(466.0012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(439.7097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  73%|███████▎  | 8/11 [00:07<00:02,  1.13it/s, v_num=0]train_loss:  tensor(442.9313, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(446.0122, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(493.9295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(468.9164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(443.2053, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(440.5555, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(445.1648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(457.8680, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(449.1016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(451.4797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(457.3599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(431.6955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(471.2683, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(442.2704, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(477.5374, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(468.5299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(463.7065, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(450.0006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(434.7622, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(454.2960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(451.3832, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(478.7804, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(462.3669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(435.3025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(449.8238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(443.5208, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(426.9871, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(432.8359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(466.3609, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(453.0816, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(472.0506, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(447.7148, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(451.9510, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(472.1917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(445.2244, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(445.2565, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(431.2578, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(456.1392, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(464.3962, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(450.9953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(433.2390, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(445.1860, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(443.1987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(437.9445, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(430.5076, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(433.4363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(455.0192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(446.9604, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(484.1689, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(477.9433, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(451.5548, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(438.0184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(439.8617, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(442.4703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(437.7284, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(436.8724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(403.0204, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(394.0576, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(441.7184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(435.4374, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(426.0291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(447.2701, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(455.9534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(433.7499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(428.5649, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(424.3222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(422.5282, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(446.6431, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(459.9241, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(424.4573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(434.3462, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(439.1443, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=0]train_loss:  tensor(406.2021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(411.4108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(456.5404, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(419.2594, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(433.2619, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(446.0865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(461.9125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(469.5142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(446.4338, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(450.8082, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(463.6342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(468.5294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(454.4964, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(458.4721, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(440.2673, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(423.7462, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(435.1515, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(412.7383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(427.7426, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(431.1110, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(433.9263, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(431.8121, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(441.3991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(441.6795, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(403.6753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(434.2374, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(425.6977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(426.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(443.8690, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(439.1960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(441.0394, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(420.9077, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(431.8420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(426.1376, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(436.0374, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(433.7321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(416.2403, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(443.5896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(427.5090, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(421.1054, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(439.1924, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(391.7408, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(415.6075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(441.2422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(424.5281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(417.2842, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(427.2021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(438.9026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(423.5928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(442.2184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(407.9746, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(444.5625, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(419.8507, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   9%|▉         | 1/11 [00:01<00:10,  0.94it/s, v_num=0]train_loss:  tensor(426.6369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  18%|█▊        | 2/11 [00:02<00:10,  0.89it/s, v_num=0]train_loss:  tensor(422.3365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  27%|██▋       | 3/11 [00:03<00:08,  0.99it/s, v_num=0]train_loss:  tensor(403.6948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  36%|███▋      | 4/11 [00:03<00:06,  1.06it/s, v_num=0]train_loss:  tensor(421.7960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(428.7184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=0]train_loss:  tensor(416.3358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(408.2196, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(448.6928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(427.9709, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(446.3170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(424.1279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(419.7687, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(409.6933, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(413.5926, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(434.1047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(412.1615, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=0]train_loss:  tensor(407.0624, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=0]train_loss:  tensor(443.6422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  73%|███████▎  | 8/11 [00:07<00:02,  1.13it/s, v_num=0]train_loss:  tensor(422.0654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(411.8818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(432.9385, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing model\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 13.78it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes         | Out sizes       \n",
      "----------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 6.4 M  | train | [1, 4, 128, 128] | [1, 384]        \n",
      "1 | decoder | Decoder | 6.4 M  | train | [1, 384]         | [1, 4, 128, 128]\n",
      "----------------------------------------------------------------------------------\n",
      "12.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.8 M    Total params\n",
      "51.221    Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "training model\n",
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s]                             train_loss:  tensor(30756.8691, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(30112.3105, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(29631.9492, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:03<00:09,  0.88it/s, v_num=0]train_loss:  tensor(28962.2969, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:04<00:07,  0.92it/s, v_num=0]train_loss:  tensor(28479.3770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:05<00:06,  0.95it/s, v_num=0]train_loss:  tensor(24999.5078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:06<00:05,  0.96it/s, v_num=0]train_loss:  tensor(19213.3848, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:07<00:04,  0.98it/s, v_num=0]train_loss:  tensor(23759.4434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:08<00:03,  0.99it/s, v_num=0]train_loss:  tensor(15029.1797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  82%|████████▏ | 9/11 [00:09<00:02,  1.00it/s, v_num=0]train_loss:  tensor(14895.8066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  91%|█████████ | 10/11 [00:09<00:00,  1.00it/s, v_num=0]train_loss:  tensor(14678.0381, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(12058.7529, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   9%|▉         | 1/11 [00:01<00:10,  0.94it/s, v_num=0]train_loss:  tensor(10085.6504, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=0]train_loss:  tensor(10648.3027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(9195.4023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(8288.1465, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=0]train_loss:  tensor(7643.9487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:05<00:04,  1.07it/s, v_num=0]train_loss:  tensor(6582.1221, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:06<00:03,  1.07it/s, v_num=0]train_loss:  tensor(6073.0801, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:07<00:02,  1.07it/s, v_num=0]train_loss:  tensor(5757.3052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  82%|████████▏ | 9/11 [00:08<00:01,  1.08it/s, v_num=0]train_loss:  tensor(5413.6982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=0]train_loss:  tensor(4736.0781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(4403.6338, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   9%|▉         | 1/11 [00:01<00:11,  0.88it/s, v_num=0]train_loss:  tensor(4296.1577, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(4202.2793, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(3904.1511, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(3493.3108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:04<00:05,  1.04it/s, v_num=0]train_loss:  tensor(3291.8057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:05<00:04,  1.04it/s, v_num=0]train_loss:  tensor(3118.8054, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:06<00:03,  1.04it/s, v_num=0]train_loss:  tensor(3061.5669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:08<00:03,  0.98it/s, v_num=0]train_loss:  tensor(2968.3145, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  82%|████████▏ | 9/11 [00:09<00:02,  0.99it/s, v_num=0]train_loss:  tensor(2764.9377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  91%|█████████ | 10/11 [00:10<00:01,  1.00it/s, v_num=0]train_loss:  tensor(2558.4368, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(2516.2229, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   9%|▉         | 1/11 [00:01<00:10,  0.95it/s, v_num=0]train_loss:  tensor(2443.7197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(2245.5654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(2149.0710, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(2114.6230, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=0]train_loss:  tensor(2189.3403, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:05<00:04,  1.06it/s, v_num=0]train_loss:  tensor(1996.9854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:06<00:03,  1.06it/s, v_num=0]train_loss:  tensor(2045.3599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:07<00:02,  1.06it/s, v_num=0]train_loss:  tensor(2000.7415, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  82%|████████▏ | 9/11 [00:08<00:01,  1.06it/s, v_num=0]train_loss:  tensor(1989.1398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  91%|█████████ | 10/11 [00:09<00:00,  1.06it/s, v_num=0]train_loss:  tensor(1751.0522, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1810.0479, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=0]train_loss:  tensor(1850.4875, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(1770.2267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(1774.4592, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=0]train_loss:  tensor(1762.4077, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(1742.9397, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(1680.9015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:07<00:04,  0.97it/s, v_num=0]train_loss:  tensor(1710.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:08<00:03,  0.99it/s, v_num=0]train_loss:  tensor(1681.3273, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  82%|████████▏ | 9/11 [00:09<00:02,  1.00it/s, v_num=0]train_loss:  tensor(1618.9952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  91%|█████████ | 10/11 [00:09<00:00,  1.01it/s, v_num=0]train_loss:  tensor(1614.3660, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1641.1736, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(1616.2209, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(1491.5933, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(1515.8101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(1530.6246, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(1523.5935, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(1525.4523, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:06<00:03,  1.10it/s, v_num=0]train_loss:  tensor(1508.7552, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=0]train_loss:  tensor(1507.4537, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=0]train_loss:  tensor(1457.6661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  91%|█████████ | 10/11 [00:09<00:00,  1.10it/s, v_num=0]train_loss:  tensor(1449.2667, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1396.2197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   9%|▉         | 1/11 [00:01<00:10,  0.95it/s, v_num=0]train_loss:  tensor(1462.8842, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(1401.1764, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:02<00:07,  1.09it/s, v_num=0]train_loss:  tensor(1388.2651, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(1397.8259, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(1351.8363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:05<00:04,  1.08it/s, v_num=0]train_loss:  tensor(1317.3372, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:06<00:03,  1.07it/s, v_num=0]train_loss:  tensor(1303.0342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:08<00:03,  0.97it/s, v_num=0]train_loss:  tensor(1286.7247, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  82%|████████▏ | 9/11 [00:09<00:02,  0.97it/s, v_num=0]train_loss:  tensor(1286.4004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  91%|█████████ | 10/11 [00:10<00:01,  0.98it/s, v_num=0]train_loss:  tensor(1256.2139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1180.0139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(1136.1912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:02<00:10,  0.87it/s, v_num=0]train_loss:  tensor(1128.9873, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:03<00:09,  0.80it/s, v_num=0]train_loss:  tensor(1122.5442, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:05<00:08,  0.79it/s, v_num=0]train_loss:  tensor(1046.8923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:05<00:07,  0.83it/s, v_num=0]train_loss:  tensor(1092.5092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:06<00:05,  0.87it/s, v_num=0]train_loss:  tensor(1077.1888, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:07<00:04,  0.89it/s, v_num=0]train_loss:  tensor(997.5663, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:08<00:03,  0.90it/s, v_num=0]train_loss:  tensor(1023.3464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  82%|████████▏ | 9/11 [00:09<00:02,  0.91it/s, v_num=0]train_loss:  tensor(1013.7546, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  91%|█████████ | 10/11 [00:10<00:01,  0.92it/s, v_num=0]train_loss:  tensor(966.7191, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(918.1333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   9%|▉         | 1/11 [00:01<00:14,  0.67it/s, v_num=0]train_loss:  tensor(958.2776, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:02<00:12,  0.71it/s, v_num=0]train_loss:  tensor(1054.6488, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:03<00:09,  0.80it/s, v_num=0]train_loss:  tensor(991.2382, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:04<00:08,  0.86it/s, v_num=0]train_loss:  tensor(978.0470, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:05<00:06,  0.89it/s, v_num=0]train_loss:  tensor(942.7886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:06<00:05,  0.90it/s, v_num=0]train_loss:  tensor(959.7581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:07<00:04,  0.92it/s, v_num=0]train_loss:  tensor(904.4773, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:08<00:03,  0.94it/s, v_num=0]train_loss:  tensor(896.9668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  82%|████████▏ | 9/11 [00:09<00:02,  0.95it/s, v_num=0]train_loss:  tensor(892.9314, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  91%|█████████ | 10/11 [00:10<00:01,  0.96it/s, v_num=0]train_loss:  tensor(896.7800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(868.2883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(886.7953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(869.9631, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:02<00:07,  1.03it/s, v_num=0]train_loss:  tensor(907.0853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(874.6924, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:04<00:05,  1.05it/s, v_num=0]train_loss:  tensor(842.5137, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:05<00:04,  1.05it/s, v_num=0]train_loss:  tensor(834.1449, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:06<00:03,  1.05it/s, v_num=0]train_loss:  tensor(814.3876, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:07<00:02,  1.05it/s, v_num=0]train_loss:  tensor(843.8019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  82%|████████▏ | 9/11 [00:08<00:01,  1.05it/s, v_num=0]train_loss:  tensor(779.9139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  91%|█████████ | 10/11 [00:09<00:00,  1.05it/s, v_num=0]train_loss:  tensor(838.7736, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]        train_loss:  tensor(819.4633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   9%|▉         | 1/11 [00:01<00:12,  0.82it/s, v_num=0]train_loss:  tensor(799.8937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:02<00:09,  0.97it/s, v_num=0]train_loss:  tensor(776.5703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:03<00:08,  1.00it/s, v_num=0]train_loss:  tensor(743.3522, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:03<00:06,  1.01it/s, v_num=0]train_loss:  tensor(759.6105, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:05<00:06,  1.00it/s, v_num=0]train_loss:  tensor(739.6846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:06<00:05,  0.98it/s, v_num=0]train_loss:  tensor(731.0101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:07<00:04,  0.96it/s, v_num=0]train_loss:  tensor(728.4738, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:08<00:03,  0.95it/s, v_num=0]train_loss:  tensor(716.1543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  82%|████████▏ | 9/11 [00:09<00:02,  0.95it/s, v_num=0]train_loss:  tensor(803.8339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  91%|█████████ | 10/11 [00:10<00:01,  0.94it/s, v_num=0]train_loss:  tensor(744.6334, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(702.7485, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:09,  1.00it/s, v_num=0]train_loss:  tensor(714.6250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(727.9854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(708.2982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(710.6851, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:04<00:05,  1.04it/s, v_num=0]train_loss:  tensor(709.0365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=0]train_loss:  tensor(761.4484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=0]train_loss:  tensor(797.5244, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:07<00:02,  1.02it/s, v_num=0]train_loss:  tensor(724.3960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  82%|████████▏ | 9/11 [00:08<00:01,  1.01it/s, v_num=0]train_loss:  tensor(743.2360, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  91%|█████████ | 10/11 [00:09<00:00,  1.01it/s, v_num=0]train_loss:  tensor(679.7628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(746.5573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   9%|▉         | 1/11 [00:01<00:10,  1.00it/s, v_num=0]train_loss:  tensor(742.0596, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(753.3514, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:03<00:08,  0.99it/s, v_num=0]train_loss:  tensor(690.1441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:04<00:07,  0.99it/s, v_num=0]train_loss:  tensor(691.5083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:05<00:06,  0.98it/s, v_num=0]train_loss:  tensor(681.7751, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:06<00:05,  0.98it/s, v_num=0]train_loss:  tensor(666.2156, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:07<00:04,  0.98it/s, v_num=0]train_loss:  tensor(643.9932, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:08<00:03,  0.98it/s, v_num=0]train_loss:  tensor(683.8185, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  82%|████████▏ | 9/11 [00:09<00:02,  0.98it/s, v_num=0]train_loss:  tensor(700.5956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  91%|█████████ | 10/11 [00:10<00:01,  0.98it/s, v_num=0]train_loss:  tensor(679.9100, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(639.4324, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   9%|▉         | 1/11 [00:01<00:10,  0.94it/s, v_num=0]train_loss:  tensor(714.3788, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(678.7390, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(633.6512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=0]train_loss:  tensor(661.4970, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:04<00:05,  1.02it/s, v_num=0]train_loss:  tensor(642.1752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:06<00:05,  0.97it/s, v_num=0]train_loss:  tensor(664.4298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:07<00:04,  0.97it/s, v_num=0]train_loss:  tensor(636.8235, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:08<00:03,  0.89it/s, v_num=0]train_loss:  tensor(658.6130, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  82%|████████▏ | 9/11 [00:09<00:02,  0.90it/s, v_num=0]train_loss:  tensor(647.6238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  91%|█████████ | 10/11 [00:10<00:01,  0.91it/s, v_num=0]train_loss:  tensor(643.3320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(675.0753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=0]train_loss:  tensor(653.4359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(604.2661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(673.0789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(649.9081, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=0]train_loss:  tensor(632.7164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:05<00:04,  1.02it/s, v_num=0]train_loss:  tensor(614.8554, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=0]train_loss:  tensor(629.1299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:07<00:02,  1.02it/s, v_num=0]train_loss:  tensor(641.2692, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  82%|████████▏ | 9/11 [00:08<00:01,  1.01it/s, v_num=0]train_loss:  tensor(622.1092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  91%|█████████ | 10/11 [00:09<00:00,  1.01it/s, v_num=0]train_loss:  tensor(640.6508, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(616.5560, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   9%|▉         | 1/11 [00:00<00:09,  1.00it/s, v_num=0]train_loss:  tensor(589.7796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(641.7346, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(637.9950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(628.4420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=0]train_loss:  tensor(639.6265, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.02it/s, v_num=0]train_loss:  tensor(603.4174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=0]train_loss:  tensor(608.4645, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:07<00:02,  1.02it/s, v_num=0]train_loss:  tensor(628.2955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  82%|████████▏ | 9/11 [00:08<00:01,  1.02it/s, v_num=0]train_loss:  tensor(637.3060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  91%|█████████ | 10/11 [00:09<00:00,  1.01it/s, v_num=0]train_loss:  tensor(597.4295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(576.9382, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(624.3004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(626.3979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(587.0232, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(595.9098, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=0]train_loss:  tensor(619.0050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:06<00:05,  0.99it/s, v_num=0]train_loss:  tensor(620.9756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:07<00:04,  0.99it/s, v_num=0]train_loss:  tensor(615.0883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:08<00:03,  0.99it/s, v_num=0]train_loss:  tensor(601.2205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  82%|████████▏ | 9/11 [00:09<00:02,  0.98it/s, v_num=0]train_loss:  tensor(563.4388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  91%|█████████ | 10/11 [00:10<00:01,  0.98it/s, v_num=0]train_loss:  tensor(590.8828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(630.3217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(560.4249, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(603.5891, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(655.6023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(693.0934, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.02it/s, v_num=0]train_loss:  tensor(865.9987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:06<00:05,  0.95it/s, v_num=0]train_loss:  tensor(818.2555, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:07<00:04,  0.95it/s, v_num=0]train_loss:  tensor(726.6782, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:08<00:03,  0.96it/s, v_num=0]train_loss:  tensor(557.3890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  82%|████████▏ | 9/11 [00:09<00:02,  0.96it/s, v_num=0]train_loss:  tensor(681.8170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  91%|█████████ | 10/11 [00:10<00:01,  0.96it/s, v_num=0]train_loss:  tensor(740.6044, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(586.4564, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(613.9376, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(685.9226, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:03<00:09,  0.85it/s, v_num=0]train_loss:  tensor(565.1857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:04<00:07,  0.89it/s, v_num=0]train_loss:  tensor(570.1071, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:05<00:06,  0.90it/s, v_num=0]train_loss:  tensor(654.3087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:06<00:05,  0.92it/s, v_num=0]train_loss:  tensor(584.1484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:07<00:04,  0.92it/s, v_num=0]train_loss:  tensor(633.4413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:08<00:03,  0.93it/s, v_num=0]train_loss:  tensor(590.4068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  82%|████████▏ | 9/11 [00:09<00:02,  0.94it/s, v_num=0]train_loss:  tensor(629.1000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  91%|█████████ | 10/11 [00:10<00:01,  0.94it/s, v_num=0]train_loss:  tensor(571.7789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(577.1298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(589.2043, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(552.2050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(576.4753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(579.9823, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=0]train_loss:  tensor(568.9337, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.02it/s, v_num=0]train_loss:  tensor(563.8159, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.01it/s, v_num=0]train_loss:  tensor(566.6146, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:07<00:02,  1.01it/s, v_num=0]train_loss:  tensor(582.8093, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  82%|████████▏ | 9/11 [00:08<00:01,  1.00it/s, v_num=0]train_loss:  tensor(588.2516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  91%|█████████ | 10/11 [00:10<00:01,  1.00it/s, v_num=0]train_loss:  tensor(559.3335, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(549.4796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(547.9185, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(567.6288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(570.6416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=0]train_loss:  tensor(568.1650, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  45%|████▌     | 5/11 [00:04<00:05,  1.00it/s, v_num=0]train_loss:  tensor(557.5929, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  55%|█████▍    | 6/11 [00:05<00:04,  1.00it/s, v_num=0]train_loss:  tensor(542.6804, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  64%|██████▎   | 7/11 [00:07<00:04,  1.00it/s, v_num=0]train_loss:  tensor(522.4180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  73%|███████▎  | 8/11 [00:07<00:02,  1.00it/s, v_num=0]train_loss:  tensor(541.7036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  82%|████████▏ | 9/11 [00:08<00:01,  1.01it/s, v_num=0]train_loss:  tensor(524.2408, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  91%|█████████ | 10/11 [00:09<00:00,  1.01it/s, v_num=0]train_loss:  tensor(541.8189, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(528.4681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(538.0440, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(514.0942, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(533.0887, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  36%|███▋      | 4/11 [00:03<00:06,  1.06it/s, v_num=0]train_loss:  tensor(546.5214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  45%|████▌     | 5/11 [00:04<00:05,  1.02it/s, v_num=0]train_loss:  tensor(537.5358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  55%|█████▍    | 6/11 [00:05<00:04,  1.00it/s, v_num=0]train_loss:  tensor(527.8264, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  64%|██████▎   | 7/11 [00:07<00:04,  1.00it/s, v_num=0]train_loss:  tensor(508.0451, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  73%|███████▎  | 8/11 [00:08<00:03,  0.99it/s, v_num=0]train_loss:  tensor(530.3845, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  82%|████████▏ | 9/11 [00:09<00:02,  0.95it/s, v_num=0]train_loss:  tensor(538.0430, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  91%|█████████ | 10/11 [00:10<00:01,  0.94it/s, v_num=0]train_loss:  tensor(572.7228, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(551.1887, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   9%|▉         | 1/11 [00:01<00:10,  0.92it/s, v_num=0]train_loss:  tensor(503.8991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(513.8311, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.03it/s, v_num=0]train_loss:  tensor(540.3101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.01it/s, v_num=0]train_loss:  tensor(511.1261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  45%|████▌     | 5/11 [00:05<00:06,  1.00it/s, v_num=0]train_loss:  tensor(504.8765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  55%|█████▍    | 6/11 [00:06<00:05,  1.00it/s, v_num=0]train_loss:  tensor(531.7422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  64%|██████▎   | 7/11 [00:07<00:04,  1.00it/s, v_num=0]train_loss:  tensor(515.5927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  73%|███████▎  | 8/11 [00:08<00:03,  0.99it/s, v_num=0]train_loss:  tensor(542.9090, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  82%|████████▏ | 9/11 [00:09<00:02,  0.91it/s, v_num=0]train_loss:  tensor(514.6709, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  91%|█████████ | 10/11 [00:10<00:01,  0.91it/s, v_num=0]train_loss:  tensor(510.2387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(540.1981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(506.8779, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(507.0644, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(531.8146, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=0]train_loss:  tensor(534.7529, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.02it/s, v_num=0]train_loss:  tensor(530.2932, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.01it/s, v_num=0]train_loss:  tensor(521.2582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  64%|██████▎   | 7/11 [00:07<00:04,  1.00it/s, v_num=0]train_loss:  tensor(527.1061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  73%|███████▎  | 8/11 [00:08<00:03,  0.99it/s, v_num=0]train_loss:  tensor(540.9096, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  82%|████████▏ | 9/11 [00:09<00:02,  0.99it/s, v_num=0]train_loss:  tensor(519.5443, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  91%|█████████ | 10/11 [00:10<00:01,  0.98it/s, v_num=0]train_loss:  tensor(524.7561, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(533.9164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=0]train_loss:  tensor(505.7195, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(520.9749, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(512.5732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(496.1388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.04it/s, v_num=0]train_loss:  tensor(507.0114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.05it/s, v_num=0]train_loss:  tensor(541.5980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.06it/s, v_num=0]train_loss:  tensor(507.9254, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  73%|███████▎  | 8/11 [00:07<00:02,  1.07it/s, v_num=0]train_loss:  tensor(480.8546, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  82%|████████▏ | 9/11 [00:08<00:01,  1.07it/s, v_num=0]train_loss:  tensor(511.1828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  91%|█████████ | 10/11 [00:09<00:00,  1.07it/s, v_num=0]train_loss:  tensor(532.1610, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(535.9911, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=0]train_loss:  tensor(491.9740, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(523.4756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(517.4176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(514.5393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(509.9267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(578.2120, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(598.5034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=0]train_loss:  tensor(591.1876, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=0]train_loss:  tensor(630.2076, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  91%|█████████ | 10/11 [00:08<00:00,  1.11it/s, v_num=0]train_loss:  tensor(515.5619, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(540.4196, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(475.2228, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(495.1420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(516.8306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  36%|███▋      | 4/11 [00:04<00:07,  0.98it/s, v_num=0]train_loss:  tensor(561.5211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  45%|████▌     | 5/11 [00:05<00:06,  0.96it/s, v_num=0]train_loss:  tensor(527.7941, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  55%|█████▍    | 6/11 [00:06<00:05,  0.98it/s, v_num=0]train_loss:  tensor(504.9392, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  64%|██████▎   | 7/11 [00:07<00:04,  0.98it/s, v_num=0]train_loss:  tensor(519.6716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  73%|███████▎  | 8/11 [00:08<00:03,  1.00it/s, v_num=0]train_loss:  tensor(503.4194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  82%|████████▏ | 9/11 [00:08<00:01,  1.01it/s, v_num=0]train_loss:  tensor(523.4033, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  91%|█████████ | 10/11 [00:09<00:00,  1.02it/s, v_num=0]train_loss:  tensor(500.5598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(519.5382, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   9%|▉         | 1/11 [00:01<00:11,  0.89it/s, v_num=0]train_loss:  tensor(493.1533, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(506.2199, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(493.9405, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  36%|███▋      | 4/11 [00:04<00:07,  0.90it/s, v_num=0]train_loss:  tensor(503.2485, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  45%|████▌     | 5/11 [00:05<00:06,  0.94it/s, v_num=0]train_loss:  tensor(494.8188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  55%|█████▍    | 6/11 [00:06<00:05,  0.96it/s, v_num=0]train_loss:  tensor(484.0935, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  64%|██████▎   | 7/11 [00:07<00:04,  0.98it/s, v_num=0]train_loss:  tensor(510.9117, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  73%|███████▎  | 8/11 [00:07<00:02,  1.00it/s, v_num=0]train_loss:  tensor(504.5590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  82%|████████▏ | 9/11 [00:08<00:01,  1.01it/s, v_num=0]train_loss:  tensor(512.4802, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  91%|█████████ | 10/11 [00:09<00:00,  1.02it/s, v_num=0]train_loss:  tensor(496.8647, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(489.1441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   9%|▉         | 1/11 [00:00<00:09,  1.10it/s, v_num=0]train_loss:  tensor(481.9089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=0]train_loss:  tensor(487.0422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(479.5906, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=0]train_loss:  tensor(502.4211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=0]train_loss:  tensor(492.2831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  55%|█████▍    | 6/11 [00:05<00:04,  1.06it/s, v_num=0]train_loss:  tensor(489.9971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  64%|██████▎   | 7/11 [00:06<00:03,  1.05it/s, v_num=0]train_loss:  tensor(492.3507, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  73%|███████▎  | 8/11 [00:07<00:02,  1.04it/s, v_num=0]train_loss:  tensor(472.9881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  82%|████████▏ | 9/11 [00:08<00:01,  1.03it/s, v_num=0]train_loss:  tensor(486.9306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  91%|█████████ | 10/11 [00:09<00:00,  1.03it/s, v_num=0]train_loss:  tensor(488.8713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(472.9830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   9%|▉         | 1/11 [00:01<00:10,  1.00it/s, v_num=0]train_loss:  tensor(492.9639, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=0]train_loss:  tensor(481.4667, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=0]train_loss:  tensor(490.2511, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  36%|███▋      | 4/11 [00:03<00:06,  1.00it/s, v_num=0]train_loss:  tensor(484.0027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=0]train_loss:  tensor(474.5732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=0]train_loss:  tensor(485.7534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  64%|██████▎   | 7/11 [00:06<00:03,  1.02it/s, v_num=0]train_loss:  tensor(494.6005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  73%|███████▎  | 8/11 [00:07<00:02,  1.03it/s, v_num=0]train_loss:  tensor(479.1007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  82%|████████▏ | 9/11 [00:08<00:01,  1.02it/s, v_num=0]train_loss:  tensor(476.4774, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  91%|█████████ | 10/11 [00:09<00:00,  1.03it/s, v_num=0]train_loss:  tensor(510.1291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(487.5401, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(513.7581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(488.5245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(534.2136, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(507.1682, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(546.1723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(561.3867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(542.2024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=0]train_loss:  tensor(523.1125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=0]train_loss:  tensor(486.4087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  91%|█████████ | 10/11 [00:09<00:00,  1.10it/s, v_num=0]train_loss:  tensor(481.9294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(479.5664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(515.1781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(524.2539, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(511.6238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=0]train_loss:  tensor(481.6577, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(482.3403, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(477.7120, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(501.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=0]train_loss:  tensor(499.6519, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=0]train_loss:  tensor(455.9762, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  91%|█████████ | 10/11 [00:09<00:00,  1.04it/s, v_num=0]train_loss:  tensor(457.5113, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(482.9397, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   9%|▉         | 1/11 [00:00<00:09,  1.08it/s, v_num=0]train_loss:  tensor(470.4502, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(488.3661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(480.1890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(467.9270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(503.3127, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(481.7228, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(456.5412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(496.2538, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(448.5867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(476.8146, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(471.5717, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=0]train_loss:  tensor(501.1846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(454.7334, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(487.2663, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(463.5649, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(439.4480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(476.7926, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(459.2747, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(453.8596, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(442.1391, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(486.5708, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(458.5263, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=0]train_loss:  tensor(443.4114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(468.2362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(444.1876, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(460.3123, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(453.6628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(466.1923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(475.2328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(454.6437, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(472.0523, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(451.8001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(472.6154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   9%|▉         | 1/11 [00:00<00:09,  1.11it/s, v_num=0]train_loss:  tensor(451.8167, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(443.2308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(491.8176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(466.0759, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(514.8154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(592.5974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(594.3793, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(659.6402, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(540.0117, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(498.2806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(493.3450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   9%|▉         | 1/11 [00:00<00:09,  1.10it/s, v_num=0]train_loss:  tensor(527.1611, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(530.8806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(456.3664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(486.7901, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  45%|████▌     | 5/11 [00:04<00:05,  1.01it/s, v_num=0]train_loss:  tensor(517.0239, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=0]train_loss:  tensor(502.1960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  64%|██████▎   | 7/11 [00:06<00:03,  1.04it/s, v_num=0]train_loss:  tensor(449.8056, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  73%|███████▎  | 8/11 [00:07<00:02,  1.05it/s, v_num=0]train_loss:  tensor(453.3403, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  82%|████████▏ | 9/11 [00:08<00:01,  1.06it/s, v_num=0]train_loss:  tensor(470.5240, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  91%|█████████ | 10/11 [00:09<00:00,  1.07it/s, v_num=0]train_loss:  tensor(471.7014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(459.1629, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=0]train_loss:  tensor(467.4092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(463.0540, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(439.9044, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(433.9299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(459.2106, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(469.8710, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(445.2133, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(467.2718, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(437.3073, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(477.7055, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(433.2167, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   9%|▉         | 1/11 [00:00<00:09,  1.11it/s, v_num=0]train_loss:  tensor(462.5092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(436.4570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(443.3947, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(460.9978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(445.5732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(451.4352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(463.2720, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(443.0646, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(431.8233, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(421.7895, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(448.3319, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(426.9973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(423.1447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(452.0603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(445.4713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(435.8194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(452.8135, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(433.8673, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(446.4783, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(439.4971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(471.5047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(432.6051, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(410.5436, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(456.0689, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(457.8276, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(417.4724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(436.6613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(439.5584, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=0]train_loss:  tensor(449.7501, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(427.7186, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(442.6220, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=0]train_loss:  tensor(448.4250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(435.3730, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(434.7360, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=0]train_loss:  tensor(452.1675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(446.9051, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(417.6234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(446.0334, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(438.9786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(468.7009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=0]train_loss:  tensor(452.2482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  82%|████████▏ | 9/11 [00:08<00:01,  1.09it/s, v_num=0]train_loss:  tensor(493.8263, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  91%|█████████ | 10/11 [00:09<00:00,  1.08it/s, v_num=0]train_loss:  tensor(493.5241, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(510.6746, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   9%|▉         | 1/11 [00:01<00:10,  0.95it/s, v_num=0]train_loss:  tensor(476.0882, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  18%|█▊        | 2/11 [00:01<00:08,  1.00it/s, v_num=0]train_loss:  tensor(458.8778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  27%|██▋       | 3/11 [00:02<00:07,  1.02it/s, v_num=0]train_loss:  tensor(444.1100, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=0]train_loss:  tensor(437.5168, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  45%|████▌     | 5/11 [00:04<00:05,  1.03it/s, v_num=0]train_loss:  tensor(430.8723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  55%|█████▍    | 6/11 [00:05<00:04,  1.04it/s, v_num=0]train_loss:  tensor(436.6041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  64%|██████▎   | 7/11 [00:06<00:03,  1.05it/s, v_num=0]train_loss:  tensor(449.4709, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  73%|███████▎  | 8/11 [00:07<00:02,  1.05it/s, v_num=0]train_loss:  tensor(482.1114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  82%|████████▏ | 9/11 [00:08<00:01,  1.06it/s, v_num=0]train_loss:  tensor(434.5131, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  91%|█████████ | 10/11 [00:09<00:00,  1.06it/s, v_num=0]train_loss:  tensor(457.5131, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(416.4528, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(441.4297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(461.2708, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(449.0573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=0]train_loss:  tensor(462.3936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(433.8552, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(417.9827, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  64%|██████▎   | 7/11 [00:06<00:03,  1.09it/s, v_num=0]train_loss:  tensor(417.3837, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  73%|███████▎  | 8/11 [00:07<00:02,  1.09it/s, v_num=0]train_loss:  tensor(430.9489, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=0]train_loss:  tensor(448.6599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  91%|█████████ | 10/11 [00:09<00:00,  1.09it/s, v_num=0]train_loss:  tensor(400.8833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(436.8232, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=0]train_loss:  tensor(434.6485, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=0]train_loss:  tensor(445.0375, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(433.6047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(390.7711, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(442.3971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(433.2375, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  64%|██████▎   | 7/11 [00:06<00:03,  1.10it/s, v_num=0]train_loss:  tensor(461.2680, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=0]train_loss:  tensor(420.0734, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=0]train_loss:  tensor(398.7872, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  91%|█████████ | 10/11 [00:09<00:00,  1.11it/s, v_num=0]train_loss:  tensor(441.4646, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(426.4669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   9%|▉         | 1/11 [00:01<00:10,  1.00it/s, v_num=0]train_loss:  tensor(406.4327, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(422.2468, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(435.7824, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=0]train_loss:  tensor(441.0999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(420.7990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  55%|█████▍    | 6/11 [00:06<00:05,  0.98it/s, v_num=0]train_loss:  tensor(452.2590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  64%|██████▎   | 7/11 [00:06<00:03,  1.00it/s, v_num=0]train_loss:  tensor(414.3971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  73%|███████▎  | 8/11 [00:07<00:02,  1.02it/s, v_num=0]train_loss:  tensor(430.4818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  82%|████████▏ | 9/11 [00:08<00:01,  1.03it/s, v_num=0]train_loss:  tensor(414.8809, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  91%|█████████ | 10/11 [00:09<00:00,  1.03it/s, v_num=0]train_loss:  tensor(384.7645, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(401.7291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(430.3702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=0]train_loss:  tensor(412.6269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(416.9697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(437.0201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(443.5764, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=0]train_loss:  tensor(507.4862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=0]train_loss:  tensor(553.5562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  73%|███████▎  | 8/11 [00:07<00:02,  1.12it/s, v_num=0]train_loss:  tensor(589.4049, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, v_num=0]train_loss:  tensor(613.7388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  91%|█████████ | 10/11 [00:08<00:00,  1.12it/s, v_num=0]train_loss:  tensor(604.6956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(451.8175, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(420.2860, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=0]train_loss:  tensor(510.4631, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(496.0939, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(477.6790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(447.9123, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(468.9741, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=0]train_loss:  tensor(445.9276, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(439.1344, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  82%|████████▏ | 9/11 [00:07<00:01,  1.13it/s, v_num=0]train_loss:  tensor(442.7804, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, v_num=0]train_loss:  tensor(502.1574, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(425.6965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   9%|▉         | 1/11 [00:00<00:09,  1.08it/s, v_num=0]train_loss:  tensor(417.9818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=0]train_loss:  tensor(474.3079, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(423.6516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(417.5550, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(441.6670, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(442.5209, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=0]train_loss:  tensor(428.5340, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(450.3523, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(437.2460, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=0]train_loss:  tensor(437.0549, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(419.9325, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=0]train_loss:  tensor(397.0250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=0]train_loss:  tensor(441.6396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(422.9798, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(426.2952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(424.2848, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(427.6772, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(439.8893, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(396.4710, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(422.3439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=0]train_loss:  tensor(430.6158, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 11/11 [00:10<00:00,  1.01it/s, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 14.22it/s] \n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "for latent_dim in [64, 128, 256, 384]:\n",
    "    model_ld, result_ld = train(latent_dim)\n",
    "    model_dict[latent_dim] = {\"model\": model_ld, \"result\": result_ld}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{64: {'model': Autoencoder(\n",
       "    (encoder): Encoder(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Flatten(start_dim=1, end_dim=-1)\n",
       "        (11): Linear(in_features=16384, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=16384, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (net): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): ConvTranspose2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (9): Tanh()\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  'result': {'val': [{'test_loss': 457.75244140625}]}},\n",
       " 128: {'model': Autoencoder(\n",
       "    (encoder): Encoder(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Flatten(start_dim=1, end_dim=-1)\n",
       "        (11): Linear(in_features=16384, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=16384, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (net): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): ConvTranspose2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (9): Tanh()\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  'result': {'val': [{'test_loss': 459.4795837402344}]}},\n",
       " 256: {'model': Autoencoder(\n",
       "    (encoder): Encoder(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Flatten(start_dim=1, end_dim=-1)\n",
       "        (11): Linear(in_features=16384, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=16384, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (net): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): ConvTranspose2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (9): Tanh()\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  'result': {'val': [{'test_loss': 465.7685546875}]}},\n",
       " 384: {'model': Autoencoder(\n",
       "    (encoder): Encoder(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): GELU(approximate='none')\n",
       "        (10): Flatten(start_dim=1, end_dim=-1)\n",
       "        (11): Linear(in_features=16384, out_features=384, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=16384, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (net): Sequential(\n",
       "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GELU(approximate='none')\n",
       "        (8): ConvTranspose2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (9): Tanh()\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  'result': {'val': [{'test_loss': 434.2647705078125}]}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"392.025469pt\" height=\"286.855781pt\" viewBox=\"0 0 392.025469 286.855781\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-12-12T15:54:26.600841</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.9.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 286.855781 \n",
       "L 392.025469 286.855781 \n",
       "L 392.025469 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.025469 244.980938 \n",
       "L 384.825469 244.980938 \n",
       "L 384.825469 23.220937 \n",
       "L 50.025469 23.220937 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 65.243651 244.980938 \n",
       "L 65.243651 23.220937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 64 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(59.126619 262.354531) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 182.987578 244.980938 \n",
       "L 182.987578 23.220937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 128 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(173.812031 262.354531) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 300.731505 244.980938 \n",
       "L 300.731505 23.220937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 256 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(291.555958 262.354531) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 369.607287 244.980938 \n",
       "L 369.607287 23.220937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 384 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(360.43174 262.354531) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_5\">\n",
       "     <!-- Latent dimensionality -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(161.062031 277.130156) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-4c\" d=\"M 469 0 \n",
       "L 469 4581 \n",
       "L 1075 4581 \n",
       "L 1075 541 \n",
       "L 3331 541 \n",
       "L 3331 0 \n",
       "L 469 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-64\" d=\"M 2575 0 \n",
       "L 2575 419 \n",
       "Q 2259 -75 1647 -75 \n",
       "Q 1250 -75 917 144 \n",
       "Q 584 363 401 755 \n",
       "Q 219 1147 219 1656 \n",
       "Q 219 2153 384 2558 \n",
       "Q 550 2963 881 3178 \n",
       "Q 1213 3394 1622 3394 \n",
       "Q 1922 3394 2156 3267 \n",
       "Q 2391 3141 2538 2938 \n",
       "L 2538 4581 \n",
       "L 3097 4581 \n",
       "L 3097 0 \n",
       "L 2575 0 \n",
       "z\n",
       "M 797 1656 \n",
       "Q 797 1019 1065 703 \n",
       "Q 1334 388 1700 388 \n",
       "Q 2069 388 2326 689 \n",
       "Q 2584 991 2584 1609 \n",
       "Q 2584 2291 2321 2609 \n",
       "Q 2059 2928 1675 2928 \n",
       "Q 1300 2928 1048 2622 \n",
       "Q 797 2316 797 1656 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-79\" d=\"M 397 -1278 \n",
       "L 334 -750 \n",
       "Q 519 -800 656 -800 \n",
       "Q 844 -800 956 -737 \n",
       "Q 1069 -675 1141 -563 \n",
       "Q 1194 -478 1313 -144 \n",
       "Q 1328 -97 1363 -6 \n",
       "L 103 3319 \n",
       "L 709 3319 \n",
       "L 1400 1397 \n",
       "Q 1534 1031 1641 628 \n",
       "Q 1738 1016 1872 1384 \n",
       "L 2581 3319 \n",
       "L 3144 3319 \n",
       "L 1881 -56 \n",
       "Q 1678 -603 1566 -809 \n",
       "Q 1416 -1088 1222 -1217 \n",
       "Q 1028 -1347 759 -1347 \n",
       "Q 597 -1347 397 -1278 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-4c\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"55.615234\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"111.230469\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" x=\"139.013672\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"194.628906\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"250.244141\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"278.027344\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" x=\"305.810547\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"361.425781\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" x=\"383.642578\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" x=\"466.943359\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"522.558594\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"578.173828\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"628.173828\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"650.390625\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"706.005859\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"761.621094\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" x=\"817.236328\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"839.453125\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"861.669922\"/>\n",
       "      <use xlink:href=\"#ArialMT-79\" x=\"889.453125\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 50.025469 244.980938 \n",
       "L 384.825469 244.980938 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(34.408438 248.917734) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 50.025469 200.628938 \n",
       "L 384.825469 200.628938 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 204.565734) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 50.025469 156.276938 \n",
       "L 384.825469 156.276938 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 160.213734) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 50.025469 111.924937 \n",
       "L 384.825469 111.924937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 115.861734) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 50.025469 67.572937 \n",
       "L 384.825469 67.572937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 400 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 71.509734) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 50.025469 23.220937 \n",
       "L 384.825469 23.220937 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 500 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 27.157734) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- Reconstruction error -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(15.789375 188.451562) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-52\" d=\"M 503 0 \n",
       "L 503 4581 \n",
       "L 2534 4581 \n",
       "Q 3147 4581 3465 4457 \n",
       "Q 3784 4334 3975 4021 \n",
       "Q 4166 3709 4166 3331 \n",
       "Q 4166 2844 3850 2509 \n",
       "Q 3534 2175 2875 2084 \n",
       "Q 3116 1969 3241 1856 \n",
       "Q 3506 1613 3744 1247 \n",
       "L 4541 0 \n",
       "L 3778 0 \n",
       "L 3172 953 \n",
       "Q 2906 1366 2734 1584 \n",
       "Q 2563 1803 2427 1890 \n",
       "Q 2291 1978 2150 2013 \n",
       "Q 2047 2034 1813 2034 \n",
       "L 1109 2034 \n",
       "L 1109 0 \n",
       "L 503 0 \n",
       "z\n",
       "M 1109 2559 \n",
       "L 2413 2559 \n",
       "Q 2828 2559 3062 2645 \n",
       "Q 3297 2731 3419 2920 \n",
       "Q 3541 3109 3541 3331 \n",
       "Q 3541 3656 3305 3865 \n",
       "Q 3069 4075 2559 4075 \n",
       "L 1109 4075 \n",
       "L 1109 2559 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-63\" d=\"M 2588 1216 \n",
       "L 3141 1144 \n",
       "Q 3050 572 2676 248 \n",
       "Q 2303 -75 1759 -75 \n",
       "Q 1078 -75 664 370 \n",
       "Q 250 816 250 1647 \n",
       "Q 250 2184 428 2587 \n",
       "Q 606 2991 970 3192 \n",
       "Q 1334 3394 1763 3394 \n",
       "Q 2303 3394 2647 3120 \n",
       "Q 2991 2847 3088 2344 \n",
       "L 2541 2259 \n",
       "Q 2463 2594 2264 2762 \n",
       "Q 2066 2931 1784 2931 \n",
       "Q 1359 2931 1093 2626 \n",
       "Q 828 2322 828 1663 \n",
       "Q 828 994 1084 691 \n",
       "Q 1341 388 1753 388 \n",
       "Q 2084 388 2306 591 \n",
       "Q 2528 794 2588 1216 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-52\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" x=\"72.216797\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"127.832031\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"177.832031\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"233.447266\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"289.0625\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"339.0625\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"366.845703\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" x=\"400.146484\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"455.761719\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"505.761719\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"533.544922\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"555.761719\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"611.376953\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"666.992188\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" x=\"694.775391\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"750.390625\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"783.691406\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"816.992188\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"872.607422\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 65.243651 41.958575 \n",
       "L 182.987578 41.192553 \n",
       "L 300.731505 38.403268 \n",
       "L 369.607287 52.375826 \n",
       "\" clip-path=\"url(#pe3355aa441)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n",
       "    <defs>\n",
       "     <path id=\"meace97c0f1\" d=\"M 0 -8 \n",
       "L -1.796112 -2.472136 \n",
       "L -7.608452 -2.472136 \n",
       "L -2.90617 0.944272 \n",
       "L -4.702282 6.472136 \n",
       "L -0 3.055728 \n",
       "L 4.702282 6.472136 \n",
       "L 2.90617 0.944272 \n",
       "L 7.608452 -2.472136 \n",
       "L 1.796112 -2.472136 \n",
       "z\n",
       "\" style=\"stroke: #000000; stroke-linejoin: bevel\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pe3355aa441)\">\n",
       "     <use xlink:href=\"#meace97c0f1\" x=\"65.243651\" y=\"41.958575\" style=\"fill: #ccb974; stroke: #000000; stroke-linejoin: bevel\"/>\n",
       "     <use xlink:href=\"#meace97c0f1\" x=\"182.987578\" y=\"41.192553\" style=\"fill: #ccb974; stroke: #000000; stroke-linejoin: bevel\"/>\n",
       "     <use xlink:href=\"#meace97c0f1\" x=\"300.731505\" y=\"38.403268\" style=\"fill: #ccb974; stroke: #000000; stroke-linejoin: bevel\"/>\n",
       "     <use xlink:href=\"#meace97c0f1\" x=\"369.607287\" y=\"52.375826\" style=\"fill: #ccb974; stroke: #000000; stroke-linejoin: bevel\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.025469 244.980938 \n",
       "L 50.025469 23.220937 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.825469 244.980938 \n",
       "L 384.825469 23.220937 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.025469 244.980938 \n",
       "L 384.825469 244.980938 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.025469 23.220937 \n",
       "L 384.825469 23.220937 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <!-- Reconstruction error over latent dimensionality -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(73.090937 17.220937) scale(0.14 -0.14)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-52\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"72.216797\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"127.832031\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"177.832031\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" x=\"233.447266\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"289.0625\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"339.0625\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"366.845703\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" x=\"400.146484\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"455.761719\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"505.761719\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" x=\"533.544922\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"555.761719\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" x=\"611.376953\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"666.992188\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"694.775391\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"750.390625\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"783.691406\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"816.992188\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"872.607422\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"905.908203\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"933.691406\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" x=\"989.306641\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"1039.306641\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"1094.921875\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"1128.222656\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" x=\"1156.005859\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" x=\"1178.222656\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"1233.837891\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"1261.621094\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" x=\"1317.236328\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"1372.851562\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"1400.634766\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" x=\"1428.417969\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" x=\"1484.033203\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" x=\"1506.25\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"1589.550781\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" x=\"1645.166016\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"1700.78125\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" x=\"1750.78125\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"1772.998047\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" x=\"1828.613281\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" x=\"1884.228516\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" x=\"1939.84375\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" x=\"1962.060547\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"1984.277344\"/>\n",
       "     <use xlink:href=\"#ArialMT-79\" x=\"2012.060547\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pe3355aa441\">\n",
       "   <rect x=\"50.025469\" y=\"23.220937\" width=\"334.8\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dims = sorted(k for k in model_dict)\n",
    "val_scores = [model_dict[k][\"result\"][\"val\"][0][\"test_loss\"] for k in latent_dims]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "plt.plot(\n",
    "    latent_dims, val_scores, \"--\", color=\"#000\", marker=\"*\", markeredgecolor=\"#000\", markerfacecolor=\"y\", markersize=16\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(latent_dims, labels=latent_dims)\n",
    "plt.title(\"Reconstruction error over latent dimensionality\", fontsize=14)\n",
    "plt.xlabel(\"Latent dimensionality\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.minorticks_off()\n",
    "plt.ylim(0, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_17660\\986052091.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset_name = preset[0]\n",
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_17660\\986052091.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset = torch.tensor(preset[1:-1])\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes         | Out sizes       \n",
      "----------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 2.2 M  | train | [1, 4, 128, 128] | [1, 128]        \n",
      "1 | decoder | Decoder | 2.2 M  | train | [1, 128]         | [1, 4, 128, 128]\n",
      "----------------------------------------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.665    Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating trainer\n",
      "creating model\n",
      "training model\n",
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s]                             train_loss:  tensor(32920.5938, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=0]train_loss:  tensor(32202.6172, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:01<00:05,  1.53it/s, v_num=0]train_loss:  tensor(31856.9883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:01<00:05,  1.53it/s, v_num=0]train_loss:  tensor(31395.3477, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:02<00:04,  1.54it/s, v_num=0]train_loss:  tensor(30280.8398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:03<00:03,  1.55it/s, v_num=0]train_loss:  tensor(26305.8633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:03<00:03,  1.54it/s, v_num=0]train_loss:  tensor(22365.3398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:04<00:02,  1.55it/s, v_num=0]train_loss:  tensor(23031.7344, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:05<00:01,  1.55it/s, v_num=0]train_loss:  tensor(18874.2930, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  82%|████████▏ | 9/11 [00:05<00:01,  1.56it/s, v_num=0]train_loss:  tensor(17487.1523, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  91%|█████████ | 10/11 [00:06<00:00,  1.56it/s, v_num=0]train_loss:  tensor(16187.9844, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(14514.0332, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(12561.3789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:01<00:06,  1.37it/s, v_num=0]train_loss:  tensor(11500.9199, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:02<00:05,  1.42it/s, v_num=0]train_loss:  tensor(9951.5117, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=0]train_loss:  tensor(8647.4453, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=0]train_loss:  tensor(7491.0420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:04<00:03,  1.44it/s, v_num=0]train_loss:  tensor(6647.3447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=0]train_loss:  tensor(5806.0107, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=0]train_loss:  tensor(4899.0415, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=0]train_loss:  tensor(4404.3096, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=0]train_loss:  tensor(3835.3804, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(3578.5400, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=0]train_loss:  tensor(3172.4324, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=0]train_loss:  tensor(3117.7668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=0]train_loss:  tensor(2912.2563, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:02<00:05,  1.40it/s, v_num=0]train_loss:  tensor(2800.7456, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=0]train_loss:  tensor(2703.4219, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:04<00:03,  1.40it/s, v_num=0]train_loss:  tensor(2766.7412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=0]train_loss:  tensor(2582.1697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=0]train_loss:  tensor(2501.0679, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=0]train_loss:  tensor(2622.2341, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 2:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(2599.0532, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(2534.3516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:   9%|▉         | 1/11 [00:00<00:08,  1.16it/s, v_num=0]train_loss:  tensor(2524.9004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(2254.2561, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:02<00:05,  1.35it/s, v_num=0]train_loss:  tensor(2351.9636, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=0]train_loss:  tensor(2197.9814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:03<00:04,  1.39it/s, v_num=0]train_loss:  tensor(2175.0857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:04<00:03,  1.39it/s, v_num=0]train_loss:  tensor(2184.5181, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=0]train_loss:  tensor(2136.6179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=0]train_loss:  tensor(2227.0664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=0]train_loss:  tensor(2035.2854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 3:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=0]train_loss:  tensor(2076.4221, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(2215.9023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:   9%|▉         | 1/11 [00:01<00:19,  0.53it/s, v_num=0]train_loss:  tensor(2052.8716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:03<00:14,  0.62it/s, v_num=0]train_loss:  tensor(1982.9554, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:04<00:10,  0.74it/s, v_num=0]train_loss:  tensor(1906.7358, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:04<00:08,  0.83it/s, v_num=0]train_loss:  tensor(1921.5659, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:05<00:06,  0.89it/s, v_num=0]train_loss:  tensor(1858.5404, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:06<00:05,  0.94it/s, v_num=0]train_loss:  tensor(1820.6790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:07<00:04,  0.95it/s, v_num=0]train_loss:  tensor(1806.0229, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:08<00:03,  0.93it/s, v_num=0]train_loss:  tensor(1718.5867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  82%|████████▏ | 9/11 [00:09<00:02,  0.94it/s, v_num=0]train_loss:  tensor(1769.5867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 4:  91%|█████████ | 10/11 [00:10<00:01,  0.95it/s, v_num=0]train_loss:  tensor(1739.7731, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1796.9841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:09,  1.00it/s, v_num=0]train_loss:  tensor(1682.0192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=0]train_loss:  tensor(1797.2603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(1659.5173, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=0]train_loss:  tensor(1598.6250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(1638.1709, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(1649.5035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(1652.9211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(1620.3170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(1671.5146, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 5:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=0]train_loss:  tensor(1553.4526, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1689.1581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=0]train_loss:  tensor(1477.8805, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(1511.8069, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(1495.3691, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(1519.4550, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(1521.4452, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(1546.3716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(1524.1205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(1457.4081, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(1530.6050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 6:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(1471.6394, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1515.1133, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(1331.0526, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(1457.8201, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(1394.0938, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(1294.6357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(1304.7350, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(1271.0261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(1216.7435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=0]train_loss:  tensor(1252.7269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(1214.8142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 7:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(1193.3448, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1190.9443, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:   9%|▉         | 1/11 [00:01<00:11,  0.88it/s, v_num=0]train_loss:  tensor(1158.3335, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(1161.3275, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:02<00:07,  1.09it/s, v_num=0]train_loss:  tensor(1156.0743, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(1155.7338, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(1066.0747, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(1134.0697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(1142.8658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(1149.2786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(1144.5608, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 8:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(1070.9280, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(1061.2839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(1054.4934, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(1048.1658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(1044.9973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(1079.1688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:05<00:06,  0.98it/s, v_num=0]train_loss:  tensor(1065.3442, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:06<00:05,  0.99it/s, v_num=0]train_loss:  tensor(1074.1582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:07<00:04,  1.00it/s, v_num=0]train_loss:  tensor(1055.4423, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:07<00:02,  1.02it/s, v_num=0]train_loss:  tensor(1018.2706, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  82%|████████▏ | 9/11 [00:08<00:01,  1.04it/s, v_num=0]train_loss:  tensor(975.7435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 9:  91%|█████████ | 10/11 [00:09<00:00,  1.06it/s, v_num=0]train_loss:  tensor(934.8713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]        train_loss:  tensor(941.0540, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:   9%|▉         | 1/11 [00:01<00:12,  0.79it/s, v_num=0]train_loss:  tensor(995.3768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:02<00:09,  0.92it/s, v_num=0]train_loss:  tensor(939.8702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:03<00:08,  0.97it/s, v_num=0]train_loss:  tensor(953.8766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:03<00:06,  1.00it/s, v_num=0]train_loss:  tensor(962.8092, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:04<00:05,  1.02it/s, v_num=0]train_loss:  tensor(942.1956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=0]train_loss:  tensor(943.7935, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:06<00:03,  1.05it/s, v_num=0]train_loss:  tensor(912.1830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:07<00:02,  1.08it/s, v_num=0]train_loss:  tensor(985.2421, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=0]train_loss:  tensor(951.1799, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 10:  91%|█████████ | 10/11 [00:08<00:00,  1.11it/s, v_num=0]train_loss:  tensor(921.2322, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(919.2593, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=0]train_loss:  tensor(898.8453, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(841.5869, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(870.6495, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(888.0327, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(870.3411, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(864.0536, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(847.7715, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(833.3074, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(817.5339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 11:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(883.7145, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(864.0345, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:   9%|▉         | 1/11 [00:00<00:08,  1.19it/s, v_num=0]train_loss:  tensor(865.5361, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(831.2130, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(771.9607, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(802.7396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(781.4413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(817.6265, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(784.4976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(754.8078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(774.1111, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 12:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(753.6497, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(739.1011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(758.0151, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(734.2579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(734.5841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(761.5367, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=0]train_loss:  tensor(717.9561, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:05<00:04,  1.20it/s, v_num=0]train_loss:  tensor(741.1411, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(723.2404, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(697.8702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=0]train_loss:  tensor(728.4832, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 13:  91%|█████████ | 10/11 [00:09<00:00,  1.11it/s, v_num=0]train_loss:  tensor(713.3542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(730.8701, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=0]train_loss:  tensor(745.4386, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(770.2937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(808.2590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:04<00:07,  0.98it/s, v_num=0]train_loss:  tensor(770.5178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:05<00:06,  0.99it/s, v_num=0]train_loss:  tensor(743.7089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:06<00:05,  0.99it/s, v_num=0]train_loss:  tensor(677.7382, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:07<00:04,  0.99it/s, v_num=0]train_loss:  tensor(675.2712, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:07<00:02,  1.01it/s, v_num=0]train_loss:  tensor(765.5499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  82%|████████▏ | 9/11 [00:08<00:01,  1.02it/s, v_num=0]train_loss:  tensor(712.8586, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 14:  91%|█████████ | 10/11 [00:09<00:00,  1.02it/s, v_num=0]train_loss:  tensor(684.1954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(671.7914, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:   9%|▉         | 1/11 [00:01<00:11,  0.89it/s, v_num=0]train_loss:  tensor(690.8760, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(679.0870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:02<00:07,  1.04it/s, v_num=0]train_loss:  tensor(687.7288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=0]train_loss:  tensor(691.3389, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.06it/s, v_num=0]train_loss:  tensor(660.5109, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=0]train_loss:  tensor(693.9791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(664.2899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:07<00:02,  1.12it/s, v_num=0]train_loss:  tensor(649.9487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(667.3745, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 15:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(664.9458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(649.3044, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:   9%|▉         | 1/11 [00:01<00:12,  0.81it/s, v_num=0]train_loss:  tensor(653.3192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:02<00:11,  0.81it/s, v_num=0]train_loss:  tensor(667.4814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:03<00:09,  0.88it/s, v_num=0]train_loss:  tensor(685.7544, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:04<00:07,  0.94it/s, v_num=0]train_loss:  tensor(634.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:05<00:06,  0.98it/s, v_num=0]train_loss:  tensor(670.7155, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:05<00:04,  1.02it/s, v_num=0]train_loss:  tensor(676.3693, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.05it/s, v_num=0]train_loss:  tensor(588.3309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:07<00:02,  1.07it/s, v_num=0]train_loss:  tensor(623.2568, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  82%|████████▏ | 9/11 [00:08<00:01,  1.09it/s, v_num=0]train_loss:  tensor(617.7191, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.10it/s, v_num=0]train_loss:  tensor(673.1792, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(632.9778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=0]train_loss:  tensor(639.2040, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(648.0262, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(626.6943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(642.8362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(648.9392, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(623.7770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.14it/s, v_num=0]train_loss:  tensor(607.5494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(612.0262, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(612.3848, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 17:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(633.9234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(633.2272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(595.3777, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=0]train_loss:  tensor(635.4175, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.06it/s, v_num=0]train_loss:  tensor(586.4277, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(604.8317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(566.1129, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(623.7069, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(606.7758, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(665.0270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(651.6946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(712.8167, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(643.8122, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(591.3516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=0]train_loss:  tensor(591.0120, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:02<00:06,  1.33it/s, v_num=0]train_loss:  tensor(584.9024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=0]train_loss:  tensor(578.0035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=0]train_loss:  tensor(592.3011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:04<00:03,  1.34it/s, v_num=0]train_loss:  tensor(593.6247, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=0]train_loss:  tensor(574.0492, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:05<00:02,  1.35it/s, v_num=0]train_loss:  tensor(552.6765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  82%|████████▏ | 9/11 [00:06<00:01,  1.35it/s, v_num=0]train_loss:  tensor(563.5944, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 19:  91%|█████████ | 10/11 [00:07<00:00,  1.35it/s, v_num=0]train_loss:  tensor(578.9367, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(594.4494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=0]train_loss:  tensor(558.9017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  18%|█▊        | 2/11 [00:01<00:06,  1.33it/s, v_num=0]train_loss:  tensor(555.9810, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  27%|██▋       | 3/11 [00:02<00:05,  1.33it/s, v_num=0]train_loss:  tensor(563.7694, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(564.9454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=0]train_loss:  tensor(570.4482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(534.7316, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(578.2257, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(566.0335, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(538.7515, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 20:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(548.0853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(546.1017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=0]train_loss:  tensor(532.2328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(535.8398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(548.7235, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(524.1991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(575.4364, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(541.6853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=0]train_loss:  tensor(569.0115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(555.0069, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=0]train_loss:  tensor(560.6669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 21:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(534.5359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(521.0272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(532.4288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(526.7383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(555.8280, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(567.5833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(584.6716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(598.0254, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(668.3782, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(655.5703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(655.9066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 22:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(608.2892, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(506.5977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:   9%|▉         | 1/11 [00:01<00:10,  0.96it/s, v_num=0]train_loss:  tensor(556.9434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(571.2457, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, v_num=0]train_loss:  tensor(585.1512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(546.0670, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(525.6917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(560.8683, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(572.6865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(562.0272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(532.5417, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 23:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(532.5797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(551.4524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(534.0597, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(536.1574, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(550.8107, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(546.8615, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(504.8770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(512.9839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(522.9672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(501.1663, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(515.9543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 24:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(483.6979, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(504.3247, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(542.2786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(506.3885, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(494.9176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(492.4083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(531.8027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(519.7941, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(511.5251, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(495.0143, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(496.6469, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 25:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(517.7748, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(513.1675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:   9%|▉         | 1/11 [00:01<00:11,  0.90it/s, v_num=0]train_loss:  tensor(495.5581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  18%|█▊        | 2/11 [00:01<00:08,  1.02it/s, v_num=0]train_loss:  tensor(510.8907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(503.1057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=0]train_loss:  tensor(504.9550, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(475.8361, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(483.3300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(507.9129, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(496.7629, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(487.6658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 26:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(474.0242, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(505.4976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=0]train_loss:  tensor(474.0983, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(492.2653, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(502.3935, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(549.2008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(539.7589, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(602.2789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(550.0178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(519.9045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(535.1901, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 27:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(478.0286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(484.2290, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=0]train_loss:  tensor(511.6868, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(536.3018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(524.1974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(505.4946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(505.1438, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(480.0968, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(506.0667, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(493.1973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(492.1652, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 28:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(487.1472, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(476.9351, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(497.7426, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(496.6673, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(493.8477, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(491.8195, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=0]train_loss:  tensor(477.6567, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s, v_num=0]train_loss:  tensor(467.7000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  64%|██████▎   | 7/11 [00:05<00:03,  1.33it/s, v_num=0]train_loss:  tensor(503.7454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  73%|███████▎  | 8/11 [00:06<00:02,  1.33it/s, v_num=0]train_loss:  tensor(471.5048, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  82%|████████▏ | 9/11 [00:06<00:01,  1.33it/s, v_num=0]train_loss:  tensor(474.0992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 29:  91%|█████████ | 10/11 [00:07<00:00,  1.33it/s, v_num=0]train_loss:  tensor(474.1428, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(471.0207, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=0]train_loss:  tensor(479.8716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(479.8998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(489.7981, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(459.9327, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(467.4494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(445.8732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(450.2993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(508.2132, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(487.6170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 30:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(523.2576, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(491.2097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:   9%|▉         | 1/11 [00:00<00:07,  1.31it/s, v_num=0]train_loss:  tensor(476.9597, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(533.5451, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(516.3952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(507.5369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=0]train_loss:  tensor(491.1882, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=0]train_loss:  tensor(475.7719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=0]train_loss:  tensor(479.6799, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  73%|███████▎  | 8/11 [00:06<00:02,  1.33it/s, v_num=0]train_loss:  tensor(463.9064, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  82%|████████▏ | 9/11 [00:06<00:01,  1.33it/s, v_num=0]train_loss:  tensor(468.4170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 31:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(444.1639, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(435.6887, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(496.3873, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(475.8028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(450.5714, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(473.1119, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(468.8632, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(469.1737, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(476.3404, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(465.2267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(479.1215, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 32:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(439.8565, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(474.1006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:   9%|▉         | 1/11 [00:00<00:09,  1.10it/s, v_num=0]train_loss:  tensor(449.8911, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(447.7734, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(449.8695, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(462.8168, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(481.1152, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(462.8616, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(488.8821, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(509.2996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(571.7163, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 33:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(679.4857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(736.8255, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(658.0326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(509.3084, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(487.2297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(570.2549, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(552.9592, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(503.7975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(520.1973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(530.7345, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(492.3884, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 34:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(517.4246, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(538.2294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=0]train_loss:  tensor(522.9559, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=0]train_loss:  tensor(523.3108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  27%|██▋       | 3/11 [00:02<00:06,  1.33it/s, v_num=0]train_loss:  tensor(534.2628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(490.5280, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(519.5443, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=0]train_loss:  tensor(528.0803, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(418.2953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(466.4326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(483.9292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 35:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(478.6796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(473.4833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:   9%|▉         | 1/11 [00:00<00:09,  1.09it/s, v_num=0]train_loss:  tensor(507.6876, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(470.8889, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(465.5185, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(461.0476, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=0]train_loss:  tensor(478.1524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(476.8859, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(447.5118, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(436.3099, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(441.5920, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 36:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(474.6035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(446.8070, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(443.6038, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=0]train_loss:  tensor(465.6282, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  27%|██▋       | 3/11 [00:02<00:06,  1.32it/s, v_num=0]train_loss:  tensor(446.9534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(474.5681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=0]train_loss:  tensor(452.2988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(456.6833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(459.9863, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=0]train_loss:  tensor(423.2781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=0]train_loss:  tensor(464.9680, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 37:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(418.8888, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(429.0975, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(417.7407, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(463.4922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(445.4869, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(430.5184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(478.8369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(464.6949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(444.2723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(454.2606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(424.8314, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 38:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(445.6858, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(444.0356, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(430.7703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(444.5065, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(439.2099, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=0]train_loss:  tensor(435.5862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=0]train_loss:  tensor(427.5732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=0]train_loss:  tensor(461.7561, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=0]train_loss:  tensor(473.0295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(415.4478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(440.6066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 39:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(451.7180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(419.8899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=0]train_loss:  tensor(436.2061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(450.4490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(430.1101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(435.9412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(439.3997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(473.2261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(435.7785, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(434.6248, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(424.8902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 40:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(451.2663, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(444.9484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(430.3113, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(426.0525, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=0]train_loss:  tensor(418.5462, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(408.7016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(452.7023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(448.1154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(450.2622, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(426.8320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(444.0110, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 41:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(431.0457, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(453.5664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=0]train_loss:  tensor(420.9455, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(423.8881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(446.5555, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(450.6275, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(434.0217, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(442.1091, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(438.1710, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(451.7972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(435.3856, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 42:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(424.2624, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(461.6676, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(489.7458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=0]train_loss:  tensor(466.8900, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  27%|██▋       | 3/11 [00:02<00:06,  1.33it/s, v_num=0]train_loss:  tensor(438.4269, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=0]train_loss:  tensor(461.8582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=0]train_loss:  tensor(460.4118, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=0]train_loss:  tensor(430.2629, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=0]train_loss:  tensor(423.7938, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  73%|███████▎  | 8/11 [00:06<00:02,  1.33it/s, v_num=0]train_loss:  tensor(444.2112, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  82%|████████▏ | 9/11 [00:06<00:01,  1.33it/s, v_num=0]train_loss:  tensor(446.1649, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 43:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(452.9928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(422.4920, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(428.0695, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(447.1551, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, v_num=0]train_loss:  tensor(417.4856, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(426.5590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(464.1000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(465.9245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(430.5223, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(429.5726, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=0]train_loss:  tensor(428.1885, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 44:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(452.6324, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(415.4022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=0]train_loss:  tensor(435.8463, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(439.4258, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(435.7869, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=0]train_loss:  tensor(407.3659, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(419.2867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(443.6901, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(410.8334, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(415.7904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(430.3654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 45:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(430.7517, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(410.1649, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(431.3417, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=0]train_loss:  tensor(434.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(433.3107, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(431.2874, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(427.2541, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(414.9997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(403.5513, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(433.9639, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(419.0142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 46:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(425.6867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(406.0273, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(449.2282, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  18%|█▊        | 2/11 [00:01<00:08,  1.10it/s, v_num=0]train_loss:  tensor(422.4633, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(420.0844, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(450.3123, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(428.2697, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(426.1050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(454.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(441.3198, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(519.0383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 47:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(552.5573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(552.9505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(478.6572, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=0]train_loss:  tensor(409.7301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  27%|██▋       | 3/11 [00:02<00:06,  1.32it/s, v_num=0]train_loss:  tensor(435.7577, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(528.0233, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(487.4125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(409.5355, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(435.7087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=0]train_loss:  tensor(456.1083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(442.8123, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 48:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(427.2423, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(448.3153, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(446.7562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=0]train_loss:  tensor(439.4594, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  27%|██▋       | 3/11 [00:02<00:06,  1.32it/s, v_num=0]train_loss:  tensor(424.6579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=0]train_loss:  tensor(467.5399, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=0]train_loss:  tensor(430.3451, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=0]train_loss:  tensor(396.2968, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  64%|██████▎   | 7/11 [00:05<00:03,  1.32it/s, v_num=0]train_loss:  tensor(425.6218, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  73%|███████▎  | 8/11 [00:06<00:02,  1.32it/s, v_num=0]train_loss:  tensor(420.2707, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=0]train_loss:  tensor(418.1846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 49:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s, v_num=0]train_loss:  tensor(433.2386, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(427.7041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(448.2154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(409.7763, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(445.1585, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(400.6508, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(420.2895, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  55%|█████▍    | 6/11 [00:05<00:04,  1.20it/s, v_num=0]train_loss:  tensor(426.8881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(418.9549, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(398.4481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(404.2783, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 50:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(430.7884, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(437.1419, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(409.9439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(385.1480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(449.1450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(411.6031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=0]train_loss:  tensor(423.4904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(429.5662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=0]train_loss:  tensor(402.0340, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(399.1778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(402.7230, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 51:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(408.7227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(403.0699, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(422.1177, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(399.5303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(419.6556, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(430.6188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(399.5109, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(424.7672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(397.4807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(411.7095, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(409.8205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 52:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(424.8628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(404.8562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(422.7941, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(418.5544, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(396.9740, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(396.5970, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(405.4899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(405.3452, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(432.8627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(408.3937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(405.3231, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 53:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(413.4573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(416.9117, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(405.3840, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(402.9830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(376.7990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  36%|███▋      | 4/11 [00:03<00:06,  1.04it/s, v_num=0]train_loss:  tensor(414.9902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=0]train_loss:  tensor(425.3067, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(417.1041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  64%|██████▎   | 7/11 [00:06<00:03,  1.08it/s, v_num=0]train_loss:  tensor(395.0807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  73%|███████▎  | 8/11 [00:07<00:02,  1.08it/s, v_num=0]train_loss:  tensor(431.4194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=0]train_loss:  tensor(397.7515, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 54:  91%|█████████ | 10/11 [00:08<00:00,  1.12it/s, v_num=0]train_loss:  tensor(407.1295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(411.2028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(390.8405, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(415.4772, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(421.8220, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(413.0377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  45%|████▌     | 5/11 [00:03<00:04,  1.25it/s, v_num=0]train_loss:  tensor(406.5180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(412.4296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(412.6855, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(387.0089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(392.0025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 55:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(416.3369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(398.3456, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(393.9434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(383.7105, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(396.2080, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(391.7830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(411.1094, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(405.2648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(402.3476, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(444.0109, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(423.0272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 56:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(430.1212, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(404.9634, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(422.1628, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(416.6423, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(399.1292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(401.2719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  45%|████▌     | 5/11 [00:04<00:05,  1.13it/s, v_num=0]train_loss:  tensor(408.1270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(396.2482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=0]train_loss:  tensor(412.7020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=0]train_loss:  tensor(430.6961, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=0]train_loss:  tensor(394.3818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 57:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(365.4054, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(419.2363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=0]train_loss:  tensor(405.5450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(389.5584, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(430.4916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(387.9134, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(429.5165, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(416.4816, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(411.7338, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(395.7732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(394.8922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 58:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(383.8998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(396.9222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:   9%|▉         | 1/11 [00:01<00:10,  0.94it/s, v_num=0]train_loss:  tensor(397.0210, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  18%|█▊        | 2/11 [00:02<00:09,  0.94it/s, v_num=0]train_loss:  tensor(399.1916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  27%|██▋       | 3/11 [00:02<00:07,  1.03it/s, v_num=0]train_loss:  tensor(405.6282, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(404.3125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  45%|████▌     | 5/11 [00:04<00:05,  1.02it/s, v_num=0]train_loss:  tensor(401.4022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  55%|█████▍    | 6/11 [00:05<00:04,  1.05it/s, v_num=0]train_loss:  tensor(397.6277, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  64%|██████▎   | 7/11 [00:06<00:03,  1.08it/s, v_num=0]train_loss:  tensor(374.6241, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  73%|███████▎  | 8/11 [00:07<00:02,  1.09it/s, v_num=0]train_loss:  tensor(415.9398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  82%|████████▏ | 9/11 [00:08<00:01,  1.11it/s, v_num=0]train_loss:  tensor(420.0587, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 59:  91%|█████████ | 10/11 [00:08<00:00,  1.12it/s, v_num=0]train_loss:  tensor(418.1759, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(380.4362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(421.9588, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(403.9175, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(417.8791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(424.1744, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(427.5520, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(407.9634, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(434.0648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(426.3326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(410.2834, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 60:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=0]train_loss:  tensor(396.3179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(400.5530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(406.8599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(412.6700, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(412.6277, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(422.7431, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(417.2910, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(395.4808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(400.4151, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(381.0107, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(377.1859, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 61:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(400.3279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(401.9433, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:   9%|▉         | 1/11 [00:00<00:09,  1.09it/s, v_num=0]train_loss:  tensor(418.3265, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(391.6303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(368.3618, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(403.6519, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  45%|████▌     | 5/11 [00:03<00:04,  1.25it/s, v_num=0]train_loss:  tensor(421.3396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(382.7432, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(402.9193, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(408.1597, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  82%|████████▏ | 9/11 [00:07<00:01,  1.29it/s, v_num=0]train_loss:  tensor(376.6476, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 62:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(422.0366, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(388.9526, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(389.0400, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(402.7164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(398.5724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(387.9399, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(408.5373, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=0]train_loss:  tensor(411.2686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(426.1735, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(377.9278, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(411.1639, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 63:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=0]train_loss:  tensor(388.1573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(406.9029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=0]train_loss:  tensor(419.4865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(392.4333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(396.2662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(393.1516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(416.5729, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(388.2138, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(369.8564, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(400.8056, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(393.9623, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 64:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(395.6699, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(393.9848, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(405.8412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(378.3636, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(403.5966, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(411.8974, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(388.3525, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(372.7764, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(403.0732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(400.9313, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(399.7675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 65:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(395.8019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(398.4367, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(410.5948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(394.1675, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(414.9362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(440.5794, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(422.7247, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(430.9385, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(384.6362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(411.2570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(429.7614, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 66:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(398.4260, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(384.5397, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(419.1320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(401.0790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(408.4430, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(404.1001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(405.7246, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(399.5992, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(408.0916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(393.8038, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(416.1795, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 67:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(384.5977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(400.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:   9%|▉         | 1/11 [00:00<00:09,  1.09it/s, v_num=0]train_loss:  tensor(409.9822, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(386.8029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(380.7023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(378.1232, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(383.4164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=0]train_loss:  tensor(419.5838, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(388.6950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  73%|███████▎  | 8/11 [00:07<00:02,  1.12it/s, v_num=0]train_loss:  tensor(417.1489, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(375.9807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 68:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(367.8661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(395.6796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(394.1816, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(373.6341, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(382.3423, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(390.3478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(387.5781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(414.0549, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(393.9091, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=0]train_loss:  tensor(396.5139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(370.1255, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 69:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(391.4291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(404.0813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:   9%|▉         | 1/11 [00:01<00:11,  0.90it/s, v_num=0]train_loss:  tensor(372.3671, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(393.1388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(399.5690, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(402.5124, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(381.8631, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=0]train_loss:  tensor(400.9742, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(398.1466, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(385.8794, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(362.6551, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 70:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(373.1281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(385.8953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(394.3571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(390.8204, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(393.3905, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(380.6808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(386.7997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(374.8499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(374.2686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(400.1912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(374.2531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 71:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(402.0485, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(403.0702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(360.5112, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(393.1289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(382.2448, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(391.4036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(377.3452, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(402.5239, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(395.0666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(381.9517, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(372.4606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 72:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(383.4221, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(408.6600, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(406.8813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(380.6722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(394.3122, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(411.0285, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(393.0614, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(417.3737, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(435.8242, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(419.6190, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(442.2214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 73:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(440.5277, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(416.7831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(391.1279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  18%|█▊        | 2/11 [00:01<00:08,  1.10it/s, v_num=0]train_loss:  tensor(395.6693, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(406.5053, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(399.7492, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(401.8068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(373.8615, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(396.7719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(391.5102, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(418.1171, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 74:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(396.4307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(396.3090, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(377.1790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(410.3908, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(426.8947, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(388.2586, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(353.3584, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(398.3777, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(398.9330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(378.4767, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(398.0884, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 75:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(358.3355, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(406.7698, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:   9%|▉         | 1/11 [00:01<00:10,  0.93it/s, v_num=0]train_loss:  tensor(406.5274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=0]train_loss:  tensor(378.5136, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(382.5819, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(375.3570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(384.8040, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  55%|█████▍    | 6/11 [00:05<00:04,  1.09it/s, v_num=0]train_loss:  tensor(390.6766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(365.6943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  73%|███████▎  | 8/11 [00:07<00:02,  1.12it/s, v_num=0]train_loss:  tensor(381.8387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(383.5569, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 76:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=0]train_loss:  tensor(374.0270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(374.3140, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(383.7159, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(375.0294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(390.4373, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(361.2769, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=0]train_loss:  tensor(379.9601, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(391.6026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(389.1494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(407.1163, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(371.5226, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 77:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(376.7188, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(405.7626, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(390.6036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(361.5654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(389.7541, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(377.7412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(370.5235, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(384.0113, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=0]train_loss:  tensor(379.7902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(373.2630, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=0]train_loss:  tensor(377.9427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 78:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(359.2794, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(387.1971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=0]train_loss:  tensor(382.3778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(387.8464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(392.6490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(370.7243, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=0]train_loss:  tensor(374.8554, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(372.2388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(403.0562, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(360.0455, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(381.4115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 79:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(354.5478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(383.5072, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:   9%|▉         | 1/11 [00:01<00:13,  0.76it/s, v_num=0]train_loss:  tensor(381.5794, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  18%|█▊        | 2/11 [00:02<00:09,  0.95it/s, v_num=0]train_loss:  tensor(371.0450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  27%|██▋       | 3/11 [00:02<00:07,  1.04it/s, v_num=0]train_loss:  tensor(381.5162, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  36%|███▋      | 4/11 [00:03<00:06,  1.10it/s, v_num=0]train_loss:  tensor(383.6454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(370.5132, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(372.9649, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(355.7527, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(397.8387, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(364.0514, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 80:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(406.7908, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(388.8530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(368.3566, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(399.0013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(393.8464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(361.7603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(405.2090, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(385.1468, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(367.7267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(392.1902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(345.1508, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 81:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(348.5388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(362.1068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(397.9026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(372.0062, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  27%|██▋       | 3/11 [00:02<00:07,  1.02it/s, v_num=0]train_loss:  tensor(383.1276, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  36%|███▋      | 4/11 [00:03<00:06,  1.08it/s, v_num=0]train_loss:  tensor(383.2300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(366.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(368.7862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=0]train_loss:  tensor(394.5192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(375.1346, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(401.6600, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 82:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(376.0666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(396.0449, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(355.2035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(362.5307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(388.9792, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(392.5386, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(382.4980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(368.7896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(358.8542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(390.6534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(371.0542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 83:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(387.1472, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(383.0357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:   9%|▉         | 1/11 [00:01<00:11,  0.89it/s, v_num=0]train_loss:  tensor(361.6673, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, v_num=0]train_loss:  tensor(391.6223, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(374.2060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(380.0508, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(374.7375, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(375.0761, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(378.2714, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(376.1639, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(388.1940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 84:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(436.4648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(441.7903, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(458.8908, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(479.6274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(447.8909, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(396.8055, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(397.5870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(428.0699, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(439.8107, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(393.1458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(381.5063, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 85:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(374.0766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(443.1685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(389.6870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(390.4142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(408.3534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(415.7691, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(396.0031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(365.2952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(375.0756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(389.0224, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(369.8805, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 86:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(372.3190, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(364.0186, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(386.4378, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(377.5280, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(386.4197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=0]train_loss:  tensor(391.5718, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(368.0998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(369.0427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=0]train_loss:  tensor(375.6354, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(384.8701, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(378.0460, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 87:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=0]train_loss:  tensor(399.7389, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(398.0477, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(380.8317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=0]train_loss:  tensor(364.4791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=0]train_loss:  tensor(359.3418, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(338.8809, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(364.4208, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(361.9505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(398.8286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(409.8936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(385.5238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 88:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(350.1286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(375.3907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:   9%|▉         | 1/11 [00:01<00:11,  0.86it/s, v_num=0]train_loss:  tensor(355.0909, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=0]train_loss:  tensor(369.0434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  27%|██▋       | 3/11 [00:02<00:07,  1.09it/s, v_num=0]train_loss:  tensor(371.8582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(392.3000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(348.8202, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(381.4230, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(377.7333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(369.9684, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(365.7886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 89:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(383.7726, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(363.8849, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(351.5406, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(386.5172, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(383.4085, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(352.6912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=0]train_loss:  tensor(394.6138, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  55%|█████▍    | 6/11 [00:05<00:04,  1.06it/s, v_num=0]train_loss:  tensor(366.3931, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  64%|██████▎   | 7/11 [00:06<00:03,  1.01it/s, v_num=0]train_loss:  tensor(357.0326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  73%|███████▎  | 8/11 [00:08<00:03,  1.00it/s, v_num=0]train_loss:  tensor(367.8233, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  82%|████████▏ | 9/11 [00:08<00:01,  1.03it/s, v_num=0]train_loss:  tensor(371.0018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 90:  91%|█████████ | 10/11 [00:09<00:00,  1.05it/s, v_num=0]train_loss:  tensor(386.5927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(358.5427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:   9%|▉         | 1/11 [00:01<00:10,  0.98it/s, v_num=0]train_loss:  tensor(348.3642, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(394.0143, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(378.5542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(362.6575, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(372.3666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  55%|█████▍    | 6/11 [00:05<00:04,  1.20it/s, v_num=0]train_loss:  tensor(357.2208, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(368.3801, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(370.0786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(367.8200, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 91:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(386.5526, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(362.4879, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=0]train_loss:  tensor(403.2902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=0]train_loss:  tensor(348.0361, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  27%|██▋       | 3/11 [00:02<00:07,  1.04it/s, v_num=0]train_loss:  tensor(356.5255, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(355.1393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(383.4739, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(362.2153, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(374.1724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(367.2367, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(348.6846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 92:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(394.6603, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(344.1751, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:   9%|▉         | 1/11 [00:01<00:10,  0.97it/s, v_num=0]train_loss:  tensor(364.8016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(350.3466, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(374.0178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(381.0839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(363.2750, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(384.3826, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(386.0371, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(365.0851, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(361.7200, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 93:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(359.4275, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(356.2303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=0]train_loss:  tensor(387.6435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(380.9711, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(366.1885, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(384.5560, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(358.4025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(368.8273, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(351.7403, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(355.0192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(378.8578, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 94:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(373.3096, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(372.3826, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:   9%|▉         | 1/11 [00:01<00:10,  0.94it/s, v_num=0]train_loss:  tensor(365.2012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(373.7687, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(398.7399, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(348.9183, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(355.2896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(349.3949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=0]train_loss:  tensor(350.9426, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(398.0016, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(367.2410, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 95:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(346.2230, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(377.2579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:   9%|▉         | 1/11 [00:00<00:09,  1.09it/s, v_num=0]train_loss:  tensor(351.2396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  18%|█▊        | 2/11 [00:01<00:08,  1.00it/s, v_num=0]train_loss:  tensor(372.1423, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(369.7527, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(361.1237, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  45%|████▌     | 5/11 [00:04<00:05,  1.13it/s, v_num=0]train_loss:  tensor(359.3529, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(352.7381, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=0]train_loss:  tensor(385.9006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=0]train_loss:  tensor(378.3708, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=0]train_loss:  tensor(369.6102, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 96:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(368.7560, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(371.4236, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(392.7763, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(391.9184, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(414.1240, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(385.1207, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(422.0371, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(356.9685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(351.0443, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(369.1219, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(370.3613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 97:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(340.7379, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(404.5785, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=0]train_loss:  tensor(394.1893, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=0]train_loss:  tensor(358.2297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  27%|██▋       | 3/11 [00:02<00:06,  1.33it/s, v_num=0]train_loss:  tensor(366.1321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=0]train_loss:  tensor(345.0681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=0]train_loss:  tensor(380.9046, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(357.1744, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(363.2068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(347.4023, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(360.0490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 98:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(395.2619, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(364.9579, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(365.2437, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(356.2646, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(371.3954, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(348.7928, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(377.0595, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(358.1331, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=0]train_loss:  tensor(371.1446, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(360.5899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(348.6741, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 99:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(394.1261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]        train_loss:  tensor(349.9317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:   9%|▉         | 1/11 [00:00<00:08,  1.17it/s, v_num=0]train_loss:  tensor(369.8548, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(373.1439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(378.5803, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(349.4909, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(361.3940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(364.2000, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(346.2621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(343.3124, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(366.6320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 100:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=0]train_loss:  tensor(377.1771, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(340.5789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=0]train_loss:  tensor(369.2129, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(376.2449, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, v_num=0]train_loss:  tensor(340.9505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=0]train_loss:  tensor(357.5420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(351.1336, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(367.9521, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=0]train_loss:  tensor(378.2894, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(370.9236, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(340.3438, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 101:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(376.2858, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(359.4803, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:   9%|▉         | 1/11 [00:00<00:08,  1.19it/s, v_num=0]train_loss:  tensor(357.3945, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(358.8574, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, v_num=0]train_loss:  tensor(367.8710, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=0]train_loss:  tensor(385.0543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=0]train_loss:  tensor(392.0909, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(407.0405, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s, v_num=0]train_loss:  tensor(390.7958, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=0]train_loss:  tensor(468.5378, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, v_num=0]train_loss:  tensor(431.1439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 102:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, v_num=0]train_loss:  tensor(359.7922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(360.2756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(360.3260, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(406.1808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(412.2904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(372.7560, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(376.4375, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(346.7590, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(392.3525, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(379.4378, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(400.3124, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 103:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(345.6626, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(357.7530, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=0]train_loss:  tensor(393.8569, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(370.3340, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(342.6331, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(367.2856, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(379.8766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(347.8140, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(361.7814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(356.7458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(366.7216, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 104:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=0]train_loss:  tensor(366.0250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(352.8432, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(378.7195, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(351.1837, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(373.9119, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  36%|███▋      | 4/11 [00:03<00:06,  1.17it/s, v_num=0]train_loss:  tensor(342.0013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=0]train_loss:  tensor(329.3324, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(353.5489, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  64%|██████▎   | 7/11 [00:05<00:03,  1.21it/s, v_num=0]train_loss:  tensor(346.3227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(373.4142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(355.9025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 105:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=0]train_loss:  tensor(381.9413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(368.9991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(349.8226, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(344.4156, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(356.7814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(344.5355, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(355.3970, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(373.4203, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  64%|██████▎   | 7/11 [00:05<00:03,  1.30it/s, v_num=0]train_loss:  tensor(344.7457, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(364.3290, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(342.6467, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 106:  91%|█████████ | 10/11 [00:07<00:00,  1.31it/s, v_num=0]train_loss:  tensor(335.6207, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(355.6172, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:   9%|▉         | 1/11 [00:00<00:09,  1.08it/s, v_num=0]train_loss:  tensor(369.0570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(339.8427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(361.5685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(356.1888, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(350.1122, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(343.5942, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(346.7939, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(342.9239, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(346.9174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 107:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(338.8788, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(352.2787, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(358.8348, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  18%|█▊        | 2/11 [00:02<00:10,  0.90it/s, v_num=0]train_loss:  tensor(334.8171, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  27%|██▋       | 3/11 [00:02<00:07,  1.00it/s, v_num=0]train_loss:  tensor(314.8204, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(360.4681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(349.8914, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(345.9539, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(355.7619, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(349.3377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(355.7542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 108:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(374.2624, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(359.5608, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=0]train_loss:  tensor(348.7773, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=0]train_loss:  tensor(362.9279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(341.4800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(356.1295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(359.1696, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(346.0209, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(340.3826, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(356.7060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(362.9740, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 109:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(371.9042, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(359.6599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(368.5058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=0]train_loss:  tensor(352.5536, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(352.5602, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(348.7716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(337.3588, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(338.8193, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(364.7001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(356.1187, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(337.9503, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 110:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(313.2831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(329.7266, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=0]train_loss:  tensor(353.2736, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(348.8723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(327.3788, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(334.1862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=0]train_loss:  tensor(351.0089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  55%|█████▍    | 6/11 [00:04<00:03,  1.30it/s, v_num=0]train_loss:  tensor(361.6474, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=0]train_loss:  tensor(339.7573, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(340.1134, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(342.2322, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 111:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(348.4271, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(331.6972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(343.5836, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(359.2758, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(337.8225, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(353.1372, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(345.8664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(327.0817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(341.2405, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  73%|███████▎  | 8/11 [00:07<00:02,  1.08it/s, v_num=0]train_loss:  tensor(346.4867, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  82%|████████▏ | 9/11 [00:08<00:01,  1.10it/s, v_num=0]train_loss:  tensor(318.7714, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 112:  91%|█████████ | 10/11 [00:08<00:00,  1.12it/s, v_num=0]train_loss:  tensor(349.5902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(344.9129, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:   9%|▉         | 1/11 [00:00<00:08,  1.19it/s, v_num=0]train_loss:  tensor(343.5308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(317.5688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(332.0644, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(327.4767, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(339.7723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(331.0466, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(337.1160, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  73%|███████▎  | 8/11 [00:06<00:02,  1.22it/s, v_num=0]train_loss:  tensor(351.6368, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(340.8252, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 113:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(338.2571, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(333.1164, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:   9%|▉         | 1/11 [00:01<00:11,  0.84it/s, v_num=0]train_loss:  tensor(320.3902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  18%|█▊        | 2/11 [00:02<00:09,  0.98it/s, v_num=0]train_loss:  tensor(331.6729, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  27%|██▋       | 3/11 [00:02<00:07,  1.03it/s, v_num=0]train_loss:  tensor(323.2383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  36%|███▋      | 4/11 [00:03<00:06,  1.08it/s, v_num=0]train_loss:  tensor(340.9075, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(370.6073, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(329.0844, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(335.6179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(347.1330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(333.7345, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 114:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(361.4533, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(381.1408, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:   9%|▉         | 1/11 [00:01<00:11,  0.87it/s, v_num=0]train_loss:  tensor(406.1912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(377.8139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  27%|██▋       | 3/11 [00:02<00:07,  1.05it/s, v_num=0]train_loss:  tensor(375.4757, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  36%|███▋      | 4/11 [00:03<00:06,  1.09it/s, v_num=0]train_loss:  tensor(359.1149, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  45%|████▌     | 5/11 [00:04<00:05,  1.13it/s, v_num=0]train_loss:  tensor(308.3787, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(328.4678, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(339.9094, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=0]train_loss:  tensor(354.5342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=0]train_loss:  tensor(356.5659, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 115:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=0]train_loss:  tensor(372.4018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(355.0747, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:   9%|▉         | 1/11 [00:01<00:12,  0.77it/s, v_num=0]train_loss:  tensor(333.4344, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  18%|█▊        | 2/11 [00:02<00:09,  0.90it/s, v_num=0]train_loss:  tensor(335.3464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  27%|██▋       | 3/11 [00:03<00:08,  0.99it/s, v_num=0]train_loss:  tensor(345.2107, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  36%|███▋      | 4/11 [00:03<00:06,  1.06it/s, v_num=0]train_loss:  tensor(325.1450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(328.0844, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(325.0626, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(337.3170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(323.1750, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(329.7110, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 116:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(354.6099, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(338.8858, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(321.5801, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(322.2548, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(343.8531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(345.3613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(327.1743, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(326.9958, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(319.2587, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(339.4656, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(314.1402, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 117:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(338.8013, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(326.8413, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:   9%|▉         | 1/11 [00:01<00:12,  0.78it/s, v_num=0]train_loss:  tensor(317.6936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  18%|█▊        | 2/11 [00:02<00:09,  0.96it/s, v_num=0]train_loss:  tensor(308.6556, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  27%|██▋       | 3/11 [00:03<00:08,  0.98it/s, v_num=0]train_loss:  tensor(326.0664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(334.9765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(318.0669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=0]train_loss:  tensor(317.2838, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(338.1179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(353.3895, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(337.9003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 118:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(322.6922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(342.0203, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(318.2041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(337.3766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(329.7577, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(334.8802, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(335.5991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(328.9330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(333.7817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(314.9214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(325.4608, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 119:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(323.5818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(325.8296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=0]train_loss:  tensor(318.6448, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(351.9461, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(328.8875, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(320.8421, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(332.9117, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(308.4435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(334.9519, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(316.5264, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(303.3904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 120:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(352.8972, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(336.1445, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(315.5564, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(319.7744, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(346.2962, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(326.0083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(326.2257, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(314.5307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(305.7097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(325.8369, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(328.5854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 121:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(344.4553, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(356.4650, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(329.7783, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(330.9700, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(372.8321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(358.8987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(342.4286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(344.5412, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(341.3064, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(300.3499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=0]train_loss:  tensor(317.9964, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 122:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(348.1487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(350.4048, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(360.4150, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(318.1366, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(308.6806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(333.3600, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(351.4957, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(340.9034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(326.2025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=0]train_loss:  tensor(313.3274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(320.5791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 123:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(325.0450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(350.4322, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(339.6383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(338.5234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(335.9451, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(332.0881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(290.1951, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(331.0558, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(342.9459, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(321.9734, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(309.7559, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 124:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=0]train_loss:  tensor(306.4073, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(308.7422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=0]train_loss:  tensor(323.5996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(336.6236, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(323.7906, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(312.5648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(313.3052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(338.8015, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(302.3664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(311.5865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(329.2087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 125:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(322.9706, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(310.1490, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=0]train_loss:  tensor(337.8384, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=0]train_loss:  tensor(316.1688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(313.3741, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(313.1450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(311.8131, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(295.4095, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(315.7263, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(324.8855, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(337.3698, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 126:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(310.0080, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(324.2318, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(312.9723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(320.1353, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(298.1173, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(315.3785, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(309.4114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(325.3306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(295.4227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(305.5715, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(348.3885, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 127:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(313.9424, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(305.4444, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=0]train_loss:  tensor(328.7350, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(302.6271, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(314.1397, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(306.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(310.1982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(311.0174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(305.1393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(317.5722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(314.1415, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 128:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(337.2258, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(315.8371, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(324.7925, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(311.4806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(322.0532, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(318.2101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(313.3131, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(300.6254, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(305.3864, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(310.7909, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(295.5408, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 129:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(297.0853, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(292.3410, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(300.3670, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(289.4581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(337.8854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(300.1800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(305.8901, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(316.4802, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(318.5085, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(315.9365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(303.2727, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 130:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(324.7672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(321.7973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(358.8085, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(343.0884, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(362.1007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(337.7170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(329.4739, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(305.6994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(321.0063, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(305.1461, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(311.7190, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 131:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(349.7841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(330.8441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(320.7480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(292.0300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=0]train_loss:  tensor(310.1205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=0]train_loss:  tensor(335.0882, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=0]train_loss:  tensor(342.0551, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(314.8060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(304.2672, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(298.8114, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  82%|████████▏ | 9/11 [00:07<00:01,  1.29it/s, v_num=0]train_loss:  tensor(326.8541, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 132:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(334.7330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(313.9657, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=0]train_loss:  tensor(302.3098, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(299.3778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(290.9667, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(322.8273, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(318.7003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(307.2383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(302.8762, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(301.1873, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(323.7533, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 133:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(307.3330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(282.3797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(290.2484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(302.2370, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(317.1103, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(316.6997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=0]train_loss:  tensor(304.8226, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(309.2863, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(301.7173, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(303.3342, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(297.0332, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 134:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(315.4267, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(311.1929, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(306.9003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(304.8885, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(317.7049, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(297.5343, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(294.0320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  55%|█████▍    | 6/11 [00:04<00:03,  1.25it/s, v_num=0]train_loss:  tensor(299.0034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(299.4476, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(287.3377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(295.5115, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 135:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(310.4281, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(316.9047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(306.4449, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=0]train_loss:  tensor(303.8007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, v_num=0]train_loss:  tensor(299.2624, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(312.1608, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  45%|████▌     | 5/11 [00:04<00:05,  1.13it/s, v_num=0]train_loss:  tensor(287.7031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  55%|█████▍    | 6/11 [00:05<00:04,  1.16it/s, v_num=0]train_loss:  tensor(304.2377, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  64%|██████▎   | 7/11 [00:05<00:03,  1.18it/s, v_num=0]train_loss:  tensor(295.8197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=0]train_loss:  tensor(297.4917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  82%|████████▏ | 9/11 [00:07<00:01,  1.13it/s, v_num=0]train_loss:  tensor(297.5857, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 136:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=0]train_loss:  tensor(297.1192, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(301.4313, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(294.2724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(305.7993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(280.7654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(296.8124, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(297.0516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(309.0156, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(305.6286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(301.8644, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(299.5832, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 137:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(312.2506, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(315.6648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(301.7238, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  18%|█▊        | 2/11 [00:01<00:08,  1.08it/s, v_num=0]train_loss:  tensor(289.3447, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(307.0922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(276.0894, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=0]train_loss:  tensor(282.2071, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(294.6699, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(309.2303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(298.3813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(302.5627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 138:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(300.8658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(289.4686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(300.9424, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(313.2479, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(351.9176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(336.7641, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(339.8422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(298.4160, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(311.9001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(306.0078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(303.2323, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 139:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(310.5034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(320.0248, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(326.8813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=0]train_loss:  tensor(308.0355, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  27%|██▋       | 3/11 [00:02<00:07,  1.14it/s, v_num=0]train_loss:  tensor(307.6520, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(296.4406, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(296.2393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(309.3658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(306.6996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(312.2605, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(302.8066, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 140:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(303.7278, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(309.4312, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(302.0594, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(281.6723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(293.6910, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(304.0831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(297.3896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(292.4351, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(284.2973, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(289.1459, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(303.2481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 141:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(278.6422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(295.2197, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(283.4509, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=0]train_loss:  tensor(293.4320, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, v_num=0]train_loss:  tensor(280.8575, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(283.5581, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  45%|████▌     | 5/11 [00:04<00:05,  1.19it/s, v_num=0]train_loss:  tensor(295.9663, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  55%|█████▍    | 6/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(301.2029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(292.5815, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(297.2142, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(282.3591, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 142:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(273.3154, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(294.0988, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:   9%|▉         | 1/11 [00:00<00:09,  1.10it/s, v_num=0]train_loss:  tensor(290.7256, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=0]train_loss:  tensor(297.7339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(283.1058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(285.6896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(299.5795, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(278.5466, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(282.3046, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(290.0024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(282.3222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 143:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(279.8363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 0:  27%|██▋       | 3/11 [1:35:32<4:14:47,  0.00it/s, v_num=0]\n",
      "train_loss:  tensor(276.0686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(276.5907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  18%|█▊        | 2/11 [00:02<00:09,  0.98it/s, v_num=0]train_loss:  tensor(293.9817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(295.5820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(290.2022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(285.4241, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(287.8967, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(286.9722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(285.2141, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(275.0955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 144:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(276.7725, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(282.9027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:   9%|▉         | 1/11 [00:01<00:11,  0.84it/s, v_num=0]train_loss:  tensor(290.2272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  18%|█▊        | 2/11 [00:01<00:08,  1.03it/s, v_num=0]train_loss:  tensor(289.0176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(285.5797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(259.5965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(286.6299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(284.9250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(285.6786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(275.9566, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(283.1927, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 145:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(270.8326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(280.0685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=0]train_loss:  tensor(276.8126, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(268.7516, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(293.3253, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(271.8455, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(291.1011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(283.1462, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(282.8568, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(281.6260, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(297.6807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 146:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(293.9766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(302.2133, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(288.4614, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  18%|█▊        | 2/11 [00:02<00:09,  0.90it/s, v_num=0]train_loss:  tensor(296.7881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=0]train_loss:  tensor(301.4483, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(295.8163, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(298.6317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(287.9125, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(288.4985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(282.1105, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(285.3300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 147:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(258.2451, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(269.1313, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(269.7815, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(285.2863, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(295.7179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(279.6815, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(299.2300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(279.9360, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(288.2952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(269.3713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  82%|████████▏ | 9/11 [00:06<00:01,  1.30it/s, v_num=0]train_loss:  tensor(276.6368, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 148:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(274.3946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(295.2696, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(298.5866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  18%|█▊        | 2/11 [00:02<00:09,  0.91it/s, v_num=0]train_loss:  tensor(294.4837, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=0]train_loss:  tensor(280.8220, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(262.0326, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(271.4464, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(277.5806, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(276.3248, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(282.9720, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(273.9667, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 149:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(287.7959, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(268.2144, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(285.9990, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(286.5524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(272.2721, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  36%|███▋      | 4/11 [00:03<00:05,  1.23it/s, v_num=0]train_loss:  tensor(276.2998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(285.2803, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(274.8297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(294.2888, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(263.1293, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(268.8163, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 150:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(287.6304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(264.2866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(281.7336, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  18%|█▊        | 2/11 [00:01<00:08,  1.12it/s, v_num=0]train_loss:  tensor(277.2097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(274.0068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(276.7839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(280.2330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(276.3426, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(270.0997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(269.0120, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(268.5896, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 151:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(268.2175, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(276.9855, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=0]train_loss:  tensor(287.1775, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=0]train_loss:  tensor(254.7222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(272.1611, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(277.5839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  45%|████▌     | 5/11 [00:03<00:04,  1.25it/s, v_num=0]train_loss:  tensor(263.7883, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(263.8622, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(259.5830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(276.7869, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(268.5547, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 152:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(283.7314, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(264.3288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(279.0222, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(280.2170, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(292.0028, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  36%|███▋      | 4/11 [00:03<00:05,  1.24it/s, v_num=0]train_loss:  tensor(292.9689, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  45%|████▌     | 5/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(299.0627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(300.3022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(297.7458, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(281.4335, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(289.7589, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 153:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(254.3375, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(288.3651, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(273.5333, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, v_num=0]train_loss:  tensor(260.4416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(274.8257, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, v_num=0]train_loss:  tensor(271.6455, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(272.4568, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=0]train_loss:  tensor(280.7314, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(272.8098, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(280.8542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(276.7225, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 154:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(273.7839, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(278.7224, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(264.5078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(260.0924, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(269.4252, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(274.3450, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(272.7919, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(268.4803, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(261.3948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(273.9383, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(277.9830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 155:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(269.6510, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(263.1494, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:   9%|▉         | 1/11 [00:01<00:10,  1.00it/s, v_num=0]train_loss:  tensor(260.0219, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, v_num=0]train_loss:  tensor(272.2713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, v_num=0]train_loss:  tensor(269.9918, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  36%|███▋      | 4/11 [00:03<00:05,  1.17it/s, v_num=0]train_loss:  tensor(275.0495, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=0]train_loss:  tensor(261.3606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(269.7958, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(257.0328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(273.4545, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(263.9688, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 156:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(274.8500, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(279.8713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(273.0756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(260.6041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=0]train_loss:  tensor(272.4769, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(275.2359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(276.2669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(268.1440, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(288.1621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(286.5012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(276.8841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 157:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(271.1868, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(277.2662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(273.4538, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(276.4283, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(284.8555, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(260.6864, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(275.6428, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(270.4952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(263.5722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(255.4533, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(274.1662, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 158:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(260.6332, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(267.6835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(259.4716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  18%|█▊        | 2/11 [00:02<00:09,  0.99it/s, v_num=0]train_loss:  tensor(267.8489, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, v_num=0]train_loss:  tensor(263.4087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(266.7744, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, v_num=0]train_loss:  tensor(276.8043, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=0]train_loss:  tensor(267.3542, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(266.1045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(276.8336, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(260.3505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 159:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(248.4486, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(259.4469, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(247.0087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(266.9537, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(264.8524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(259.5408, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(273.6805, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(264.3617, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(263.6948, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(272.9336, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(252.6918, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 160:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(269.6824, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(266.9677, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=0]train_loss:  tensor(261.9497, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=0]train_loss:  tensor(272.0986, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(253.4565, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=0]train_loss:  tensor(261.7875, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(255.4865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(256.5818, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(263.6479, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(269.2335, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(263.1565, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 161:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(231.0652, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(254.3669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=0]train_loss:  tensor(257.4526, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  18%|█▊        | 2/11 [00:01<00:08,  1.09it/s, v_num=0]train_loss:  tensor(252.8756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(257.8362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(251.4243, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(265.5813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(261.1034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(277.2045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(263.5429, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(251.5658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 162:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=0]train_loss:  tensor(253.1454, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(246.9441, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(274.6403, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  18%|█▊        | 2/11 [00:01<00:07,  1.28it/s, v_num=0]train_loss:  tensor(271.5388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(284.9940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(283.6805, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(269.0872, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(271.0991, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(285.7923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(271.9614, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, v_num=0]train_loss:  tensor(268.3347, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 163:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(245.2775, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(268.6270, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:   9%|▉         | 1/11 [00:01<00:11,  0.83it/s, v_num=0]train_loss:  tensor(275.5963, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  18%|█▊        | 2/11 [00:01<00:08,  1.01it/s, v_num=0]train_loss:  tensor(277.6273, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(252.9630, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=0]train_loss:  tensor(255.3110, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  45%|████▌     | 5/11 [00:04<00:05,  1.14it/s, v_num=0]train_loss:  tensor(246.0574, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, v_num=0]train_loss:  tensor(256.1285, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  64%|██████▎   | 7/11 [00:05<00:03,  1.19it/s, v_num=0]train_loss:  tensor(259.9752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(260.2860, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(251.8845, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 164:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(275.2211, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(276.5106, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(269.5301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(262.0076, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=0]train_loss:  tensor(254.1740, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=0]train_loss:  tensor(266.3568, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=0]train_loss:  tensor(253.6143, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(249.5465, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(262.8589, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(270.9570, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(252.3543, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 165:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(250.0904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(260.8102, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=0]train_loss:  tensor(252.9611, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  18%|█▊        | 2/11 [00:01<00:08,  1.10it/s, v_num=0]train_loss:  tensor(261.3496, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(250.2949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(262.2153, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(259.2850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(265.8870, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  64%|██████▎   | 7/11 [00:05<00:03,  1.24it/s, v_num=0]train_loss:  tensor(260.4237, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=0]train_loss:  tensor(271.8460, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=0]train_loss:  tensor(265.5632, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 166:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(250.7771, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(248.7167, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(250.7960, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=0]train_loss:  tensor(269.3966, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(254.8330, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(269.6087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(265.8713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(255.2602, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(260.0757, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(270.0487, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(248.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 167:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(264.2129, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(259.9774, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(275.7658, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=0]train_loss:  tensor(274.4912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(263.7798, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, v_num=0]train_loss:  tensor(255.5865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(245.9912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  55%|█████▍    | 6/11 [00:05<00:04,  1.15it/s, v_num=0]train_loss:  tensor(248.3800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  64%|██████▎   | 7/11 [00:05<00:03,  1.17it/s, v_num=0]train_loss:  tensor(257.6179, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(257.1956, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, v_num=0]train_loss:  tensor(254.8699, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 168:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, v_num=0]train_loss:  tensor(244.7835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(255.4397, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(246.5153, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(253.6067, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(266.6621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(246.0388, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(244.2545, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, v_num=0]train_loss:  tensor(257.9151, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(256.2099, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, v_num=0]train_loss:  tensor(269.5789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(245.9118, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 169:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(255.8536, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(254.4897, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=0]train_loss:  tensor(250.6797, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(252.1212, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(259.7378, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(247.7149, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(256.7681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(251.4949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(244.9274, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(248.1531, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(246.2937, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 170:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(255.4054, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(242.3621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(255.7944, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  18%|█▊        | 2/11 [00:02<00:10,  0.88it/s, v_num=0]train_loss:  tensor(251.7189, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  27%|██▋       | 3/11 [00:03<00:08,  0.99it/s, v_num=0]train_loss:  tensor(248.2610, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  36%|███▋      | 4/11 [00:03<00:06,  1.05it/s, v_num=0]train_loss:  tensor(257.8035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(242.2059, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=0]train_loss:  tensor(251.2889, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(251.6031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(258.2537, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(251.5846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 171:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(232.5247, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(249.9364, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=0]train_loss:  tensor(267.3817, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(256.3299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(257.3745, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(254.4742, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(261.2203, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(253.6791, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(258.5134, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(272.0574, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(276.3432, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 172:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(265.4512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(257.0698, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(259.7477, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(248.0828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=0]train_loss:  tensor(253.0907, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=0]train_loss:  tensor(256.6347, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(255.7357, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(269.4923, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(254.5110, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(240.2462, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(261.5482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 173:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=0]train_loss:  tensor(243.0890, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(242.7966, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=0]train_loss:  tensor(258.2491, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(249.1769, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(244.6997, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(260.1393, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  45%|████▌     | 5/11 [00:03<00:04,  1.25it/s, v_num=0]train_loss:  tensor(246.3473, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(249.4495, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(269.6021, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, v_num=0]train_loss:  tensor(242.2292, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=0]train_loss:  tensor(258.0067, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 174:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=0]train_loss:  tensor(252.9302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(243.7980, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:   9%|▉         | 1/11 [00:00<00:08,  1.19it/s, v_num=0]train_loss:  tensor(258.2719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=0]train_loss:  tensor(249.8286, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=0]train_loss:  tensor(242.1006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(258.6713, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=0]train_loss:  tensor(250.6480, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(243.1237, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(239.6994, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(248.8512, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(229.4847, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 175:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(257.3774, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(246.3033, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(232.6411, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  18%|█▊        | 2/11 [00:02<00:10,  0.90it/s, v_num=0]train_loss:  tensor(256.8663, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  27%|██▋       | 3/11 [00:02<00:07,  1.00it/s, v_num=0]train_loss:  tensor(245.0771, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(251.2831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  45%|████▌     | 5/11 [00:04<00:05,  1.11it/s, v_num=0]train_loss:  tensor(247.6088, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(234.3158, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(250.8078, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(255.1083, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(250.5833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 176:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(260.9194, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(255.7117, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=0]train_loss:  tensor(236.1291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(248.5569, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(233.5221, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(254.9587, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(235.8186, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(247.1508, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(254.1502, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(265.6224, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(273.7242, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 177:  91%|█████████ | 10/11 [00:08<00:00,  1.24it/s, v_num=0]train_loss:  tensor(268.0062, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(263.0483, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=0]train_loss:  tensor(244.3246, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(254.7847, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=0]train_loss:  tensor(267.0719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(266.9996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(282.0534, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  55%|█████▍    | 6/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(275.9496, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(241.5309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(248.4770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(248.8505, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 178:  91%|█████████ | 10/11 [00:07<00:00,  1.26it/s, v_num=0]train_loss:  tensor(255.2820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(259.9461, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:   9%|▉         | 1/11 [00:00<00:08,  1.21it/s, v_num=0]train_loss:  tensor(252.6654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  18%|█▊        | 2/11 [00:01<00:07,  1.19it/s, v_num=0]train_loss:  tensor(242.8340, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(258.6353, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, v_num=0]train_loss:  tensor(253.4327, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, v_num=0]train_loss:  tensor(265.6227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, v_num=0]train_loss:  tensor(261.5024, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  64%|██████▎   | 7/11 [00:05<00:03,  1.20it/s, v_num=0]train_loss:  tensor(242.3484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, v_num=0]train_loss:  tensor(247.8360, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  82%|████████▏ | 9/11 [00:07<00:01,  1.22it/s, v_num=0]train_loss:  tensor(247.3950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 179:  91%|█████████ | 10/11 [00:08<00:00,  1.23it/s, v_num=0]train_loss:  tensor(259.5209, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(246.1100, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(241.2471, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  18%|█▊        | 2/11 [00:01<00:06,  1.30it/s, v_num=0]train_loss:  tensor(243.2916, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(252.2503, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(242.8500, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=0]train_loss:  tensor(241.4420, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  55%|█████▍    | 6/11 [00:04<00:03,  1.28it/s, v_num=0]train_loss:  tensor(245.1294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(232.9352, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(257.1478, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(252.8746, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 180:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(249.0522, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(245.6261, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:   9%|▉         | 1/11 [00:00<00:08,  1.25it/s, v_num=0]train_loss:  tensor(241.0845, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  18%|█▊        | 2/11 [00:01<00:08,  1.10it/s, v_num=0]train_loss:  tensor(237.4683, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=0]train_loss:  tensor(244.9113, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  36%|███▋      | 4/11 [00:03<00:05,  1.19it/s, v_num=0]train_loss:  tensor(251.5087, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  45%|████▌     | 5/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(244.2109, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(245.0589, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=0]train_loss:  tensor(243.6012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(249.5799, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(241.7943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 181:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, v_num=0]train_loss:  tensor(258.2996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(246.6082, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:   9%|▉         | 1/11 [00:00<00:09,  1.11it/s, v_num=0]train_loss:  tensor(236.0319, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=0]train_loss:  tensor(243.0289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=0]train_loss:  tensor(238.9953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  36%|███▋      | 4/11 [00:03<00:06,  1.08it/s, v_num=0]train_loss:  tensor(241.6321, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(251.7116, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(234.3104, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(243.9398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=0]train_loss:  tensor(236.7878, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(241.6950, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 182:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(261.9524, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(237.1214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=0]train_loss:  tensor(246.1922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=0]train_loss:  tensor(249.5971, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(244.9509, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(257.8874, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(236.9008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(233.1003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  64%|██████▎   | 7/11 [00:05<00:03,  1.27it/s, v_num=0]train_loss:  tensor(234.1312, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(222.8435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(246.9339, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 183:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(250.3396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(239.7363, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(242.3091, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  18%|█▊        | 2/11 [00:01<00:08,  1.11it/s, v_num=0]train_loss:  tensor(242.6781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  27%|██▋       | 3/11 [00:02<00:06,  1.17it/s, v_num=0]train_loss:  tensor(249.0137, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(237.4830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(237.3522, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  55%|█████▍    | 6/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(254.1248, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=0]train_loss:  tensor(235.1446, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(234.5685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=0]train_loss:  tensor(232.7225, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 184:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(226.2265, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(244.1532, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(243.5493, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, v_num=0]train_loss:  tensor(228.6996, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  27%|██▋       | 3/11 [00:03<00:08,  0.97it/s, v_num=0]train_loss:  tensor(243.4398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  36%|███▋      | 4/11 [00:03<00:06,  1.03it/s, v_num=0]train_loss:  tensor(241.5484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  45%|████▌     | 5/11 [00:04<00:05,  1.08it/s, v_num=0]train_loss:  tensor(235.3014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  55%|█████▍    | 6/11 [00:05<00:04,  1.11it/s, v_num=0]train_loss:  tensor(230.4822, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=0]train_loss:  tensor(248.5650, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  73%|███████▎  | 8/11 [00:07<00:02,  1.14it/s, v_num=0]train_loss:  tensor(232.6656, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(227.6506, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 185:  91%|█████████ | 10/11 [00:08<00:00,  1.17it/s, v_num=0]train_loss:  tensor(243.0965, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(229.7301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(230.8353, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=0]train_loss:  tensor(230.8913, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=0]train_loss:  tensor(226.9245, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(242.4434, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  45%|████▌     | 5/11 [00:04<00:05,  1.20it/s, v_num=0]train_loss:  tensor(240.6687, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(247.9096, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(234.1416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  73%|███████▎  | 8/11 [00:06<00:02,  1.24it/s, v_num=0]train_loss:  tensor(242.4946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  82%|████████▏ | 9/11 [00:07<00:01,  1.23it/s, v_num=0]train_loss:  tensor(248.3288, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 186:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(225.5250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(234.9220, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(244.0934, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(239.4621, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=0]train_loss:  tensor(258.3800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=0]train_loss:  tensor(251.2264, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  45%|████▌     | 5/11 [00:03<00:04,  1.28it/s, v_num=0]train_loss:  tensor(251.2346, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=0]train_loss:  tensor(266.0119, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=0]train_loss:  tensor(256.9809, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  73%|███████▎  | 8/11 [00:06<00:02,  1.29it/s, v_num=0]train_loss:  tensor(233.3185, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  82%|████████▏ | 9/11 [00:06<00:01,  1.29it/s, v_num=0]train_loss:  tensor(236.0436, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 187:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=0]train_loss:  tensor(236.3939, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(239.2481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:   9%|▉         | 1/11 [00:01<00:14,  0.70it/s, v_num=0]train_loss:  tensor(241.6101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  18%|█▊        | 2/11 [00:02<00:10,  0.89it/s, v_num=0]train_loss:  tensor(244.4432, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  27%|██▋       | 3/11 [00:03<00:08,  0.99it/s, v_num=0]train_loss:  tensor(252.0205, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  36%|███▋      | 4/11 [00:03<00:06,  1.06it/s, v_num=0]train_loss:  tensor(248.0148, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  45%|████▌     | 5/11 [00:04<00:05,  1.09it/s, v_num=0]train_loss:  tensor(247.1961, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(232.6304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(233.1606, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(240.2661, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(243.3963, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 188:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(248.4871, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(243.1108, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(243.6225, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, v_num=0]train_loss:  tensor(230.2208, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, v_num=0]train_loss:  tensor(236.7813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, v_num=0]train_loss:  tensor(239.7767, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, v_num=0]train_loss:  tensor(223.4422, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  55%|█████▍    | 6/11 [00:05<00:04,  1.10it/s, v_num=0]train_loss:  tensor(236.5398, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  64%|██████▎   | 7/11 [00:06<00:03,  1.13it/s, v_num=0]train_loss:  tensor(245.4800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  73%|███████▎  | 8/11 [00:07<00:02,  1.13it/s, v_num=0]train_loss:  tensor(236.1835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  82%|████████▏ | 9/11 [00:07<00:01,  1.15it/s, v_num=0]train_loss:  tensor(235.7598, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 189:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=0]train_loss:  tensor(226.3178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(247.8612, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=0]train_loss:  tensor(220.8930, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=0]train_loss:  tensor(230.0513, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(219.0475, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(245.7978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(240.1949, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(239.3250, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(232.3266, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(230.6481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(229.9643, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 190:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(232.4489, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(247.1931, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=0]train_loss:  tensor(228.0522, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  18%|█▊        | 2/11 [00:01<00:07,  1.16it/s, v_num=0]train_loss:  tensor(231.1408, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  27%|██▋       | 3/11 [00:02<00:06,  1.22it/s, v_num=0]train_loss:  tensor(225.8722, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  36%|███▋      | 4/11 [00:03<00:05,  1.25it/s, v_num=0]train_loss:  tensor(240.6506, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(230.3386, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=0]train_loss:  tensor(231.4823, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(221.8627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  73%|███████▎  | 8/11 [00:06<00:02,  1.27it/s, v_num=0]train_loss:  tensor(227.6976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(230.5868, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 191:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(237.7251, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(222.7162, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=0]train_loss:  tensor(229.9485, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(235.4717, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=0]train_loss:  tensor(222.3385, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  36%|███▋      | 4/11 [00:03<00:05,  1.20it/s, v_num=0]train_loss:  tensor(247.0264, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  45%|████▌     | 5/11 [00:04<00:05,  1.12it/s, v_num=0]train_loss:  tensor(234.5291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(239.3613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(227.7999, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  73%|███████▎  | 8/11 [00:06<00:02,  1.15it/s, v_num=0]train_loss:  tensor(230.2985, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  82%|████████▏ | 9/11 [00:07<00:01,  1.16it/s, v_num=0]train_loss:  tensor(226.1275, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 192:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(222.2176, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(238.3157, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:   9%|▉         | 1/11 [00:00<00:09,  1.01it/s, v_num=0]train_loss:  tensor(247.6020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(233.9940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(252.2482, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=0]train_loss:  tensor(285.4753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  45%|████▌     | 5/11 [00:04<00:04,  1.20it/s, v_num=0]train_loss:  tensor(310.5587, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=0]train_loss:  tensor(335.7345, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(287.1724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(244.1063, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(254.7439, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 193:  91%|█████████ | 10/11 [00:07<00:00,  1.25it/s, v_num=0]train_loss:  tensor(264.3379, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(258.6020, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:   9%|▉         | 1/11 [00:00<00:08,  1.22it/s, v_num=0]train_loss:  tensor(242.8251, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=0]train_loss:  tensor(250.0648, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  27%|██▋       | 3/11 [00:02<00:06,  1.21it/s, v_num=0]train_loss:  tensor(251.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=0]train_loss:  tensor(246.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  45%|████▌     | 5/11 [00:04<00:04,  1.24it/s, v_num=0]train_loss:  tensor(230.6022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  55%|█████▍    | 6/11 [00:04<00:04,  1.21it/s, v_num=0]train_loss:  tensor(259.1689, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  64%|██████▎   | 7/11 [00:05<00:03,  1.22it/s, v_num=0]train_loss:  tensor(239.0599, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  73%|███████▎  | 8/11 [00:06<00:02,  1.23it/s, v_num=0]train_loss:  tensor(241.4416, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  82%|████████▏ | 9/11 [00:07<00:01,  1.24it/s, v_num=0]train_loss:  tensor(247.9899, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 194:  91%|█████████ | 10/11 [00:08<00:00,  1.25it/s, v_num=0]train_loss:  tensor(244.3158, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(256.0384, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:   9%|▉         | 1/11 [00:01<00:12,  0.83it/s, v_num=0]train_loss:  tensor(233.1842, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  18%|█▊        | 2/11 [00:02<00:09,  0.98it/s, v_num=0]train_loss:  tensor(237.7709, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=0]train_loss:  tensor(241.7397, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  36%|███▋      | 4/11 [00:03<00:06,  1.12it/s, v_num=0]train_loss:  tensor(244.0101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, v_num=0]train_loss:  tensor(229.0200, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(230.8331, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=0]train_loss:  tensor(240.4097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(228.2649, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(232.0504, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 195:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(253.4717, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(229.4753, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:   9%|▉         | 1/11 [00:00<00:09,  1.00it/s, v_num=0]train_loss:  tensor(238.0059, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  18%|█▊        | 2/11 [00:01<00:07,  1.13it/s, v_num=0]train_loss:  tensor(215.3943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  27%|██▋       | 3/11 [00:02<00:06,  1.15it/s, v_num=0]train_loss:  tensor(240.1703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  36%|███▋      | 4/11 [00:03<00:06,  1.07it/s, v_num=0]train_loss:  tensor(225.9835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(227.9835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  55%|█████▍    | 6/11 [00:05<00:04,  1.13it/s, v_num=0]train_loss:  tensor(241.2429, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(241.1409, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  73%|███████▎  | 8/11 [00:06<00:02,  1.17it/s, v_num=0]train_loss:  tensor(234.4435, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, v_num=0]train_loss:  tensor(229.9868, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 196:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, v_num=0]train_loss:  tensor(246.6669, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(224.5402, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:   9%|▉         | 1/11 [00:00<00:07,  1.25it/s, v_num=0]train_loss:  tensor(232.0216, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=0]train_loss:  tensor(228.9702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=0]train_loss:  tensor(235.7582, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  36%|███▋      | 4/11 [00:03<00:05,  1.26it/s, v_num=0]train_loss:  tensor(231.2778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  45%|████▌     | 5/11 [00:03<00:04,  1.26it/s, v_num=0]train_loss:  tensor(225.9891, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  55%|█████▍    | 6/11 [00:04<00:03,  1.27it/s, v_num=0]train_loss:  tensor(237.3768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  64%|██████▎   | 7/11 [00:05<00:03,  1.28it/s, v_num=0]train_loss:  tensor(239.2683, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  73%|███████▎  | 8/11 [00:06<00:02,  1.28it/s, v_num=0]train_loss:  tensor(227.9234, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=0]train_loss:  tensor(224.3351, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 197:  91%|█████████ | 10/11 [00:07<00:00,  1.28it/s, v_num=0]train_loss:  tensor(230.3865, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(224.8100, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:   9%|▉         | 1/11 [00:00<00:08,  1.13it/s, v_num=0]train_loss:  tensor(231.2466, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=0]train_loss:  tensor(228.2362, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  27%|██▋       | 3/11 [00:02<00:06,  1.20it/s, v_num=0]train_loss:  tensor(225.5731, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=0]train_loss:  tensor(216.1279, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=0]train_loss:  tensor(228.1677, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  55%|█████▍    | 6/11 [00:04<00:04,  1.25it/s, v_num=0]train_loss:  tensor(226.8105, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  64%|██████▎   | 7/11 [00:05<00:03,  1.26it/s, v_num=0]train_loss:  tensor(246.9237, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  73%|███████▎  | 8/11 [00:06<00:02,  1.26it/s, v_num=0]train_loss:  tensor(221.7705, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=0]train_loss:  tensor(226.6886, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 198:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=0]train_loss:  tensor(230.2089, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:   0%|          | 0/11 [00:00<?, ?it/s, v_num=0]         train_loss:  tensor(222.7254, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=0]train_loss:  tensor(224.0317, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  18%|█▊        | 2/11 [00:02<00:09,  0.91it/s, v_num=0]train_loss:  tensor(223.7091, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  27%|██▋       | 3/11 [00:02<00:07,  1.01it/s, v_num=0]train_loss:  tensor(230.3931, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  36%|███▋      | 4/11 [00:03<00:06,  1.06it/s, v_num=0]train_loss:  tensor(234.3895, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  45%|████▌     | 5/11 [00:04<00:05,  1.10it/s, v_num=0]train_loss:  tensor(235.8654, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, v_num=0]train_loss:  tensor(235.5277, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  64%|██████▎   | 7/11 [00:06<00:03,  1.16it/s, v_num=0]train_loss:  tensor(222.1365, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  73%|███████▎  | 8/11 [00:06<00:02,  1.16it/s, v_num=0]train_loss:  tensor(225.0569, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, v_num=0]train_loss:  tensor(216.7137, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199:  91%|█████████ | 10/11 [00:08<00:00,  1.18it/s, v_num=0]train_loss:  tensor(222.0650, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 199: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 11/11 [00:10<00:00,  1.09it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing model\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 13.83it/s] \n"
     ]
    }
   ],
   "source": [
    "# they all look about the same, so let's just use 128\n",
    "latent_dim = 128\n",
    "model_ld, result_ld = train(latent_dim, max_epochs=200)\n",
    "# Save the model checkpoint. Not strictly necessary because lightning is also saving it, but just to be safe\n",
    "checkpoint_filename = Path(CHECKPOINT_PATH) / f\"final_model_dim_{latent_dim}\" / \"final_checkpoint.ckpt\"\n",
    "torch.save(model_ld.state_dict(), checkpoint_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting preset from latent representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feed_Forward(nn.Module):\n",
    "    def __init__(self, latent_dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 88),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(88, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim: int,\n",
    "        num_classes: int,\n",
    "        encoder_model_checkpoint: str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters of autoencoder\n",
    "        self.save_hyperparameters()\n",
    "        # Load autoencoder and get the encoder only\n",
    "        self.encoder = Autoencoder.load_from_checkpoint(encoder_model_checkpoint).encoder\n",
    "        # Put the encoder in evaluation mode\n",
    "        self.encoder.eval()\n",
    "        self.feed_forward = Feed_Forward(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function takes in an image and returns the reconstructed image.\"\"\"\n",
    "        z = self.encoder(x)\n",
    "        y_hat = self.feed_forward(z)\n",
    "        return y_hat\n",
    "\n",
    "    def _get_reconstruction_loss(self, batch):\n",
    "        \"\"\"Given a batch of images, this function returns the reconstruction loss (MSE in our case).\"\"\"\n",
    "        x, y = batch  # We do not need the labels\n",
    "        y_hat = self.forward(x)\n",
    "        # print('x.shape: ', y.shape)\n",
    "        # print('x_hat.shape: ', y_hat.shape)\n",
    "        # Take the first value of y as the only label for prediction\n",
    "        y = y[:, 0].unsqueeze(1)\n",
    "        y = y.float()\n",
    "        y_hat = y_hat.float()\n",
    "        print('y.shape: ', y.shape)\n",
    "        print('y_hat.shape: ', y_hat.shape)\n",
    "        loss = F.mse_loss(y, y_hat)\n",
    "        print('loss: ', loss) # 256, 88\n",
    "        # loss = loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
    "        r2 = R2Score()\n",
    "        r2.update(y_hat, y)\n",
    "        r2_score = r2.compute().item()\n",
    "        print('r2_score: ', r2_score)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        # Using a scheduler is optional but can be helpful.\n",
    "        # The scheduler reduces the LR if the validation performance hasn't improved for the last N epochs\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=20, min_lr=5e-5)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"test_loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through data in dataloader,\n",
    "# For each data point, pass it through the decoder, and then pass the output through our simple feedforward network\n",
    "def train_classifier(latent_dim, num_classes, max_epochs=50, encoder_model_checkpoint=None):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    print('creating trainer')\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, \"classifier_%i\" % latent_dim),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    print(\"creating model\")\n",
    "    model = Classifier(latent_dim=latent_dim, num_classes=num_classes, encoder_model_checkpoint=encoder_model_checkpoint)\n",
    "    print(\"training model\")\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    # Test best model on validation and test set\n",
    "    print(\"testing model\")\n",
    "    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "    # test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    # result = {\"test\": test_result, \"val\": val_result}\n",
    "    result = {\"val\": val_result}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type         | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | encoder      | Encoder      | 2.2 M  | eval \n",
      "1 | feed_forward | Feed_Forward | 44.5 K | train\n",
      "------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.978     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "14        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating trainer\n",
      "creating model\n",
      "training model\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_11292\\986052091.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset_name = preset[0]\n",
      "C:\\Users\\jayor\\AppData\\Local\\Temp\\ipykernel_11292\\986052091.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preset = torch.tensor(preset[1:-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.4556, device='cuda:0')\n",
      "r2_score:  -5.149169445037842\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 30.61it/s]y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.5457, device='cuda:0')\n",
      "r2_score:  -6.977519989013672\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayor\\miniconda3\\envs\\synth-reconstruct\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\jayor\\miniconda3\\envs\\synth-reconstruct\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.5104, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -5.082150936126709\n",
      "Epoch 0:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -1.200082778930664\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.4399, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -3.74167537689209\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.4531441926956177\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.7758069038391113\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.857743501663208\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.5868080854415894\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.674340009689331\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0742419958114624\n",
      "Epoch 0:  82%|████████▏ | 9/11 [00:05<00:01,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.07072579860687256\n",
      "Epoch 0:  91%|█████████ | 10/11 [00:06<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.1112, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.2510460615158081\n",
      "Epoch 0: 100%|██████████| 11/11 [00:06<00:00,  1.63it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0851, device='cuda:0')\n",
      "r2_score:  -0.14831435680389404\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0739, device='cuda:0')\n",
      "r2_score:  -0.08075952529907227\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.13125860691070557\n",
      "Epoch 1:   9%|▉         | 1/11 [00:00<00:05,  1.75it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.3072699308395386\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:01<00:05,  1.65it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.08850133419036865\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0868, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.032915353775024414\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.019415616989135742\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:03<00:03,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.023189067840576172\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:03<00:03,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.05548501014709473\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:04<00:02,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.024732351303100586\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:04<00:01,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.09019207954406738\n",
      "Epoch 1:  82%|████████▏ | 9/11 [00:05<00:01,  1.62it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.04341292381286621\n",
      "Epoch 1:  91%|█████████ | 10/11 [00:06<00:00,  1.63it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.1029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.10918736457824707\n",
      "Epoch 1: 100%|██████████| 11/11 [00:06<00:00,  1.70it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0750, device='cuda:0')\n",
      "r2_score:  -0.012259125709533691\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0791, device='cuda:0')\n",
      "r2_score:  -0.15588021278381348\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.011072158813476562\n",
      "Epoch 2:   9%|▉         | 1/11 [00:00<00:05,  1.70it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.015076994895935059\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:01<00:05,  1.71it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.009113430976867676\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:01<00:04,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.047702908515930176\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:02<00:04,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.03411591053009033\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:02<00:03,  1.68it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.03364133834838867\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:03<00:02,  1.68it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01063162088394165\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:04<00:02,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.023531198501586914\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:04<00:01,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0778, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.024055123329162598\n",
      "Epoch 2:  82%|████████▏ | 9/11 [00:05<00:01,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0912, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.04385936260223389\n",
      "Epoch 2:  91%|█████████ | 10/11 [00:05<00:00,  1.69it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.008370399475097656\n",
      "Epoch 2: 100%|██████████| 11/11 [00:06<00:00,  1.76it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0740, device='cuda:0')\n",
      "r2_score:  0.0016475915908813477\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0690, device='cuda:0')\n",
      "r2_score:  -0.009263396263122559\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.00810849666595459\n",
      "Epoch 3:   9%|▉         | 1/11 [00:00<00:05,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0956, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.02707982063293457\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:01<00:05,  1.64it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.005246400833129883\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:01<00:04,  1.64it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.009885787963867188\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:02<00:04,  1.66it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.04793095588684082\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:03<00:03,  1.65it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.006944894790649414\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:03<00:03,  1.66it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0856, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.049033403396606445\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:04<00:02,  1.67it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.027341008186340332\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:04<00:01,  1.67it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.004913926124572754\n",
      "Epoch 3:  82%|████████▏ | 9/11 [00:05<00:01,  1.67it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.005254507064819336\n",
      "Epoch 3:  91%|█████████ | 10/11 [00:05<00:00,  1.67it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.019795894622802734\n",
      "Epoch 3: 100%|██████████| 11/11 [00:06<00:00,  1.74it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0744, device='cuda:0')\n",
      "r2_score:  -0.00465703010559082\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0670, device='cuda:0')\n",
      "r2_score:  0.02130335569381714\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.008392095565795898\n",
      "Epoch 4:   9%|▉         | 1/11 [00:00<00:05,  1.69it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.005257546901702881\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:01<00:05,  1.62it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.018502354621887207\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:01<00:04,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.00875091552734375\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:02<00:04,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0009791851043701172\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:03<00:03,  1.63it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0942, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.004661083221435547\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:03<00:03,  1.63it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0856, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.002662181854248047\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:04<00:02,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.018281400203704834\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:05<00:01,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.012369632720947266\n",
      "Epoch 4:  82%|████████▏ | 9/11 [00:05<00:01,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.006128787994384766\n",
      "Epoch 4:  91%|█████████ | 10/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0906, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.010838210582733154\n",
      "Epoch 4: 100%|██████████| 11/11 [00:06<00:00,  1.66it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0740, device='cuda:0')\n",
      "r2_score:  0.0008849501609802246\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0717, device='cuda:0')\n",
      "r2_score:  -0.047829389572143555\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.010772645473480225\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:06,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.023909926414489746\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:01<00:05,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.008570432662963867\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:01<00:04,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0319293737411499\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:02<00:04,  1.62it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.03746175765991211\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:03<00:03,  1.62it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.011301934719085693\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:03<00:03,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.03836417198181152\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:04<00:02,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0890, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0020242929458618164\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:05<00:01,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.013738751411437988\n",
      "Epoch 5:  82%|████████▏ | 9/11 [00:05<00:01,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.018330395221710205\n",
      "Epoch 5:  91%|█████████ | 10/11 [00:06<00:00,  1.59it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.011716246604919434\n",
      "Epoch 5: 100%|██████████| 11/11 [00:06<00:00,  1.65it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0747, device='cuda:0')\n",
      "r2_score:  -0.008492350578308105\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0658, device='cuda:0')\n",
      "r2_score:  0.038587987422943115\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01319819688796997\n",
      "Epoch 6:   9%|▉         | 1/11 [00:00<00:06,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01128089427947998\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:01<00:05,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.001493215560913086\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:01<00:05,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.01327061653137207\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:02<00:04,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.011501312255859375\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:03<00:03,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.016346216201782227\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:03<00:03,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0035486221313476562\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:04<00:02,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.019984066486358643\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:05<00:01,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01942211389541626\n",
      "Epoch 6:  82%|████████▏ | 9/11 [00:05<00:01,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.005753278732299805\n",
      "Epoch 6:  91%|█████████ | 10/11 [00:06<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0904, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.05653643608093262\n",
      "Epoch 6: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0755, device='cuda:0')\n",
      "r2_score:  -0.018848419189453125\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0655, device='cuda:0')\n",
      "r2_score:  0.04243415594100952\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.026827454566955566\n",
      "Epoch 7:   9%|▉         | 1/11 [00:00<00:06,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.009868502616882324\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.014976263046264648\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0764, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01532047986984253\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01630103588104248\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:03<00:03,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.006792426109313965\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:03<00:03,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0904, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.02905404567718506\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:04<00:02,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.015938758850097656\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:05<00:01,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.012256503105163574\n",
      "Epoch 7:  82%|████████▏ | 9/11 [00:05<00:01,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.02189546823501587\n",
      "Epoch 7:  91%|█████████ | 10/11 [00:06<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.031245529651641846\n",
      "Epoch 7: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0753, device='cuda:0')\n",
      "r2_score:  -0.016357898712158203\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0658, device='cuda:0')\n",
      "r2_score:  0.03814828395843506\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.013329565525054932\n",
      "Epoch 8:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.013032317161560059\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.005847156047821045\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.02761983871459961\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.001809835433959961\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.031083762645721436\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:03<00:03,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.010781526565551758\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:04<00:02,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.025715768337249756\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:05<00:01,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0816, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.015180766582489014\n",
      "Epoch 8:  82%|████████▏ | 9/11 [00:05<00:01,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.00664973258972168\n",
      "Epoch 8:  91%|█████████ | 10/11 [00:06<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0891, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.004478096961975098\n",
      "Epoch 8: 100%|██████████| 11/11 [00:06<00:00,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0736, device='cuda:0')\n",
      "r2_score:  0.0066373348236083984\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0697, device='cuda:0')\n",
      "r2_score:  -0.019214153289794922\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01729947328567505\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0830, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.013252496719360352\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0024727582931518555\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:02<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.019684314727783203\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0944, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0126570463180542\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0883, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.008489429950714111\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.00690847635269165\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0858, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.023156940937042236\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.03304862976074219\n",
      "Epoch 9:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01963794231414795\n",
      "Epoch 9:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.049715518951416016\n",
      "Epoch 9: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0772, device='cuda:0')\n",
      "r2_score:  -0.042000532150268555\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0669, device='cuda:0')\n",
      "r2_score:  0.0222509503364563\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]        y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.009980082511901855\n",
      "Epoch 10:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0868, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.026327908039093018\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0035799145698547363\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01874774694442749\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01708012819290161\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03448128700256348\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0875, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.016611576080322266\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.036370277404785156\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.024028897285461426\n",
      "Epoch 10:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.00881338119506836\n",
      "Epoch 10:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0046408772468566895\n",
      "Epoch 10: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0735, device='cuda:0')\n",
      "r2_score:  0.007281661033630371\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0672, device='cuda:0')\n",
      "r2_score:  0.01814901828765869\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03912162780761719\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.042654573917388916\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0038073062896728516\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0924, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.02079904079437256\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.020887672901153564\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.05194211006164551\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03364062309265137\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:04<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0004563331604003906\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:05<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0030399560928344727\n",
      "Epoch 11:  82%|████████▏ | 9/11 [00:06<00:01,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.034862637519836426\n",
      "Epoch 11:  91%|█████████ | 10/11 [00:06<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.015869617462158203\n",
      "Epoch 11: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0739, device='cuda:0')\n",
      "r2_score:  0.002545595169067383\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0675, device='cuda:0')\n",
      "r2_score:  0.013733327388763428\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06170666217803955\n",
      "Epoch 12:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.042800307273864746\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.008385121822357178\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0548136830329895\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0747, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01872330904006958\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.04130584001541138\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03177851438522339\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0835, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.023376047611236572\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.01591557264328003\n",
      "Epoch 12:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.018105387687683105\n",
      "Epoch 12:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.038248538970947266\n",
      "Epoch 12: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0741, device='cuda:0')\n",
      "r2_score:  -6.4849853515625e-05\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0691, device='cuda:0')\n",
      "r2_score:  -0.010460734367370605\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.002434968948364258\n",
      "Epoch 13:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06338107585906982\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08273196220397949\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:02<00:05,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.016600608825683594\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06483352184295654\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.056848227977752686\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.04932665824890137\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0045272111892700195\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:05<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0920, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.029183804988861084\n",
      "Epoch 13:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.023572683334350586\n",
      "Epoch 13:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.040144383907318115\n",
      "Epoch 13: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0740, device='cuda:0')\n",
      "r2_score:  0.0010571479797363281\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0690, device='cuda:0')\n",
      "r2_score:  -0.00826573371887207\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.044582903385162354\n",
      "Epoch 14:   9%|▉         | 1/11 [00:00<00:07,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.05422079563140869\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.00546342134475708\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:02<00:05,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08010727167129517\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.07547038793563843\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.018033862113952637\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0901, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.07872509956359863\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03395599126815796\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.20141100883483887\n",
      "Epoch 14:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.04718732833862305\n",
      "Epoch 14:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.009241878986358643\n",
      "Epoch 14: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0839, device='cuda:0')\n",
      "r2_score:  -0.13185465335845947\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0882, device='cuda:0')\n",
      "r2_score:  -0.28927576541900635\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.17968451976776123\n",
      "Epoch 15:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.011577129364013672\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:01<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06431472301483154\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.029005706310272217\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.09145998954772949\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:03<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.022230982780456543\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:04<00:03,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.02383887767791748\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:04<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.07170617580413818\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0887, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0504680871963501\n",
      "Epoch 15:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0857, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.04989361763000488\n",
      "Epoch 15:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0033866167068481445\n",
      "Epoch 15: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0891, device='cuda:0')\n",
      "r2_score:  -0.20265161991119385\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0725, device='cuda:0')\n",
      "r2_score:  -0.059906840324401855\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.02208644151687622\n",
      "Epoch 16:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.006204128265380859\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.053401172161102295\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.021970272064208984\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.054429054260253906\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0884, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.036563873291015625\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.042420029640197754\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0779, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.025349915027618408\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.02720022201538086\n",
      "Epoch 16:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.03898131847381592\n",
      "Epoch 16:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08044713735580444\n",
      "Epoch 16: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0751, device='cuda:0')\n",
      "r2_score:  -0.013376712799072266\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0676, device='cuda:0')\n",
      "r2_score:  0.012342989444732666\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.05769217014312744\n",
      "Epoch 17:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03296864032745361\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.05684828758239746\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:02<00:05,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.05705881118774414\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.024122536182403564\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:03<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.042761266231536865\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.026478052139282227\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0544852614402771\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08187341690063477\n",
      "Epoch 17:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.009964585304260254\n",
      "Epoch 17:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06636500358581543\n",
      "Epoch 17: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0762, device='cuda:0')\n",
      "r2_score:  -0.02819681167602539\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0757, device='cuda:0')\n",
      "r2_score:  -0.10725677013397217\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0769, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.07826131582260132\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.10048788785934448\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.09391641616821289\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.10451191663742065\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.033754706382751465\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.03721320629119873\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0793, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.04773557186126709\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.008059442043304443\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.0244523286819458\n",
      "Epoch 18:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.09204494953155518\n",
      "Epoch 18:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.028536319732666016\n",
      "Epoch 18: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0815, device='cuda:0')\n",
      "r2_score:  -0.099922776222229\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0692, device='cuda:0')\n",
      "r2_score:  -0.011970043182373047\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.07087141275405884\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.09433799982070923\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0744, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06919622421264648\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0865, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.029422998428344727\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  -0.004245281219482422\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0777, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0656309723854065\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.11278444528579712\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.13203126192092896\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1203453540802002\n",
      "Epoch 19:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06466072797775269\n",
      "Epoch 19:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.038381993770599365\n",
      "Epoch 19: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0778, device='cuda:0')\n",
      "r2_score:  -0.05014598369598389\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0710, device='cuda:0')\n",
      "r2_score:  -0.03722512722015381\n",
      "Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.11449342966079712\n",
      "Epoch 20:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0903, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08918291330337524\n",
      "Epoch 20:  18%|█▊        | 2/11 [00:01<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.13397973775863647\n",
      "Epoch 20:  27%|██▋       | 3/11 [00:02<00:05,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08314990997314453\n",
      "Epoch 20:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.048703789710998535\n",
      "Epoch 20:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.12516766786575317\n",
      "Epoch 20:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.17425990104675293\n",
      "Epoch 20:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1256392002105713\n",
      "Epoch 20:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0686, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.10160785913467407\n",
      "Epoch 20:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0846627950668335\n",
      "Epoch 20:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.05237537622451782\n",
      "Epoch 20: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0783, device='cuda:0')\n",
      "r2_score:  -0.05630028247833252\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0795, device='cuda:0')\n",
      "r2_score:  -0.16236424446105957\n",
      "Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.16339612007141113\n",
      "Epoch 21:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1982390284538269\n",
      "Epoch 21:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1393057107925415\n",
      "Epoch 21:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.14325547218322754\n",
      "Epoch 21:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.10875552892684937\n",
      "Epoch 21:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.08209913969039917\n",
      "Epoch 21:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1333431601524353\n",
      "Epoch 21:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.04805278778076172\n",
      "Epoch 21:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.13539952039718628\n",
      "Epoch 21:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.0590134859085083\n",
      "Epoch 21:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.06676274538040161\n",
      "Epoch 21: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0793, device='cuda:0')\n",
      "r2_score:  -0.07025325298309326\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0747, device='cuda:0')\n",
      "r2_score:  -0.09203159809112549\n",
      "Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.16314464807510376\n",
      "Epoch 22:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.18116694688796997\n",
      "Epoch 22:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.11416971683502197\n",
      "Epoch 22:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0730, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.18005454540252686\n",
      "Epoch 22:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.13274788856506348\n",
      "Epoch 22:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.19378548860549927\n",
      "Epoch 22:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.15833133459091187\n",
      "Epoch 22:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.14489758014678955\n",
      "Epoch 22:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0685, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.16450464725494385\n",
      "Epoch 22:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.16399812698364258\n",
      "Epoch 22:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.13673609495162964\n",
      "Epoch 22: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0845, device='cuda:0')\n",
      "r2_score:  -0.1399073600769043\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0820, device='cuda:0')\n",
      "r2_score:  -0.1991959810256958\n",
      "Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2213348150253296\n",
      "Epoch 23:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.16670799255371094\n",
      "Epoch 23:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1660730242729187\n",
      "Epoch 23:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0728, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2569822669029236\n",
      "Epoch 23:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.12740713357925415\n",
      "Epoch 23:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.20688581466674805\n",
      "Epoch 23:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0716, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2068689465522766\n",
      "Epoch 23:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0607, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2048790454864502\n",
      "Epoch 23:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.20325428247451782\n",
      "Epoch 23:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.19133013486862183\n",
      "Epoch 23:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.20866888761520386\n",
      "Epoch 23: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0910, device='cuda:0')\n",
      "r2_score:  -0.22854793071746826\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0910, device='cuda:0')\n",
      "r2_score:  -0.3301006555557251\n",
      "Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.18281835317611694\n",
      "Epoch 24:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.24119150638580322\n",
      "Epoch 24:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.22397935390472412\n",
      "Epoch 24:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2260650396347046\n",
      "Epoch 24:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.29192203283309937\n",
      "Epoch 24:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2332560420036316\n",
      "Epoch 24:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.19962948560714722\n",
      "Epoch 24:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.1316232681274414\n",
      "Epoch 24:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.18007534742355347\n",
      "Epoch 24:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.12752097845077515\n",
      "Epoch 24:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0764, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.15611541271209717\n",
      "Epoch 24: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0876, device='cuda:0')\n",
      "r2_score:  -0.1827174425125122\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0868, device='cuda:0')\n",
      "r2_score:  -0.2689284086227417\n",
      "Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3009580373764038\n",
      "Epoch 25:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.14045238494873047\n",
      "Epoch 25:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2802286744117737\n",
      "Epoch 25:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.23073720932006836\n",
      "Epoch 25:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.19570928812026978\n",
      "Epoch 25:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2927919030189514\n",
      "Epoch 25:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2881593704223633\n",
      "Epoch 25:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2957056164741516\n",
      "Epoch 25:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.26066261529922485\n",
      "Epoch 25:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0566, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.29717886447906494\n",
      "Epoch 25:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2596263289451599\n",
      "Epoch 25: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0939, device='cuda:0')\n",
      "r2_score:  -0.2674570083618164\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0865, device='cuda:0')\n",
      "r2_score:  -0.2645047903060913\n",
      "Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.20412826538085938\n",
      "Epoch 26:   9%|▉         | 1/11 [00:00<00:07,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.36499470472335815\n",
      "Epoch 26:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2642737627029419\n",
      "Epoch 26:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0564, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.32223033905029297\n",
      "Epoch 26:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.27319782972335815\n",
      "Epoch 26:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3967044949531555\n",
      "Epoch 26:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0586, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2763676643371582\n",
      "Epoch 26:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2538013458251953\n",
      "Epoch 26:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3196025490760803\n",
      "Epoch 26:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.34389036893844604\n",
      "Epoch 26:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.20548087358474731\n",
      "Epoch 26: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0904, device='cuda:0')\n",
      "r2_score:  -0.22066032886505127\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0949, device='cuda:0')\n",
      "r2_score:  -0.38778162002563477\n",
      "Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3221505880355835\n",
      "Epoch 27:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3478870987892151\n",
      "Epoch 27:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.11905932426452637\n",
      "Epoch 27:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0573, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.33345484733581543\n",
      "Epoch 27:  36%|███▋      | 4/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0566, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.29699140787124634\n",
      "Epoch 27:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2154279351234436\n",
      "Epoch 27:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.14899563789367676\n",
      "Epoch 27:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.36892151832580566\n",
      "Epoch 27:  73%|███████▎  | 8/11 [00:05<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3260125517845154\n",
      "Epoch 27:  82%|████████▏ | 9/11 [00:06<00:01,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.24257999658584595\n",
      "Epoch 27:  91%|█████████ | 10/11 [00:06<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.2888355851173401\n",
      "Epoch 27: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0967, device='cuda:0')\n",
      "r2_score:  -0.3053395748138428\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0866, device='cuda:0')\n",
      "r2_score:  -0.26628339290618896\n",
      "Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.29429787397384644\n",
      "Epoch 28:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3090078830718994\n",
      "Epoch 28:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3400537371635437\n",
      "Epoch 28:  27%|██▋       | 3/11 [00:02<00:05,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3201582431793213\n",
      "Epoch 28:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0570, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.32425111532211304\n",
      "Epoch 28:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3260401487350464\n",
      "Epoch 28:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.369326651096344\n",
      "Epoch 28:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3540460467338562\n",
      "Epoch 28:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3668317198753357\n",
      "Epoch 28:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.3853263854980469\n",
      "Epoch 28:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.41061174869537354\n",
      "Epoch 28: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0909, device='cuda:0')\n",
      "r2_score:  -0.22656822204589844\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0982, device='cuda:0')\n",
      "r2_score:  -0.43496131896972656\n",
      "Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.41854971647262573\n",
      "Epoch 29:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.4572778344154358\n",
      "Epoch 29:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.4805636405944824\n",
      "Epoch 29:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.47319304943084717\n",
      "Epoch 29:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5106338262557983\n",
      "Epoch 29:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.43870508670806885\n",
      "Epoch 29:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0518, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.4295276999473572\n",
      "Epoch 29:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.40684908628463745\n",
      "Epoch 29:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.4850988984107971\n",
      "Epoch 29:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.45826560258865356\n",
      "Epoch 29:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.44363200664520264\n",
      "Epoch 29: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1022, device='cuda:0')\n",
      "r2_score:  -0.3790895938873291\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1082, device='cuda:0')\n",
      "r2_score:  -0.581863522529602\n",
      "Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5445903539657593\n",
      "Epoch 30:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5338503122329712\n",
      "Epoch 30:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.45233529806137085\n",
      "Epoch 30:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5623847842216492\n",
      "Epoch 30:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5886574983596802\n",
      "Epoch 30:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.46587008237838745\n",
      "Epoch 30:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.4972969889640808\n",
      "Epoch 30:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5710676908493042\n",
      "Epoch 30:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5055721402168274\n",
      "Epoch 30:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5373388528823853\n",
      "Epoch 30:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.45701587200164795\n",
      "Epoch 30: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1104, device='cuda:0')\n",
      "r2_score:  -0.49012959003448486\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1027, device='cuda:0')\n",
      "r2_score:  -0.5008485317230225\n",
      "Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6178019046783447\n",
      "Epoch 31:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5727843046188354\n",
      "Epoch 31:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6176886558532715\n",
      "Epoch 31:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6306912899017334\n",
      "Epoch 31:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6208129525184631\n",
      "Epoch 31:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.605344295501709\n",
      "Epoch 31:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.558173418045044\n",
      "Epoch 31:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5843682289123535\n",
      "Epoch 31:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6029142141342163\n",
      "Epoch 31:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.5571669340133667\n",
      "Epoch 31:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6062168478965759\n",
      "Epoch 31: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1021, device='cuda:0')\n",
      "r2_score:  -0.37774527072906494\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.0952, device='cuda:0')\n",
      "r2_score:  -0.3922548294067383\n",
      "Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6244856119155884\n",
      "Epoch 32:   9%|▉         | 1/11 [00:01<00:10,  0.96it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6842089295387268\n",
      "Epoch 32:  18%|█▊        | 2/11 [00:01<00:07,  1.14it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6861326694488525\n",
      "Epoch 32:  27%|██▋       | 3/11 [00:02<00:06,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6754621267318726\n",
      "Epoch 32:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6486475467681885\n",
      "Epoch 32:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6751905679702759\n",
      "Epoch 32:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7141121625900269\n",
      "Epoch 32:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7190501689910889\n",
      "Epoch 32:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6923223733901978\n",
      "Epoch 32:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7351590394973755\n",
      "Epoch 32:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7278618216514587\n",
      "Epoch 32: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1093, device='cuda:0')\n",
      "r2_score:  -0.47546660900115967\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1047, device='cuda:0')\n",
      "r2_score:  -0.5310145616531372\n",
      "Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7363936901092529\n",
      "Epoch 33:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7394989728927612\n",
      "Epoch 33:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.737525463104248\n",
      "Epoch 33:  27%|██▋       | 3/11 [00:02<00:05,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7566747069358826\n",
      "Epoch 33:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7087647914886475\n",
      "Epoch 33:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7768585085868835\n",
      "Epoch 33:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.710095226764679\n",
      "Epoch 33:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7387840747833252\n",
      "Epoch 33:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7047160863876343\n",
      "Epoch 33:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.6939448118209839\n",
      "Epoch 33:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7559637427330017\n",
      "Epoch 33: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1137, device='cuda:0')\n",
      "r2_score:  -0.5351510047912598\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1095, device='cuda:0')\n",
      "r2_score:  -0.6002858877182007\n",
      "Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7819843888282776\n",
      "Epoch 34:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7556637525558472\n",
      "Epoch 34:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7472654581069946\n",
      "Epoch 34:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7484376430511475\n",
      "Epoch 34:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8068747520446777\n",
      "Epoch 34:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.76544588804245\n",
      "Epoch 34:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7624526619911194\n",
      "Epoch 34:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7623324394226074\n",
      "Epoch 34:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7835770845413208\n",
      "Epoch 34:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.753389835357666\n",
      "Epoch 34:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7445483207702637\n",
      "Epoch 34: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1148, device='cuda:0')\n",
      "r2_score:  -0.5495116710662842\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1080, device='cuda:0')\n",
      "r2_score:  -0.5779964923858643\n",
      "Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7775678634643555\n",
      "Epoch 35:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.808401882648468\n",
      "Epoch 35:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7627701759338379\n",
      "Epoch 35:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7644124627113342\n",
      "Epoch 35:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8083468079566956\n",
      "Epoch 35:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7853226065635681\n",
      "Epoch 35:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8281095623970032\n",
      "Epoch 35:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.768258810043335\n",
      "Epoch 35:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8107103705406189\n",
      "Epoch 35:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0165, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8032840490341187\n",
      "Epoch 35:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7481704950332642\n",
      "Epoch 35: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1183, device='cuda:0')\n",
      "r2_score:  -0.5969892740249634\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1109, device='cuda:0')\n",
      "r2_score:  -0.6209475994110107\n",
      "Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8135138750076294\n",
      "Epoch 36:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.80585777759552\n",
      "Epoch 36:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.812707781791687\n",
      "Epoch 36:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8069931864738464\n",
      "Epoch 36:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7919130325317383\n",
      "Epoch 36:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7947473526000977\n",
      "Epoch 36:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.821454644203186\n",
      "Epoch 36:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8001011610031128\n",
      "Epoch 36:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7779582738876343\n",
      "Epoch 36:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8146029114723206\n",
      "Epoch 36:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8177617788314819\n",
      "Epoch 36: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1197, device='cuda:0')\n",
      "r2_score:  -0.6153382062911987\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1135, device='cuda:0')\n",
      "r2_score:  -0.6592980623245239\n",
      "Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8410342335700989\n",
      "Epoch 37:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8436994552612305\n",
      "Epoch 37:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8209167718887329\n",
      "Epoch 37:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8293856382369995\n",
      "Epoch 37:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8256840705871582\n",
      "Epoch 37:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8063790202140808\n",
      "Epoch 37:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8026639223098755\n",
      "Epoch 37:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.831317663192749\n",
      "Epoch 37:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8133810758590698\n",
      "Epoch 37:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.844062328338623\n",
      "Epoch 37:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.836175799369812\n",
      "Epoch 37: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1220, device='cuda:0')\n",
      "r2_score:  -0.6465929746627808\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1113, device='cuda:0')\n",
      "r2_score:  -0.6275532245635986\n",
      "Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8185046911239624\n",
      "Epoch 38:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8491882085800171\n",
      "Epoch 38:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8590280413627625\n",
      "Epoch 38:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8580164909362793\n",
      "Epoch 38:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8429202437400818\n",
      "Epoch 38:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8279988169670105\n",
      "Epoch 38:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8463807106018066\n",
      "Epoch 38:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8412894010543823\n",
      "Epoch 38:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8362717032432556\n",
      "Epoch 38:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8303202986717224\n",
      "Epoch 38:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.7998128533363342\n",
      "Epoch 38: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1238, device='cuda:0')\n",
      "r2_score:  -0.6713888645172119\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1154, device='cuda:0')\n",
      "r2_score:  -0.6865665912628174\n",
      "Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8423590660095215\n",
      "Epoch 39:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.863517701625824\n",
      "Epoch 39:  18%|█▊        | 2/11 [00:01<00:06,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8593516945838928\n",
      "Epoch 39:  27%|██▋       | 3/11 [00:02<00:05,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.851874053478241\n",
      "Epoch 39:  36%|███▋      | 4/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.871822714805603\n",
      "Epoch 39:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8553831577301025\n",
      "Epoch 39:  55%|█████▍    | 6/11 [00:04<00:03,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8407148718833923\n",
      "Epoch 39:  64%|██████▎   | 7/11 [00:04<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8623045086860657\n",
      "Epoch 39:  73%|███████▎  | 8/11 [00:05<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8344981074333191\n",
      "Epoch 39:  82%|████████▏ | 9/11 [00:06<00:01,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8470652103424072\n",
      "Epoch 39:  91%|█████████ | 10/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8567222356796265\n",
      "Epoch 39: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1233, device='cuda:0')\n",
      "r2_score:  -0.6639337539672852\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1138, device='cuda:0')\n",
      "r2_score:  -0.6640928983688354\n",
      "Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8772305846214294\n",
      "Epoch 40:   9%|▉         | 1/11 [00:00<00:09,  1.08it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8443307280540466\n",
      "Epoch 40:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8591013550758362\n",
      "Epoch 40:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8634977340698242\n",
      "Epoch 40:  36%|███▋      | 4/11 [00:03<00:05,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8974008560180664\n",
      "Epoch 40:  45%|████▌     | 5/11 [00:03<00:04,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8679588437080383\n",
      "Epoch 40:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8750863075256348\n",
      "Epoch 40:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8495591878890991\n",
      "Epoch 40:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8769602179527283\n",
      "Epoch 40:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8314325213432312\n",
      "Epoch 40:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8700629472732544\n",
      "Epoch 40: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1254, device='cuda:0')\n",
      "r2_score:  -0.6920729875564575\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1140, device='cuda:0')\n",
      "r2_score:  -0.6671535968780518\n",
      "Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8714309930801392\n",
      "Epoch 41:   9%|▉         | 1/11 [00:00<00:07,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0104, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.866301417350769\n",
      "Epoch 41:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8844752311706543\n",
      "Epoch 41:  27%|██▋       | 3/11 [00:02<00:05,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8510135412216187\n",
      "Epoch 41:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8662346601486206\n",
      "Epoch 41:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8785035610198975\n",
      "Epoch 41:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0092, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8944209814071655\n",
      "Epoch 41:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8822715878486633\n",
      "Epoch 41:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8880326747894287\n",
      "Epoch 41:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0088, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8891611695289612\n",
      "Epoch 41:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.884945273399353\n",
      "Epoch 41: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1284, device='cuda:0')\n",
      "r2_score:  -0.7330760955810547\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1152, device='cuda:0')\n",
      "r2_score:  -0.6837233304977417\n",
      "Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9110832214355469\n",
      "Epoch 42:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9008585214614868\n",
      "Epoch 42:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8882059454917908\n",
      "Epoch 42:  27%|██▋       | 3/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0101, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8667083382606506\n",
      "Epoch 42:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8872095942497253\n",
      "Epoch 42:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8865998387336731\n",
      "Epoch 42:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8839049339294434\n",
      "Epoch 42:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8726045489311218\n",
      "Epoch 42:  73%|███████▎  | 8/11 [00:06<00:02,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9036113023757935\n",
      "Epoch 42:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9065325260162354\n",
      "Epoch 42:  91%|█████████ | 10/11 [00:07<00:00,  1.33it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8590932488441467\n",
      "Epoch 42: 100%|██████████| 11/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1302, device='cuda:0')\n",
      "r2_score:  -0.7570374011993408\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1148, device='cuda:0')\n",
      "r2_score:  -0.6775314807891846\n",
      "Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9126425981521606\n",
      "Epoch 43:   9%|▉         | 1/11 [00:00<00:08,  1.12it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8742956519126892\n",
      "Epoch 43:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8925215005874634\n",
      "Epoch 43:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9133247137069702\n",
      "Epoch 43:  36%|███▋      | 4/11 [00:03<00:05,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9134089946746826\n",
      "Epoch 43:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9057611227035522\n",
      "Epoch 43:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9062841534614563\n",
      "Epoch 43:  64%|██████▎   | 7/11 [00:05<00:03,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8956751227378845\n",
      "Epoch 43:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9066479802131653\n",
      "Epoch 43:  82%|████████▏ | 9/11 [00:07<00:01,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8752079010009766\n",
      "Epoch 43:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9205416440963745\n",
      "Epoch 43: 100%|██████████| 11/11 [00:08<00:00,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1322, device='cuda:0')\n",
      "r2_score:  -0.7845984697341919\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1194, device='cuda:0')\n",
      "r2_score:  -0.745197057723999\n",
      "Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9003331661224365\n",
      "Epoch 44:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9284913539886475\n",
      "Epoch 44:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9061310887336731\n",
      "Epoch 44:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8819835782051086\n",
      "Epoch 44:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.920330286026001\n",
      "Epoch 44:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9120659828186035\n",
      "Epoch 44:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.8997440338134766\n",
      "Epoch 44:  64%|██████▎   | 7/11 [00:04<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.904849112033844\n",
      "Epoch 44:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9233670234680176\n",
      "Epoch 44:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9190496802330017\n",
      "Epoch 44:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9101936221122742\n",
      "Epoch 44: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1314, device='cuda:0')\n",
      "r2_score:  -0.7742570638656616\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1159, device='cuda:0')\n",
      "r2_score:  -0.6940720081329346\n",
      "Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9016368985176086\n",
      "Epoch 45:   9%|▉         | 1/11 [00:00<00:09,  1.07it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9177026152610779\n",
      "Epoch 45:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0086, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9005141258239746\n",
      "Epoch 45:  27%|██▋       | 3/11 [00:02<00:06,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9168970584869385\n",
      "Epoch 45:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9185536503791809\n",
      "Epoch 45:  45%|████▌     | 5/11 [00:03<00:04,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9158239364624023\n",
      "Epoch 45:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9270187020301819\n",
      "Epoch 45:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9224679470062256\n",
      "Epoch 45:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9212748408317566\n",
      "Epoch 45:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9312618970870972\n",
      "Epoch 45:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9218887090682983\n",
      "Epoch 45: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1344, device='cuda:0')\n",
      "r2_score:  -0.8137633800506592\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1196, device='cuda:0')\n",
      "r2_score:  -0.7487354278564453\n",
      "Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.921117901802063\n",
      "Epoch 46:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.917901873588562\n",
      "Epoch 46:  18%|█▊        | 2/11 [00:01<00:06,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9313604235649109\n",
      "Epoch 46:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9171346426010132\n",
      "Epoch 46:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9206079244613647\n",
      "Epoch 46:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9373458623886108\n",
      "Epoch 46:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9163572192192078\n",
      "Epoch 46:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9352819919586182\n",
      "Epoch 46:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9278292655944824\n",
      "Epoch 46:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9060966968536377\n",
      "Epoch 46:  91%|█████████ | 10/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9375348091125488\n",
      "Epoch 46: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1356, device='cuda:0')\n",
      "r2_score:  -0.8300971984863281\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1170, device='cuda:0')\n",
      "r2_score:  -0.7102420330047607\n",
      "Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9218569993972778\n",
      "Epoch 47:   9%|▉         | 1/11 [00:00<00:08,  1.17it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9270315766334534\n",
      "Epoch 47:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9432530403137207\n",
      "Epoch 47:  27%|██▋       | 3/11 [00:03<00:10,  0.78it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.935950756072998\n",
      "Epoch 47:  36%|███▋      | 4/11 [00:04<00:08,  0.82it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9427252411842346\n",
      "Epoch 47:  45%|████▌     | 5/11 [00:06<00:07,  0.78it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9340261220932007\n",
      "Epoch 47:  55%|█████▍    | 6/11 [00:07<00:06,  0.81it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9271751046180725\n",
      "Epoch 47:  64%|██████▎   | 7/11 [00:08<00:04,  0.86it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9398506283760071\n",
      "Epoch 47:  73%|███████▎  | 8/11 [00:08<00:03,  0.91it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9428228735923767\n",
      "Epoch 47:  82%|████████▏ | 9/11 [00:09<00:02,  0.95it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9179804921150208\n",
      "Epoch 47:  91%|█████████ | 10/11 [00:10<00:01,  0.98it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9278969168663025\n",
      "Epoch 47: 100%|██████████| 11/11 [00:10<00:00,  1.04it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1367, device='cuda:0')\n",
      "r2_score:  -0.8453593254089355\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1216, device='cuda:0')\n",
      "r2_score:  -0.7775338888168335\n",
      "Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9287196397781372\n",
      "Epoch 48:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9425867795944214\n",
      "Epoch 48:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9477601051330566\n",
      "Epoch 48:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9457749724388123\n",
      "Epoch 48:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9340425133705139\n",
      "Epoch 48:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9396697878837585\n",
      "Epoch 48:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.946799635887146\n",
      "Epoch 48:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.944717288017273\n",
      "Epoch 48:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9604142308235168\n",
      "Epoch 48:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9194860458374023\n",
      "Epoch 48:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9533531665802002\n",
      "Epoch 48: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.8407394886016846\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1177, device='cuda:0')\n",
      "r2_score:  -0.7205746173858643\n",
      "Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.953136682510376\n",
      "Epoch 49:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9441478848457336\n",
      "Epoch 49:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9397495985031128\n",
      "Epoch 49:  27%|██▋       | 3/11 [00:02<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9472237825393677\n",
      "Epoch 49:  36%|███▋      | 4/11 [00:02<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9426710605621338\n",
      "Epoch 49:  45%|████▌     | 5/11 [00:03<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9491525888442993\n",
      "Epoch 49:  55%|█████▍    | 6/11 [00:04<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9547393918037415\n",
      "Epoch 49:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9382736682891846\n",
      "Epoch 49:  73%|███████▎  | 8/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9487070441246033\n",
      "Epoch 49:  82%|████████▏ | 9/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.944012463092804\n",
      "Epoch 49:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9651256799697876\n",
      "Epoch 49: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1412, device='cuda:0')\n",
      "r2_score:  -0.9059513807296753\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1221, device='cuda:0')\n",
      "r2_score:  -0.7849205732345581\n",
      "Epoch 50:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9559701681137085\n",
      "Epoch 50:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9487825632095337\n",
      "Epoch 50:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9537386298179626\n",
      "Epoch 50:  27%|██▋       | 3/11 [00:02<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9525986313819885\n",
      "Epoch 50:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9577024579048157\n",
      "Epoch 50:  45%|████▌     | 5/11 [00:03<00:04,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9576740860939026\n",
      "Epoch 50:  55%|█████▍    | 6/11 [00:04<00:03,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9515882134437561\n",
      "Epoch 50:  64%|██████▎   | 7/11 [00:04<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9351891279220581\n",
      "Epoch 50:  73%|███████▎  | 8/11 [00:05<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9533341526985168\n",
      "Epoch 50:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9440132975578308\n",
      "Epoch 50:  91%|█████████ | 10/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9581203460693359\n",
      "Epoch 50: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1399, device='cuda:0')\n",
      "r2_score:  -0.8881269693374634\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1229, device='cuda:0')\n",
      "r2_score:  -0.7961598634719849\n",
      "Epoch 51:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9606223106384277\n",
      "Epoch 51:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9597719311714172\n",
      "Epoch 51:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9656739830970764\n",
      "Epoch 51:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9436402320861816\n",
      "Epoch 51:  36%|███▋      | 4/11 [00:02<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9574568271636963\n",
      "Epoch 51:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.963291347026825\n",
      "Epoch 51:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9506767988204956\n",
      "Epoch 51:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9679542183876038\n",
      "Epoch 51:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9541257619857788\n",
      "Epoch 51:  82%|████████▏ | 9/11 [00:06<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9493894577026367\n",
      "Epoch 51:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9507354497909546\n",
      "Epoch 51: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1384, device='cuda:0')\n",
      "r2_score:  -0.8686933517456055\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1223, device='cuda:0')\n",
      "r2_score:  -0.7880953550338745\n",
      "Epoch 52:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.970535159111023\n",
      "Epoch 52:   9%|▉         | 1/11 [00:00<00:09,  1.06it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9589298367500305\n",
      "Epoch 52:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.959855318069458\n",
      "Epoch 52:  27%|██▋       | 3/11 [00:02<00:06,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9564463496208191\n",
      "Epoch 52:  36%|███▋      | 4/11 [00:02<00:05,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9532061219215393\n",
      "Epoch 52:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9692023396492004\n",
      "Epoch 52:  55%|█████▍    | 6/11 [00:04<00:03,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9538427591323853\n",
      "Epoch 52:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9576395750045776\n",
      "Epoch 52:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9627722501754761\n",
      "Epoch 52:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9683067202568054\n",
      "Epoch 52:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9501270055770874\n",
      "Epoch 52: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1407, device='cuda:0')\n",
      "r2_score:  -0.8989393711090088\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1212, device='cuda:0')\n",
      "r2_score:  -0.7723619937896729\n",
      "Epoch 53:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9573532938957214\n",
      "Epoch 53:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9717340469360352\n",
      "Epoch 53:  18%|█▊        | 2/11 [00:01<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9672914147377014\n",
      "Epoch 53:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9759940505027771\n",
      "Epoch 53:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9642876982688904\n",
      "Epoch 53:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9642890095710754\n",
      "Epoch 53:  55%|█████▍    | 6/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9728553295135498\n",
      "Epoch 53:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9596033096313477\n",
      "Epoch 53:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.965673565864563\n",
      "Epoch 53:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9675204157829285\n",
      "Epoch 53:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.970636785030365\n",
      "Epoch 53: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1405, device='cuda:0')\n",
      "r2_score:  -0.8966679573059082\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1222, device='cuda:0')\n",
      "r2_score:  -0.7857034206390381\n",
      "Epoch 54:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.968346357345581\n",
      "Epoch 54:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9777713418006897\n",
      "Epoch 54:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9744278192520142\n",
      "Epoch 54:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9663794636726379\n",
      "Epoch 54:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9715677499771118\n",
      "Epoch 54:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9711149334907532\n",
      "Epoch 54:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9578434228897095\n",
      "Epoch 54:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9678335189819336\n",
      "Epoch 54:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9687057137489319\n",
      "Epoch 54:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9769870638847351\n",
      "Epoch 54:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9611573219299316\n",
      "Epoch 54: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1426, device='cuda:0')\n",
      "r2_score:  -0.9243718385696411\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1254, device='cuda:0')\n",
      "r2_score:  -0.8327940702438354\n",
      "Epoch 55:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9691629409790039\n",
      "Epoch 55:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9725478887557983\n",
      "Epoch 55:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9635902047157288\n",
      "Epoch 55:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9736893177032471\n",
      "Epoch 55:  36%|███▋      | 4/11 [00:02<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9770179390907288\n",
      "Epoch 55:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9695888757705688\n",
      "Epoch 55:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9682036638259888\n",
      "Epoch 55:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9729279279708862\n",
      "Epoch 55:  73%|███████▎  | 8/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9726393222808838\n",
      "Epoch 55:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9769601225852966\n",
      "Epoch 55:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.96755051612854\n",
      "Epoch 55: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1423, device='cuda:0')\n",
      "r2_score:  -0.920210599899292\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1234, device='cuda:0')\n",
      "r2_score:  -0.8032861948013306\n",
      "Epoch 56:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9764431715011597\n",
      "Epoch 56:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9705926775932312\n",
      "Epoch 56:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9724124073982239\n",
      "Epoch 56:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9745960235595703\n",
      "Epoch 56:  36%|███▋      | 4/11 [00:02<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9718926548957825\n",
      "Epoch 56:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9723473787307739\n",
      "Epoch 56:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9677177667617798\n",
      "Epoch 56:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9710296392440796\n",
      "Epoch 56:  73%|███████▎  | 8/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9670813083648682\n",
      "Epoch 56:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9780382513999939\n",
      "Epoch 56:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9786660671234131\n",
      "Epoch 56: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1429, device='cuda:0')\n",
      "r2_score:  -0.9294508695602417\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1247, device='cuda:0')\n",
      "r2_score:  -0.8229974508285522\n",
      "Epoch 57:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9770801663398743\n",
      "Epoch 1:  64%|██████▎   | 7/11 [50:11<28:40,  0.00it/s, v_num=10]]\n",
      "Epoch 23:  45%|████▌     | 5/11 [12:00<14:24,  0.01it/s, v_num=12]\n",
      "y.shape:  torch.Size([256, 1])                                     \n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.974957287311554\n",
      "Epoch 57:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9570947885513306\n",
      "Epoch 57:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9747609496116638\n",
      "Epoch 57:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9737055897712708\n",
      "Epoch 57:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9775753617286682\n",
      "Epoch 57:  55%|█████▍    | 6/11 [00:04<00:03,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.978625476360321\n",
      "Epoch 57:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.978442370891571\n",
      "Epoch 57:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9743373394012451\n",
      "Epoch 57:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9653483629226685\n",
      "Epoch 57:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.978216290473938\n",
      "Epoch 57: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1425, device='cuda:0')\n",
      "r2_score:  -0.9240744113922119\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1244, device='cuda:0')\n",
      "r2_score:  -0.818374752998352\n",
      "Epoch 58:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9785184264183044\n",
      "Epoch 58:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9734599590301514\n",
      "Epoch 58:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9666927456855774\n",
      "Epoch 58:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9683945178985596\n",
      "Epoch 58:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9773910045623779\n",
      "Epoch 58:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9733469486236572\n",
      "Epoch 58:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9761763215065002\n",
      "Epoch 58:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9766756296157837\n",
      "Epoch 58:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9748652577400208\n",
      "Epoch 58:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9787772297859192\n",
      "Epoch 58:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.972662627696991\n",
      "Epoch 58: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1425, device='cuda:0')\n",
      "r2_score:  -0.9240096807479858\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1248, device='cuda:0')\n",
      "r2_score:  -0.8235918283462524\n",
      "Epoch 59:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9711688756942749\n",
      "Epoch 59:   9%|▉         | 1/11 [00:00<00:09,  1.10it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9683406352996826\n",
      "Epoch 59:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9740031361579895\n",
      "Epoch 59:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9752148389816284\n",
      "Epoch 59:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9856541156768799\n",
      "Epoch 59:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9776492714881897\n",
      "Epoch 59:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.973861575126648\n",
      "Epoch 59:  64%|██████▎   | 7/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9807343482971191\n",
      "Epoch 59:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9811230897903442\n",
      "Epoch 59:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9687851071357727\n",
      "Epoch 59:  91%|█████████ | 10/11 [00:06<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.968972384929657\n",
      "Epoch 59: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1427, device='cuda:0')\n",
      "r2_score:  -0.9260660409927368\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1245, device='cuda:0')\n",
      "r2_score:  -0.8193912506103516\n",
      "Epoch 60:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.972441554069519\n",
      "Epoch 60:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9773781299591064\n",
      "Epoch 60:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9794105291366577\n",
      "Epoch 60:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9801672101020813\n",
      "Epoch 60:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9846005439758301\n",
      "Epoch 60:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9715949296951294\n",
      "Epoch 60:  55%|█████▍    | 6/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9768604040145874\n",
      "Epoch 60:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9651732444763184\n",
      "Epoch 60:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.974055826663971\n",
      "Epoch 60:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9794273972511292\n",
      "Epoch 60:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9798964858055115\n",
      "Epoch 60: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1429, device='cuda:0')\n",
      "r2_score:  -0.9288327693939209\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1249, device='cuda:0')\n",
      "r2_score:  -0.8255611658096313\n",
      "Epoch 61:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9705427885055542\n",
      "Epoch 61:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9796967506408691\n",
      "Epoch 61:  18%|█▊        | 2/11 [00:01<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.975989580154419\n",
      "Epoch 61:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9763302206993103\n",
      "Epoch 61:  36%|███▋      | 4/11 [00:02<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9815551042556763\n",
      "Epoch 61:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9808351993560791\n",
      "Epoch 61:  55%|█████▍    | 6/11 [00:04<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.978646993637085\n",
      "Epoch 61:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9714774489402771\n",
      "Epoch 61:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9810110926628113\n",
      "Epoch 61:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9732481837272644\n",
      "Epoch 61:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9783996939659119\n",
      "Epoch 61: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1434, device='cuda:0')\n",
      "r2_score:  -0.9362260103225708\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1255, device='cuda:0')\n",
      "r2_score:  -0.8348821401596069\n",
      "Epoch 62:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9736378192901611\n",
      "Epoch 62:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9817444682121277\n",
      "Epoch 62:  18%|█▊        | 2/11 [00:01<00:06,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.98661869764328\n",
      "Epoch 62:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9812783598899841\n",
      "Epoch 62:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9739852547645569\n",
      "Epoch 62:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.974600613117218\n",
      "Epoch 62:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9743943214416504\n",
      "Epoch 62:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.974276602268219\n",
      "Epoch 62:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9769690632820129\n",
      "Epoch 62:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9767484068870544\n",
      "Epoch 62:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9833652377128601\n",
      "Epoch 62: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1437, device='cuda:0')\n",
      "r2_score:  -0.9398245811462402\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1253, device='cuda:0')\n",
      "r2_score:  -0.8318543434143066\n",
      "Epoch 63:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.980380117893219\n",
      "Epoch 63:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9766120910644531\n",
      "Epoch 63:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9766435623168945\n",
      "Epoch 63:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.980128824710846\n",
      "Epoch 63:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.972507119178772\n",
      "Epoch 63:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.974637508392334\n",
      "Epoch 63:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9784847497940063\n",
      "Epoch 63:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9785301089286804\n",
      "Epoch 63:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9812717437744141\n",
      "Epoch 63:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.978710949420929\n",
      "Epoch 63:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9831811189651489\n",
      "Epoch 63: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1437, device='cuda:0')\n",
      "r2_score:  -0.9402047395706177\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1258, device='cuda:0')\n",
      "r2_score:  -0.8383492231369019\n",
      "Epoch 64:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9726572632789612\n",
      "Epoch 64:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9811955094337463\n",
      "Epoch 64:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9788028001785278\n",
      "Epoch 64:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9823271036148071\n",
      "Epoch 64:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.985840916633606\n",
      "Epoch 64:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.976354718208313\n",
      "Epoch 64:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9786595702171326\n",
      "Epoch 64:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9762746691703796\n",
      "Epoch 64:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9793967604637146\n",
      "Epoch 64:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9802387356758118\n",
      "Epoch 64:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.980103611946106\n",
      "Epoch 64: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1441, device='cuda:0')\n",
      "r2_score:  -0.9452348947525024\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1257, device='cuda:0')\n",
      "r2_score:  -0.8375465869903564\n",
      "Epoch 65:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9772325158119202\n",
      "Epoch 65:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9848467707633972\n",
      "Epoch 65:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9777584671974182\n",
      "Epoch 65:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9769219756126404\n",
      "Epoch 65:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.979072630405426\n",
      "Epoch 65:  45%|████▌     | 5/11 [00:03<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9731197357177734\n",
      "Epoch 65:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.980927586555481\n",
      "Epoch 65:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9798787832260132\n",
      "Epoch 65:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9804939031600952\n",
      "Epoch 65:  82%|████████▏ | 9/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9794090986251831\n",
      "Epoch 65:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9842148423194885\n",
      "Epoch 65: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1441, device='cuda:0')\n",
      "r2_score:  -0.9446135759353638\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1268, device='cuda:0')\n",
      "r2_score:  -0.8539941310882568\n",
      "Epoch 66:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9804033041000366\n",
      "Epoch 66:   9%|▉         | 1/11 [00:00<00:08,  1.20it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9831150770187378\n",
      "Epoch 66:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9735050201416016\n",
      "Epoch 66:  27%|██▋       | 3/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9796223640441895\n",
      "Epoch 66:  36%|███▋      | 4/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9799842238426208\n",
      "Epoch 66:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9792895913124084\n",
      "Epoch 66:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9821574687957764\n",
      "Epoch 66:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9778547286987305\n",
      "Epoch 66:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9774706363677979\n",
      "Epoch 66:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9847543239593506\n",
      "Epoch 66:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9745949506759644\n",
      "Epoch 66: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1445, device='cuda:0')\n",
      "r2_score:  -0.949885368347168\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1264, device='cuda:0')\n",
      "r2_score:  -0.847010612487793\n",
      "Epoch 67:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9794288277626038\n",
      "Epoch 67:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9776663780212402\n",
      "Epoch 67:  18%|█▊        | 2/11 [00:01<00:06,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9762811660766602\n",
      "Epoch 67:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9794382452964783\n",
      "Epoch 67:  36%|███▋      | 4/11 [00:02<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9856592416763306\n",
      "Epoch 67:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9836122989654541\n",
      "Epoch 67:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.976144552230835\n",
      "Epoch 67:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9802316427230835\n",
      "Epoch 67:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9796442985534668\n",
      "Epoch 67:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9809826612472534\n",
      "Epoch 67:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9845742583274841\n",
      "Epoch 67: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1446, device='cuda:0')\n",
      "r2_score:  -0.9514116048812866\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1265, device='cuda:0')\n",
      "r2_score:  -0.8491679430007935\n",
      "Epoch 68:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9824475646018982\n",
      "Epoch 68:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9724670648574829\n",
      "Epoch 68:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9846687316894531\n",
      "Epoch 68:  27%|██▋       | 3/11 [00:02<00:05,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9847342371940613\n",
      "Epoch 68:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9837465882301331\n",
      "Epoch 68:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9852091670036316\n",
      "Epoch 68:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9848525524139404\n",
      "Epoch 68:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9827143549919128\n",
      "Epoch 68:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9780067205429077\n",
      "Epoch 68:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9818647503852844\n",
      "Epoch 68:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9680432081222534\n",
      "Epoch 68: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1441, device='cuda:0')\n",
      "r2_score:  -0.9449057579040527\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1265, device='cuda:0')\n",
      "r2_score:  -0.8495234251022339\n",
      "Epoch 69:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.983400821685791\n",
      "Epoch 69:   9%|▉         | 1/11 [00:00<00:07,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9803796410560608\n",
      "Epoch 69:  18%|█▊        | 2/11 [00:01<00:06,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9778940677642822\n",
      "Epoch 69:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9836252927780151\n",
      "Epoch 69:  36%|███▋      | 4/11 [00:02<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9853441715240479\n",
      "Epoch 69:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9827459454536438\n",
      "Epoch 69:  55%|█████▍    | 6/11 [00:04<00:03,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9806694984436035\n",
      "Epoch 69:  64%|██████▎   | 7/11 [00:04<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.979080080986023\n",
      "Epoch 69:  73%|███████▎  | 8/11 [00:05<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9845297336578369\n",
      "Epoch 69:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9830934405326843\n",
      "Epoch 69:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9862805008888245\n",
      "Epoch 69: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1441, device='cuda:0')\n",
      "r2_score:  -0.9443721771240234\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1266, device='cuda:0')\n",
      "r2_score:  -0.8501710891723633\n",
      "Epoch 70:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9855582118034363\n",
      "Epoch 70:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.981820285320282\n",
      "Epoch 70:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9824663400650024\n",
      "Epoch 70:  27%|██▋       | 3/11 [00:02<00:05,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9847474098205566\n",
      "Epoch 70:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9836332201957703\n",
      "Epoch 70:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9822495579719543\n",
      "Epoch 70:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9831441640853882\n",
      "Epoch 70:  64%|██████▎   | 7/11 [00:05<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9813030362129211\n",
      "Epoch 70:  73%|███████▎  | 8/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9864160418510437\n",
      "Epoch 70:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9806328415870667\n",
      "Epoch 70:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9795680642127991\n",
      "Epoch 70: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1450, device='cuda:0')\n",
      "r2_score:  -0.9574437141418457\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1273, device='cuda:0')\n",
      "r2_score:  -0.861292839050293\n",
      "Epoch 71:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9762260317802429\n",
      "Epoch 71:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9886638522148132\n",
      "Epoch 71:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9854486584663391\n",
      "Epoch 71:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9832668900489807\n",
      "Epoch 71:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9907321929931641\n",
      "Epoch 71:  45%|████▌     | 5/11 [00:04<00:05,  1.01it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9799008369445801\n",
      "Epoch 71:  55%|█████▍    | 6/11 [00:05<00:04,  1.03it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9839273691177368\n",
      "Epoch 71:  64%|██████▎   | 7/11 [00:06<00:03,  1.07it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9802687764167786\n",
      "Epoch 71:  73%|███████▎  | 8/11 [00:07<00:02,  1.10it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9858570098876953\n",
      "Epoch 71:  82%|████████▏ | 9/11 [00:07<00:01,  1.13it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9834691882133484\n",
      "Epoch 71:  91%|█████████ | 10/11 [00:08<00:00,  1.16it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9779174327850342\n",
      "Epoch 71: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1434, device='cuda:0')\n",
      "r2_score:  -0.935326099395752\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1268, device='cuda:0')\n",
      "r2_score:  -0.8535052537918091\n",
      "Epoch 72:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9788220524787903\n",
      "Epoch 72:   9%|▉         | 1/11 [00:00<00:07,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9839962124824524\n",
      "Epoch 72:  18%|█▊        | 2/11 [00:01<00:06,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9883084297180176\n",
      "Epoch 72:  27%|██▋       | 3/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9880356192588806\n",
      "Epoch 72:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9851005673408508\n",
      "Epoch 72:  45%|████▌     | 5/11 [00:03<00:04,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9807326793670654\n",
      "Epoch 72:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9799062609672546\n",
      "Epoch 72:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9811047315597534\n",
      "Epoch 72:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9885612726211548\n",
      "Epoch 72:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9841602444648743\n",
      "Epoch 72:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9857823252677917\n",
      "Epoch 72: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1439, device='cuda:0')\n",
      "r2_score:  -0.9427796602249146\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1262, device='cuda:0')\n",
      "r2_score:  -0.8453851938247681\n",
      "Epoch 73:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9787564873695374\n",
      "Epoch 73:   9%|▉         | 1/11 [00:00<00:07,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9833146333694458\n",
      "Epoch 73:  18%|█▊        | 2/11 [00:01<00:06,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.98160719871521\n",
      "Epoch 73:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9863460659980774\n",
      "Epoch 73:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9869799613952637\n",
      "Epoch 73:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9850538372993469\n",
      "Epoch 73:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9840646982192993\n",
      "Epoch 73:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.985071063041687\n",
      "Epoch 73:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9885849356651306\n",
      "Epoch 73:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9877138733863831\n",
      "Epoch 73:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9776751399040222\n",
      "Epoch 73: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1444, device='cuda:0')\n",
      "r2_score:  -0.9487789869308472\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1275, device='cuda:0')\n",
      "r2_score:  -0.8636597394943237\n",
      "Epoch 74:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9842510223388672\n",
      "Epoch 74:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9874017238616943\n",
      "Epoch 74:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9835622310638428\n",
      "Epoch 74:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9803637266159058\n",
      "Epoch 74:  36%|███▋      | 4/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9840373992919922\n",
      "Epoch 74:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9826313257217407\n",
      "Epoch 74:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898237586021423\n",
      "Epoch 74:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9847560524940491\n",
      "Epoch 74:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9864025115966797\n",
      "Epoch 74:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9868638515472412\n",
      "Epoch 74:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9875865578651428\n",
      "Epoch 74: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1441, device='cuda:0')\n",
      "r2_score:  -0.9456400871276855\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1272, device='cuda:0')\n",
      "r2_score:  -0.859700083732605\n",
      "Epoch 75:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9869816899299622\n",
      "Epoch 75:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9870222210884094\n",
      "Epoch 75:  18%|█▊        | 2/11 [00:01<00:06,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.984752893447876\n",
      "Epoch 75:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.989861249923706\n",
      "Epoch 75:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9843229055404663\n",
      "Epoch 75:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9840662479400635\n",
      "Epoch 75:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9878168106079102\n",
      "Epoch 75:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9846082925796509\n",
      "Epoch 75:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9830619096755981\n",
      "Epoch 75:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9829869866371155\n",
      "Epoch 75:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9896764159202576\n",
      "Epoch 75: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1441, device='cuda:0')\n",
      "r2_score:  -0.9454606771469116\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1272, device='cuda:0')\n",
      "r2_score:  -0.8592116832733154\n",
      "Epoch 76:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9848471879959106\n",
      "Epoch 76:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9877826571464539\n",
      "Epoch 76:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898143410682678\n",
      "Epoch 76:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9820327758789062\n",
      "Epoch 76:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9887290596961975\n",
      "Epoch 76:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9833697080612183\n",
      "Epoch 76:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9847796559333801\n",
      "Epoch 76:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9837327599525452\n",
      "Epoch 76:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9868101477622986\n",
      "Epoch 76:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.987341046333313\n",
      "Epoch 76:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9899011254310608\n",
      "Epoch 76: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1450, device='cuda:0')\n",
      "r2_score:  -0.9570286273956299\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1277, device='cuda:0')\n",
      "r2_score:  -0.866646409034729\n",
      "Epoch 77:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.981397271156311\n",
      "Epoch 77:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9868956804275513\n",
      "Epoch 77:  18%|█▊        | 2/11 [00:01<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9896255135536194\n",
      "Epoch 77:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9896465539932251\n",
      "Epoch 77:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9882434010505676\n",
      "Epoch 77:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9864318370819092\n",
      "Epoch 77:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9796746373176575\n",
      "Epoch 77:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9876015782356262\n",
      "Epoch 77:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9878695607185364\n",
      "Epoch 77:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9917575716972351\n",
      "Epoch 77:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9818056225776672\n",
      "Epoch 77: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1446, device='cuda:0')\n",
      "r2_score:  -0.9521739482879639\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1276, device='cuda:0')\n",
      "r2_score:  -0.8654187917709351\n",
      "Epoch 78:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9877903461456299\n",
      "Epoch 78:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9885037541389465\n",
      "Epoch 78:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9875332713127136\n",
      "Epoch 78:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9825341105461121\n",
      "Epoch 78:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.987529456615448\n",
      "Epoch 78:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9917657971382141\n",
      "Epoch 78:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.986221194267273\n",
      "Epoch 78:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9912753105163574\n",
      "Epoch 78:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9820798635482788\n",
      "Epoch 78:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9845794439315796\n",
      "Epoch 78:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898226857185364\n",
      "Epoch 78: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1453, device='cuda:0')\n",
      "r2_score:  -0.9616221189498901\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1285, device='cuda:0')\n",
      "r2_score:  -0.8782336711883545\n",
      "Epoch 79:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9824921488761902\n",
      "Epoch 79:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9882736802101135\n",
      "Epoch 79:  18%|█▊        | 2/11 [00:01<00:06,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9918937683105469\n",
      "Epoch 79:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9846116304397583\n",
      "Epoch 79:  36%|███▋      | 4/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9853449463844299\n",
      "Epoch 79:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9900107383728027\n",
      "Epoch 79:  55%|█████▍    | 6/11 [00:04<00:03,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9920847415924072\n",
      "Epoch 79:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9906262755393982\n",
      "Epoch 79:  73%|███████▎  | 8/11 [00:05<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.987084150314331\n",
      "Epoch 79:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9833505153656006\n",
      "Epoch 79:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9862610101699829\n",
      "Epoch 79: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1457, device='cuda:0')\n",
      "r2_score:  -0.9660936594009399\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1282, device='cuda:0')\n",
      "r2_score:  -0.8742420673370361\n",
      "Epoch 80:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9915897250175476\n",
      "Epoch 80:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9868371486663818\n",
      "Epoch 80:  18%|█▊        | 2/11 [00:01<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9887371063232422\n",
      "Epoch 80:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9901279807090759\n",
      "Epoch 80:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9882258772850037\n",
      "Epoch 80:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9881489872932434\n",
      "Epoch 80:  55%|█████▍    | 6/11 [00:04<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9856873750686646\n",
      "Epoch 80:  64%|██████▎   | 7/11 [00:04<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9874406456947327\n",
      "Epoch 80:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9827192425727844\n",
      "Epoch 80:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9912151098251343\n",
      "Epoch 80:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9854110479354858\n",
      "Epoch 80: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1445, device='cuda:0')\n",
      "r2_score:  -0.9498717784881592\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1281, device='cuda:0')\n",
      "r2_score:  -0.8721760511398315\n",
      "Epoch 81:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9884322285652161\n",
      "Epoch 81:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9868600368499756\n",
      "Epoch 81:  18%|█▊        | 2/11 [00:01<00:06,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9882796406745911\n",
      "Epoch 81:  27%|██▋       | 3/11 [00:02<00:05,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.986426055431366\n",
      "Epoch 81:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9887967109680176\n",
      "Epoch 81:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9891040921211243\n",
      "Epoch 81:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9886375069618225\n",
      "Epoch 81:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9888884425163269\n",
      "Epoch 81:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9875075817108154\n",
      "Epoch 81:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9884493947029114\n",
      "Epoch 81:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898501038551331\n",
      "Epoch 81: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1455, device='cuda:0')\n",
      "r2_score:  -0.9641889333724976\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1283, device='cuda:0')\n",
      "r2_score:  -0.8756281137466431\n",
      "Epoch 82:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923492074012756\n",
      "Epoch 82:   9%|▉         | 1/11 [00:00<00:07,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9872062802314758\n",
      "Epoch 82:  18%|█▊        | 2/11 [00:01<00:07,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9840856194496155\n",
      "Epoch 82:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9877500534057617\n",
      "Epoch 82:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9903131127357483\n",
      "Epoch 82:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9889538288116455\n",
      "Epoch 82:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9856627583503723\n",
      "Epoch 82:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9899544715881348\n",
      "Epoch 82:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9924902319908142\n",
      "Epoch 82:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9903057217597961\n",
      "Epoch 82:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9870296120643616\n",
      "Epoch 82: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1455, device='cuda:0')\n",
      "r2_score:  -0.9637620449066162\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1293, device='cuda:0')\n",
      "r2_score:  -0.8894650936126709\n",
      "Epoch 83:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9888963103294373\n",
      "Epoch 83:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9904696345329285\n",
      "Epoch 83:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898741841316223\n",
      "Epoch 83:  27%|██▋       | 3/11 [00:02<00:05,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909472465515137\n",
      "Epoch 83:  36%|███▋      | 4/11 [00:02<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9860849976539612\n",
      "Epoch 83:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9866108298301697\n",
      "Epoch 83:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.991605281829834\n",
      "Epoch 83:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9895292520523071\n",
      "Epoch 83:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9902283549308777\n",
      "Epoch 83:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9896309971809387\n",
      "Epoch 83:  91%|█████████ | 10/11 [00:06<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9861724972724915\n",
      "Epoch 83: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1449, device='cuda:0')\n",
      "r2_score:  -0.9559738636016846\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1284, device='cuda:0')\n",
      "r2_score:  -0.8767298460006714\n",
      "Epoch 84:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9885125160217285\n",
      "Epoch 84:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9886201620101929\n",
      "Epoch 84:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9935153126716614\n",
      "Epoch 84:  27%|██▋       | 3/11 [00:02<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9904167652130127\n",
      "Epoch 84:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9906395077705383\n",
      "Epoch 84:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909247159957886\n",
      "Epoch 84:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9886114001274109\n",
      "Epoch 84:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9863885641098022\n",
      "Epoch 84:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9925844073295593\n",
      "Epoch 84:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9879268407821655\n",
      "Epoch 84:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9864595532417297\n",
      "Epoch 84: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1461, device='cuda:0')\n",
      "r2_score:  -0.9725902080535889\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1291, device='cuda:0')\n",
      "r2_score:  -0.8875083923339844\n",
      "Epoch 85:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9901481866836548\n",
      "Epoch 85:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9925837516784668\n",
      "Epoch 85:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9915892481803894\n",
      "Epoch 85:  27%|██▋       | 3/11 [00:02<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909771084785461\n",
      "Epoch 85:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9887793660163879\n",
      "Epoch 85:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9900882244110107\n",
      "Epoch 85:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9883884191513062\n",
      "Epoch 85:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9854151606559753\n",
      "Epoch 85:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9912481307983398\n",
      "Epoch 85:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9919687509536743\n",
      "Epoch 85:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.987509548664093\n",
      "Epoch 85: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1457, device='cuda:0')\n",
      "r2_score:  -0.9672640562057495\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1292, device='cuda:0')\n",
      "r2_score:  -0.8886100053787231\n",
      "Epoch 86:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9886980056762695\n",
      "Epoch 86:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.991159975528717\n",
      "Epoch 86:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9874964356422424\n",
      "Epoch 86:  27%|██▋       | 3/11 [00:02<00:05,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9925144910812378\n",
      "Epoch 86:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9922230243682861\n",
      "Epoch 86:  45%|████▌     | 5/11 [00:03<00:04,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9944115281105042\n",
      "Epoch 86:  55%|█████▍    | 6/11 [00:04<00:03,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.990644097328186\n",
      "Epoch 86:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9913582801818848\n",
      "Epoch 86:  73%|███████▎  | 8/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9858670234680176\n",
      "Epoch 86:  82%|████████▏ | 9/11 [00:06<00:01,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9905046224594116\n",
      "Epoch 86:  91%|█████████ | 10/11 [00:07<00:00,  1.32it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9896778464317322\n",
      "Epoch 86: 100%|██████████| 11/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1456, device='cuda:0')\n",
      "r2_score:  -0.9653524160385132\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1298, device='cuda:0')\n",
      "r2_score:  -0.897324800491333\n",
      "Epoch 87:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.990566611289978\n",
      "Epoch 87:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909459948539734\n",
      "Epoch 87:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909101724624634\n",
      "Epoch 87:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9915867447853088\n",
      "Epoch 87:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9869240522384644\n",
      "Epoch 87:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9916985630989075\n",
      "Epoch 87:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9908061027526855\n",
      "Epoch 87:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9912429451942444\n",
      "Epoch 87:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9929473996162415\n",
      "Epoch 87:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9879505038261414\n",
      "Epoch 87:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9926873445510864\n",
      "Epoch 87: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1451, device='cuda:0')\n",
      "r2_score:  -0.9584071636199951\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1294, device='cuda:0')\n",
      "r2_score:  -0.8922405242919922\n",
      "Epoch 88:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9926076531410217\n",
      "Epoch 88:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.990307629108429\n",
      "Epoch 88:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9918568730354309\n",
      "Epoch 88:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9907659292221069\n",
      "Epoch 88:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9926135540008545\n",
      "Epoch 88:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940203428268433\n",
      "Epoch 88:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898349642753601\n",
      "Epoch 88:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9891424179077148\n",
      "Epoch 88:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9920293688774109\n",
      "Epoch 88:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9895174503326416\n",
      "Epoch 88:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9883894920349121\n",
      "Epoch 88: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1458, device='cuda:0')\n",
      "r2_score:  -0.9673846960067749\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1295, device='cuda:0')\n",
      "r2_score:  -0.8934632539749146\n",
      "Epoch 89:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923440217971802\n",
      "Epoch 89:   9%|▉         | 1/11 [00:00<00:06,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.992200493812561\n",
      "Epoch 89:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9885661602020264\n",
      "Epoch 89:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995516836643219\n",
      "Epoch 89:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9883089661598206\n",
      "Epoch 89:  45%|████▌     | 5/11 [00:03<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9922580122947693\n",
      "Epoch 89:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9891095161437988\n",
      "Epoch 89:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9938227534294128\n",
      "Epoch 89:  73%|███████▎  | 8/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9902550578117371\n",
      "Epoch 89:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9903503060340881\n",
      "Epoch 89:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9943264126777649\n",
      "Epoch 89: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1455, device='cuda:0')\n",
      "r2_score:  -0.9642194509506226\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1296, device='cuda:0')\n",
      "r2_score:  -0.8941737413406372\n",
      "Epoch 90:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9946703314781189\n",
      "Epoch 90:   9%|▉         | 1/11 [00:00<00:08,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923231601715088\n",
      "Epoch 90:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9932944178581238\n",
      "Epoch 90:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.988474428653717\n",
      "Epoch 90:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921982884407043\n",
      "Epoch 90:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9898310899734497\n",
      "Epoch 90:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.991747260093689\n",
      "Epoch 90:  64%|██████▎   | 7/11 [00:04<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9910600185394287\n",
      "Epoch 90:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9925245642662048\n",
      "Epoch 90:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9914998412132263\n",
      "Epoch 90:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9933814406394958\n",
      "Epoch 90: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1462, device='cuda:0')\n",
      "r2_score:  -0.9730708599090576\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1298, device='cuda:0')\n",
      "r2_score:  -0.8971143960952759\n",
      "Epoch 91:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9946770071983337\n",
      "Epoch 91:   9%|▉         | 1/11 [00:00<00:07,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9906407594680786\n",
      "Epoch 91:  18%|█▊        | 2/11 [00:01<00:06,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921383857727051\n",
      "Epoch 91:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9934121370315552\n",
      "Epoch 91:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993701696395874\n",
      "Epoch 91:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9925689101219177\n",
      "Epoch 91:  55%|█████▍    | 6/11 [00:04<00:03,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9934645891189575\n",
      "Epoch 91:  64%|██████▎   | 7/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9907487034797668\n",
      "Epoch 91:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923376441001892\n",
      "Epoch 91:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9895684719085693\n",
      "Epoch 91:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9869062900543213\n",
      "Epoch 91: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1462, device='cuda:0')\n",
      "r2_score:  -0.9733574390411377\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1301, device='cuda:0')\n",
      "r2_score:  -0.901896595954895\n",
      "Epoch 92:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9935010671615601\n",
      "Epoch 92:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9959530830383301\n",
      "Epoch 92:  18%|█▊        | 2/11 [00:01<00:05,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9930254220962524\n",
      "Epoch 92:  27%|██▋       | 3/11 [00:01<00:05,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9935682415962219\n",
      "Epoch 92:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.988508403301239\n",
      "Epoch 92:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909965395927429\n",
      "Epoch 92:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9925945997238159\n",
      "Epoch 92:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9914695620536804\n",
      "Epoch 92:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9914655685424805\n",
      "Epoch 92:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9938356876373291\n",
      "Epoch 92:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921730756759644\n",
      "Epoch 92: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1463, device='cuda:0')\n",
      "r2_score:  -0.974579930305481\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1304, device='cuda:0')\n",
      "r2_score:  -0.906777024269104\n",
      "Epoch 93:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9943845868110657\n",
      "Epoch 93:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9920302629470825\n",
      "Epoch 93:  18%|█▊        | 2/11 [00:01<00:05,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940056800842285\n",
      "Epoch 93:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.988844096660614\n",
      "Epoch 93:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9926775693893433\n",
      "Epoch 93:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9955161809921265\n",
      "Epoch 93:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9932800531387329\n",
      "Epoch 93:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9928478598594666\n",
      "Epoch 93:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9885920882225037\n",
      "Epoch 93:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9942789673805237\n",
      "Epoch 93:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923281669616699\n",
      "Epoch 93: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1463, device='cuda:0')\n",
      "r2_score:  -0.974401593208313\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1306, device='cuda:0')\n",
      "r2_score:  -0.9088767766952515\n",
      "Epoch 94:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9927065372467041\n",
      "Epoch 94:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9913801550865173\n",
      "Epoch 94:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921482801437378\n",
      "Epoch 94:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9906132221221924\n",
      "Epoch 94:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9933819770812988\n",
      "Epoch 94:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9934436082839966\n",
      "Epoch 94:  55%|█████▍    | 6/11 [00:03<00:03,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9932976961135864\n",
      "Epoch 94:  64%|██████▎   | 7/11 [00:04<00:02,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9933185577392578\n",
      "Epoch 94:  73%|███████▎  | 8/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9944092631340027\n",
      "Epoch 94:  82%|████████▏ | 9/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9938686490058899\n",
      "Epoch 94:  91%|█████████ | 10/11 [00:06<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994438886642456\n",
      "Epoch 94: 100%|██████████| 11/11 [00:06<00:00,  1.61it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1463, device='cuda:0')\n",
      "r2_score:  -0.9742354154586792\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1304, device='cuda:0')\n",
      "r2_score:  -0.9063174724578857\n",
      "Epoch 95:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9930264949798584\n",
      "Epoch 95:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993720293045044\n",
      "Epoch 95:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.990739643573761\n",
      "Epoch 95:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9941076636314392\n",
      "Epoch 95:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995234489440918\n",
      "Epoch 95:  45%|████▌     | 5/11 [00:03<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99309903383255\n",
      "Epoch 95:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9949996471405029\n",
      "Epoch 95:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9901487231254578\n",
      "Epoch 95:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993277370929718\n",
      "Epoch 95:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954960942268372\n",
      "Epoch 95:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9918549656867981\n",
      "Epoch 95: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1462, device='cuda:0')\n",
      "r2_score:  -0.9728797674179077\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1308, device='cuda:0')\n",
      "r2_score:  -0.9114152193069458\n",
      "Epoch 96:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921433329582214\n",
      "Epoch 96:   9%|▉         | 1/11 [00:00<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9944347143173218\n",
      "Epoch 96:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9950204491615295\n",
      "Epoch 96:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9878553748130798\n",
      "Epoch 96:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9945817589759827\n",
      "Epoch 96:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9941603541374207\n",
      "Epoch 96:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921684861183167\n",
      "Epoch 96:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995663046836853\n",
      "Epoch 96:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953511357307434\n",
      "Epoch 96:  82%|████████▏ | 9/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.991699755191803\n",
      "Epoch 96:  91%|█████████ | 10/11 [00:06<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9947547912597656\n",
      "Epoch 96: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1462, device='cuda:0')\n",
      "r2_score:  -0.9727667570114136\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1303, device='cuda:0')\n",
      "r2_score:  -0.9052619934082031\n",
      "Epoch 97:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954094290733337\n",
      "Epoch 97:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994053065776825\n",
      "Epoch 97:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993281900882721\n",
      "Epoch 97:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9917117357254028\n",
      "Epoch 97:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9933288097381592\n",
      "Epoch 97:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923956394195557\n",
      "Epoch 97:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9934660196304321\n",
      "Epoch 97:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9939354062080383\n",
      "Epoch 97:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9950584173202515\n",
      "Epoch 97:  82%|████████▏ | 9/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9944585561752319\n",
      "Epoch 97:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99332195520401\n",
      "Epoch 97: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1459, device='cuda:0')\n",
      "r2_score:  -0.969102144241333\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1305, device='cuda:0')\n",
      "r2_score:  -0.9075565338134766\n",
      "Epoch 98:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961389899253845\n",
      "Epoch 98:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953690767288208\n",
      "Epoch 98:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9937863349914551\n",
      "Epoch 98:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9956153631210327\n",
      "Epoch 98:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9943652749061584\n",
      "Epoch 98:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.992294430732727\n",
      "Epoch 98:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9886581301689148\n",
      "Epoch 98:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9931811094284058\n",
      "Epoch 98:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940690994262695\n",
      "Epoch 98:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9950660467147827\n",
      "Epoch 98:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9941694140434265\n",
      "Epoch 98: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1457, device='cuda:0')\n",
      "r2_score:  -0.9663776159286499\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1302, device='cuda:0')\n",
      "r2_score:  -0.9030604362487793\n",
      "Epoch 99:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9943421483039856\n",
      "Epoch 99:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954315423965454\n",
      "Epoch 99:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940820336341858\n",
      "Epoch 99:  27%|██▋       | 3/11 [00:02<00:05,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994010865688324\n",
      "Epoch 99:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9934371709823608\n",
      "Epoch 99:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9946544170379639\n",
      "Epoch 99:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9946242570877075\n",
      "Epoch 99:  64%|██████▎   | 7/11 [00:04<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952675104141235\n",
      "Epoch 99:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9909231066703796\n",
      "Epoch 99:  82%|████████▏ | 9/11 [00:06<00:01,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9924794435501099\n",
      "Epoch 99:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995171308517456\n",
      "Epoch 99: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1465, device='cuda:0')\n",
      "r2_score:  -0.9768227338790894\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1313, device='cuda:0')\n",
      "r2_score:  -0.919784426689148\n",
      "Epoch 100:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]        y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9942041635513306\n",
      "Epoch 100:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9946173429489136\n",
      "Epoch 100:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9931500554084778\n",
      "Epoch 100:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9945686459541321\n",
      "Epoch 100:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9942883253097534\n",
      "Epoch 100:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994921863079071\n",
      "Epoch 100:  55%|█████▍    | 6/11 [00:03<00:03,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9955739378929138\n",
      "Epoch 100:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99295973777771\n",
      "Epoch 100:  73%|███████▎  | 8/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995312511920929\n",
      "Epoch 100:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9937121868133545\n",
      "Epoch 100:  91%|█████████ | 10/11 [00:06<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996032178401947\n",
      "Epoch 100: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1467, device='cuda:0')\n",
      "r2_score:  -0.9799262285232544\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1313, device='cuda:0')\n",
      "r2_score:  -0.9197603464126587\n",
      "Epoch 101:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9946787357330322\n",
      "Epoch 101:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967414140701294\n",
      "Epoch 101:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995079755783081\n",
      "Epoch 101:  27%|██▋       | 3/11 [00:02<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9950124025344849\n",
      "Epoch 101:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9922091960906982\n",
      "Epoch 101:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9950161576271057\n",
      "Epoch 101:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993331253528595\n",
      "Epoch 101:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99305659532547\n",
      "Epoch 101:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953058362007141\n",
      "Epoch 101:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964389801025391\n",
      "Epoch 101:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940288066864014\n",
      "Epoch 101: 100%|██████████| 11/11 [00:06<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1468, device='cuda:0')\n",
      "r2_score:  -0.9807980060577393\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1321, device='cuda:0')\n",
      "r2_score:  -0.9315210580825806\n",
      "Epoch 102:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968141913414001\n",
      "Epoch 102:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9949625134468079\n",
      "Epoch 102:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994726836681366\n",
      "Epoch 102:  27%|██▋       | 3/11 [00:01<00:05,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940336346626282\n",
      "Epoch 102:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952720999717712\n",
      "Epoch 102:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9942013025283813\n",
      "Epoch 102:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961475133895874\n",
      "Epoch 102:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9942878484725952\n",
      "Epoch 102:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9920181035995483\n",
      "Epoch 102:  82%|████████▏ | 9/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9949590563774109\n",
      "Epoch 102:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967241883277893\n",
      "Epoch 102: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1462, device='cuda:0')\n",
      "r2_score:  -0.9737474918365479\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1308, device='cuda:0')\n",
      "r2_score:  -0.9117494821548462\n",
      "Epoch 103:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965789318084717\n",
      "Epoch 103:   9%|▉         | 1/11 [00:00<00:06,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954549074172974\n",
      "Epoch 103:  18%|█▊        | 2/11 [00:01<00:05,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964249730110168\n",
      "Epoch 103:  27%|██▋       | 3/11 [00:01<00:05,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996471643447876\n",
      "Epoch 103:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9922024607658386\n",
      "Epoch 103:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9955291748046875\n",
      "Epoch 103:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9945904612541199\n",
      "Epoch 103:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9963535666465759\n",
      "Epoch 103:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9935895800590515\n",
      "Epoch 103:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993557333946228\n",
      "Epoch 103:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9937461018562317\n",
      "Epoch 103: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1466, device='cuda:0')\n",
      "r2_score:  -0.9784817695617676\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1315, device='cuda:0')\n",
      "r2_score:  -0.9229295253753662\n",
      "Epoch 104:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9966297149658203\n",
      "Epoch 104:   9%|▉         | 1/11 [00:00<00:07,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9938769936561584\n",
      "Epoch 104:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9957073926925659\n",
      "Epoch 104:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953704476356506\n",
      "Epoch 104:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9958436489105225\n",
      "Epoch 104:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953291416168213\n",
      "Epoch 104:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9955766201019287\n",
      "Epoch 104:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9932011961936951\n",
      "Epoch 104:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9957475066184998\n",
      "Epoch 104:  82%|████████▏ | 9/11 [00:06<00:01,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953492879867554\n",
      "Epoch 104:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952672719955444\n",
      "Epoch 104: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1464, device='cuda:0')\n",
      "r2_score:  -0.9757052659988403\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1314, device='cuda:0')\n",
      "r2_score:  -0.9206138849258423\n",
      "Epoch 105:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965890049934387\n",
      "Epoch 105:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967435002326965\n",
      "Epoch 105:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9962022304534912\n",
      "Epoch 105:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9921119809150696\n",
      "Epoch 105:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967415928840637\n",
      "Epoch 105:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954718351364136\n",
      "Epoch 105:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993566632270813\n",
      "Epoch 105:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967665672302246\n",
      "Epoch 105:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954178929328918\n",
      "Epoch 105:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9947106242179871\n",
      "Epoch 105:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964026212692261\n",
      "Epoch 105: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1467, device='cuda:0')\n",
      "r2_score:  -0.9803241491317749\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1319, device='cuda:0')\n",
      "r2_score:  -0.9283580780029297\n",
      "Epoch 106:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9972794055938721\n",
      "Epoch 106:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960848689079285\n",
      "Epoch 106:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9958580732345581\n",
      "Epoch 106:  27%|██▋       | 3/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994649350643158\n",
      "Epoch 106:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.993723452091217\n",
      "Epoch 106:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9949126839637756\n",
      "Epoch 106:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9959519505500793\n",
      "Epoch 106:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997256338596344\n",
      "Epoch 106:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952787160873413\n",
      "Epoch 106:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9950504899024963\n",
      "Epoch 106:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9955286383628845\n",
      "Epoch 106: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1465, device='cuda:0')\n",
      "r2_score:  -0.9773670434951782\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1320, device='cuda:0')\n",
      "r2_score:  -0.9296950101852417\n",
      "Epoch 107:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960845708847046\n",
      "Epoch 107:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960029125213623\n",
      "Epoch 107:  18%|█▊        | 2/11 [00:01<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968875050544739\n",
      "Epoch 107:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961154460906982\n",
      "Epoch 107:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9940938949584961\n",
      "Epoch 107:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9959231615066528\n",
      "Epoch 107:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9954643845558167\n",
      "Epoch 107:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964607954025269\n",
      "Epoch 107:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967343807220459\n",
      "Epoch 107:  82%|████████▏ | 9/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9958484172821045\n",
      "Epoch 107:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9916859865188599\n",
      "Epoch 107: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1469, device='cuda:0')\n",
      "r2_score:  -0.9826668500900269\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1327, device='cuda:0')\n",
      "r2_score:  -0.9399029016494751\n",
      "Epoch 108:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996090292930603\n",
      "Epoch 108:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996100902557373\n",
      "Epoch 108:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9944841861724854\n",
      "Epoch 108:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9948100447654724\n",
      "Epoch 108:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996928334236145\n",
      "Epoch 108:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953586459159851\n",
      "Epoch 108:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9958789348602295\n",
      "Epoch 108:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9966740012168884\n",
      "Epoch 108:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960688948631287\n",
      "Epoch 108:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960850477218628\n",
      "Epoch 108:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9956099987030029\n",
      "Epoch 108: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1473, device='cuda:0')\n",
      "r2_score:  -0.9879684448242188\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1323, device='cuda:0')\n",
      "r2_score:  -0.9335222244262695\n",
      "Epoch 109:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9958526492118835\n",
      "Epoch 109:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974339604377747\n",
      "Epoch 109:  18%|█▊        | 2/11 [00:01<00:06,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.995692253112793\n",
      "Epoch 109:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960436224937439\n",
      "Epoch 109:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9956874251365662\n",
      "Epoch 109:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9958645701408386\n",
      "Epoch 109:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996945321559906\n",
      "Epoch 109:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969376921653748\n",
      "Epoch 109:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.994591474533081\n",
      "Epoch 109:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9959498643875122\n",
      "Epoch 109:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9956307411193848\n",
      "Epoch 109: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1469, device='cuda:0')\n",
      "r2_score:  -0.9824460744857788\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1324, device='cuda:0')\n",
      "r2_score:  -0.9355394840240479\n",
      "Epoch 110:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967979192733765\n",
      "Epoch 110:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967226386070251\n",
      "Epoch 110:  18%|█▊        | 2/11 [00:01<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961656928062439\n",
      "Epoch 110:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9971107244491577\n",
      "Epoch 110:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9943233132362366\n",
      "Epoch 110:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9963626861572266\n",
      "Epoch 110:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9966207146644592\n",
      "Epoch 110:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969647526741028\n",
      "Epoch 110:  73%|███████▎  | 8/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996609091758728\n",
      "Epoch 110:  82%|████████▏ | 9/11 [00:05<00:01,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952369928359985\n",
      "Epoch 110:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9966262578964233\n",
      "Epoch 110: 100%|██████████| 11/11 [00:06<00:00,  1.60it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1471, device='cuda:0')\n",
      "r2_score:  -0.9855678081512451\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1326, device='cuda:0')\n",
      "r2_score:  -0.9378139972686768\n",
      "Epoch 111:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9955825805664062\n",
      "Epoch 111:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9959967136383057\n",
      "Epoch 111:  18%|█▊        | 2/11 [00:01<00:07,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967380166053772\n",
      "Epoch 111:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9957035183906555\n",
      "Epoch 111:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974124431610107\n",
      "Epoch 111:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960282444953918\n",
      "Epoch 111:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9972147941589355\n",
      "Epoch 111:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997081458568573\n",
      "Epoch 111:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967668056488037\n",
      "Epoch 111:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980481863021851\n",
      "Epoch 111:  91%|█████████ | 10/11 [00:06<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9923394918441772\n",
      "Epoch 111: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1469, device='cuda:0')\n",
      "r2_score:  -0.9834725856781006\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1330, device='cuda:0')\n",
      "r2_score:  -0.9448370933532715\n",
      "Epoch 112:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965935349464417\n",
      "Epoch 112:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961065053939819\n",
      "Epoch 112:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9945826530456543\n",
      "Epoch 112:  27%|██▋       | 3/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969745874404907\n",
      "Epoch 112:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996648371219635\n",
      "Epoch 112:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975062012672424\n",
      "Epoch 112:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996588945388794\n",
      "Epoch 112:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967446327209473\n",
      "Epoch 112:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969373345375061\n",
      "Epoch 112:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9966489672660828\n",
      "Epoch 112:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961094856262207\n",
      "Epoch 112: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1473, device='cuda:0')\n",
      "r2_score:  -0.9881823062896729\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1329, device='cuda:0')\n",
      "r2_score:  -0.942163348197937\n",
      "Epoch 113:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975910186767578\n",
      "Epoch 113:   9%|▉         | 1/11 [00:00<00:07,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997225284576416\n",
      "Epoch 113:  18%|█▊        | 2/11 [00:01<00:06,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961681962013245\n",
      "Epoch 113:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974034428596497\n",
      "Epoch 113:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965805411338806\n",
      "Epoch 113:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99464350938797\n",
      "Epoch 113:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964364767074585\n",
      "Epoch 113:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960171580314636\n",
      "Epoch 113:  73%|███████▎  | 8/11 [00:05<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969956874847412\n",
      "Epoch 113:  82%|████████▏ | 9/11 [00:06<00:01,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969766736030579\n",
      "Epoch 113:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976916313171387\n",
      "Epoch 113: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1476, device='cuda:0')\n",
      "r2_score:  -0.9919133186340332\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1328, device='cuda:0')\n",
      "r2_score:  -0.9415639638900757\n",
      "Epoch 114:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9972254037857056\n",
      "Epoch 114:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953328371047974\n",
      "Epoch 114:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9973764419555664\n",
      "Epoch 114:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997130811214447\n",
      "Epoch 114:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9962612986564636\n",
      "Epoch 114:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960770606994629\n",
      "Epoch 114:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977093935012817\n",
      "Epoch 114:  64%|██████▎   | 7/11 [00:04<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998146116733551\n",
      "Epoch 114:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9959301352500916\n",
      "Epoch 114:  82%|████████▏ | 9/11 [00:06<00:01,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9960446953773499\n",
      "Epoch 114:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9973458647727966\n",
      "Epoch 114: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1474, device='cuda:0')\n",
      "r2_score:  -0.9900970458984375\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1336, device='cuda:0')\n",
      "r2_score:  -0.9524574279785156\n",
      "Epoch 115:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969407916069031\n",
      "Epoch 115:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977232813835144\n",
      "Epoch 115:  18%|█▊        | 2/11 [00:01<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967031478881836\n",
      "Epoch 115:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975296854972839\n",
      "Epoch 115:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9961866140365601\n",
      "Epoch 115:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965006113052368\n",
      "Epoch 115:  55%|█████▍    | 6/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977478981018066\n",
      "Epoch 115:  64%|██████▎   | 7/11 [00:04<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952521324157715\n",
      "Epoch 115:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967586994171143\n",
      "Epoch 115:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976943731307983\n",
      "Epoch 115:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99781733751297\n",
      "Epoch 115: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1471, device='cuda:0')\n",
      "r2_score:  -0.9848698377609253\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1331, device='cuda:0')\n",
      "r2_score:  -0.9459879398345947\n",
      "Epoch 116:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9951117038726807\n",
      "Epoch 116:   9%|▉         | 1/11 [00:00<00:06,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953343868255615\n",
      "Epoch 116:  18%|█▊        | 2/11 [00:01<00:06,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982477426528931\n",
      "Epoch 116:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99644935131073\n",
      "Epoch 116:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997882604598999\n",
      "Epoch 116:  45%|████▌     | 5/11 [00:03<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976586103439331\n",
      "Epoch 116:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977422952651978\n",
      "Epoch 116:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979112148284912\n",
      "Epoch 116:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9962049722671509\n",
      "Epoch 116:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997597873210907\n",
      "Epoch 116:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977890253067017\n",
      "Epoch 116: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1474, device='cuda:0')\n",
      "r2_score:  -0.9900416135787964\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1333, device='cuda:0')\n",
      "r2_score:  -0.9491060972213745\n",
      "Epoch 117:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975389838218689\n",
      "Epoch 117:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974784255027771\n",
      "Epoch 117:  18%|█▊        | 2/11 [00:01<00:05,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9942298531532288\n",
      "Epoch 117:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975022673606873\n",
      "Epoch 117:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977887868881226\n",
      "Epoch 117:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9970262050628662\n",
      "Epoch 117:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981053471565247\n",
      "Epoch 117:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968962669372559\n",
      "Epoch 117:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974780678749084\n",
      "Epoch 117:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9973174929618835\n",
      "Epoch 117:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976730942726135\n",
      "Epoch 117: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1473, device='cuda:0')\n",
      "r2_score:  -0.9880588054656982\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1331, device='cuda:0')\n",
      "r2_score:  -0.9460225105285645\n",
      "Epoch 118:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982870221138\n",
      "Epoch 118:   9%|▉         | 1/11 [00:00<00:07,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977529048919678\n",
      "Epoch 118:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9953128099441528\n",
      "Epoch 118:  27%|██▋       | 3/11 [00:02<00:05,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977975487709045\n",
      "Epoch 118:  36%|███▋      | 4/11 [00:03<00:05,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99772709608078\n",
      "Epoch 118:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979748725891113\n",
      "Epoch 118:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967617988586426\n",
      "Epoch 118:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997810959815979\n",
      "Epoch 118:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965522885322571\n",
      "Epoch 118:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969021081924438\n",
      "Epoch 118:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979121685028076\n",
      "Epoch 118: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1475, device='cuda:0')\n",
      "r2_score:  -0.9913842678070068\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1335, device='cuda:0')\n",
      "r2_score:  -0.9508744478225708\n",
      "Epoch 119:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968160390853882\n",
      "Epoch 119:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974433779716492\n",
      "Epoch 119:  18%|█▊        | 2/11 [00:01<00:06,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9973340034484863\n",
      "Epoch 119:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9962565898895264\n",
      "Epoch 119:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9972854256629944\n",
      "Epoch 119:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976044297218323\n",
      "Epoch 119:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980088472366333\n",
      "Epoch 119:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979482293128967\n",
      "Epoch 119:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974260330200195\n",
      "Epoch 119:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987698197364807\n",
      "Epoch 119:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964174628257751\n",
      "Epoch 119: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1474, device='cuda:0')\n",
      "r2_score:  -0.9890483617782593\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1333, device='cuda:0')\n",
      "r2_score:  -0.94879150390625\n",
      "Epoch 120:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975705742835999\n",
      "Epoch 120:   9%|▉         | 1/11 [00:00<00:06,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9972798228263855\n",
      "Epoch 120:  18%|█▊        | 2/11 [00:01<00:05,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974597692489624\n",
      "Epoch 120:  27%|██▋       | 3/11 [00:01<00:05,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977361559867859\n",
      "Epoch 120:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964359998703003\n",
      "Epoch 120:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986326694488525\n",
      "Epoch 120:  55%|█████▍    | 6/11 [00:04<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978505373001099\n",
      "Epoch 120:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978424310684204\n",
      "Epoch 120:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9974228143692017\n",
      "Epoch 120:  82%|████████▏ | 9/11 [00:06<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984696507453918\n",
      "Epoch 120:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9951706528663635\n",
      "Epoch 120: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1478, device='cuda:0')\n",
      "r2_score:  -0.9954447746276855\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1340, device='cuda:0')\n",
      "r2_score:  -0.9580717086791992\n",
      "Epoch 121:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984183311462402\n",
      "Epoch 121:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9957992434501648\n",
      "Epoch 121:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978880882263184\n",
      "Epoch 121:  27%|██▋       | 3/11 [00:02<00:05,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998206377029419\n",
      "Epoch 121:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9971421957015991\n",
      "Epoch 121:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975430965423584\n",
      "Epoch 121:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998329758644104\n",
      "Epoch 121:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969710111618042\n",
      "Epoch 121:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9969626665115356\n",
      "Epoch 121:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979807734489441\n",
      "Epoch 121:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976660013198853\n",
      "Epoch 121: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1476, device='cuda:0')\n",
      "r2_score:  -0.9927585124969482\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1336, device='cuda:0')\n",
      "r2_score:  -0.9522223472595215\n",
      "Epoch 122:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981691837310791\n",
      "Epoch 122:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983013272285461\n",
      "Epoch 122:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9952182173728943\n",
      "Epoch 122:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997188925743103\n",
      "Epoch 122:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984849691390991\n",
      "Epoch 122:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967195987701416\n",
      "Epoch 122:  55%|█████▍    | 6/11 [00:04<00:03,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998591959476471\n",
      "Epoch 122:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997674822807312\n",
      "Epoch 122:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975335597991943\n",
      "Epoch 122:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979866147041321\n",
      "Epoch 122:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976833462715149\n",
      "Epoch 122: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1472, device='cuda:0')\n",
      "r2_score:  -0.9866753816604614\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1338, device='cuda:0')\n",
      "r2_score:  -0.9562454223632812\n",
      "Epoch 123:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976221323013306\n",
      "Epoch 123:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975296258926392\n",
      "Epoch 123:  18%|█▊        | 2/11 [00:01<00:05,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980454444885254\n",
      "Epoch 123:  27%|██▋       | 3/11 [00:01<00:05,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980369806289673\n",
      "Epoch 123:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979165196418762\n",
      "Epoch 123:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985668063163757\n",
      "Epoch 123:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976789951324463\n",
      "Epoch 123:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9965834021568298\n",
      "Epoch 123:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979821443557739\n",
      "Epoch 123:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977771639823914\n",
      "Epoch 123:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975602030754089\n",
      "Epoch 123: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1481, device='cuda:0')\n",
      "r2_score:  -0.9983770847320557\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1339, device='cuda:0')\n",
      "r2_score:  -0.9578074216842651\n",
      "Epoch 124:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984685778617859\n",
      "Epoch 124:   9%|▉         | 1/11 [00:00<00:07,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975292086601257\n",
      "Epoch 124:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982461929321289\n",
      "Epoch 124:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981877207756042\n",
      "Epoch 124:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997910737991333\n",
      "Epoch 124:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968897104263306\n",
      "Epoch 124:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983591437339783\n",
      "Epoch 124:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984407424926758\n",
      "Epoch 124:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983841776847839\n",
      "Epoch 124:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968024492263794\n",
      "Epoch 124:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9966896772384644\n",
      "Epoch 124: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1472, device='cuda:0')\n",
      "r2_score:  -0.9870897531509399\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1341, device='cuda:0')\n",
      "r2_score:  -0.9606386423110962\n",
      "Epoch 125:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986992478370667\n",
      "Epoch 125:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978280663490295\n",
      "Epoch 125:  18%|█▊        | 2/11 [00:01<00:06,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981024861335754\n",
      "Epoch 125:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9973570704460144\n",
      "Epoch 125:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983623623847961\n",
      "Epoch 125:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997689425945282\n",
      "Epoch 125:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982900619506836\n",
      "Epoch 125:  64%|██████▎   | 7/11 [00:04<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985722303390503\n",
      "Epoch 125:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967588186264038\n",
      "Epoch 125:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979757070541382\n",
      "Epoch 125:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968084096908569\n",
      "Epoch 125: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1478, device='cuda:0')\n",
      "r2_score:  -0.9951804876327515\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1341, device='cuda:0')\n",
      "r2_score:  -0.9605724811553955\n",
      "Epoch 126:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983094334602356\n",
      "Epoch 126:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997975766658783\n",
      "Epoch 126:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982993602752686\n",
      "Epoch 126:  27%|██▋       | 3/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978623986244202\n",
      "Epoch 126:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984203577041626\n",
      "Epoch 126:  45%|████▌     | 5/11 [00:03<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984813928604126\n",
      "Epoch 126:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9972823858261108\n",
      "Epoch 126:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988888502120972\n",
      "Epoch 126:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9964785575866699\n",
      "Epoch 126:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979201555252075\n",
      "Epoch 126:  91%|█████████ | 10/11 [00:06<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977930188179016\n",
      "Epoch 126: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1479, device='cuda:0')\n",
      "r2_score:  -0.9957351684570312\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1342, device='cuda:0')\n",
      "r2_score:  -0.9615697860717773\n",
      "Epoch 127:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987078309059143\n",
      "Epoch 127:   9%|▉         | 1/11 [00:00<00:07,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980107545852661\n",
      "Epoch 127:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986045956611633\n",
      "Epoch 127:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.4087e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998867392539978\n",
      "Epoch 127:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998781144618988\n",
      "Epoch 127:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997886061668396\n",
      "Epoch 127:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987154603004456\n",
      "Epoch 127:  64%|██████▎   | 7/11 [00:04<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9967131018638611\n",
      "Epoch 127:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979686737060547\n",
      "Epoch 127:  82%|████████▏ | 9/11 [00:06<00:01,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9975677132606506\n",
      "Epoch 127:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976932406425476\n",
      "Epoch 127: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1481, device='cuda:0')\n",
      "r2_score:  -0.9989557266235352\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1342, device='cuda:0')\n",
      "r2_score:  -0.9619115591049194\n",
      "Epoch 128:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984453320503235\n",
      "Epoch 128:   9%|▉         | 1/11 [00:00<00:08,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998599648475647\n",
      "Epoch 128:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982694387435913\n",
      "Epoch 128:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9962263107299805\n",
      "Epoch 128:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982753992080688\n",
      "Epoch 128:  45%|████▌     | 5/11 [00:03<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983663558959961\n",
      "Epoch 128:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.3571e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987955689430237\n",
      "Epoch 128:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984333515167236\n",
      "Epoch 128:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981622099876404\n",
      "Epoch 128:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985312819480896\n",
      "Epoch 128:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980058073997498\n",
      "Epoch 128: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1477, device='cuda:0')\n",
      "r2_score:  -0.9935531616210938\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1341, device='cuda:0')\n",
      "r2_score:  -0.9595867395401001\n",
      "Epoch 129:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988514184951782\n",
      "Epoch 129:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9973233342170715\n",
      "Epoch 129:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986749291419983\n",
      "Epoch 129:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986185431480408\n",
      "Epoch 129:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978915452957153\n",
      "Epoch 129:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979758262634277\n",
      "Epoch 129:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.9148e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988704919815063\n",
      "Epoch 129:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983071088790894\n",
      "Epoch 129:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983232021331787\n",
      "Epoch 129:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986497163772583\n",
      "Epoch 129:  91%|█████████ | 10/11 [00:06<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997918963432312\n",
      "Epoch 129: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1479, device='cuda:0')\n",
      "r2_score:  -0.9966694116592407\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1345, device='cuda:0')\n",
      "r2_score:  -0.9663115739822388\n",
      "Epoch 130:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987457394599915\n",
      "Epoch 130:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983134269714355\n",
      "Epoch 130:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981721639633179\n",
      "Epoch 130:  27%|██▋       | 3/11 [00:02<00:05,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998197615146637\n",
      "Epoch 130:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986857771873474\n",
      "Epoch 130:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986138939857483\n",
      "Epoch 130:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984682202339172\n",
      "Epoch 130:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9976147413253784\n",
      "Epoch 130:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983646273612976\n",
      "Epoch 130:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988464117050171\n",
      "Epoch 130:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979852437973022\n",
      "Epoch 130: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1479, device='cuda:0')\n",
      "r2_score:  -0.9957505464553833\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1345, device='cuda:0')\n",
      "r2_score:  -0.966301441192627\n",
      "Epoch 131:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982688426971436\n",
      "Epoch 131:   9%|▉         | 1/11 [00:00<00:08,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981979727745056\n",
      "Epoch 131:  18%|█▊        | 2/11 [00:01<00:06,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998310923576355\n",
      "Epoch 131:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984156489372253\n",
      "Epoch 131:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8924e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989237189292908\n",
      "Epoch 131:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979159235954285\n",
      "Epoch 131:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986166954040527\n",
      "Epoch 131:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987204074859619\n",
      "Epoch 131:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986289143562317\n",
      "Epoch 131:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983534216880798\n",
      "Epoch 131:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.1474e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990066289901733\n",
      "Epoch 131: 100%|██████████| 11/11 [00:07<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1481, device='cuda:0')\n",
      "r2_score:  -0.9986821413040161\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1347, device='cuda:0')\n",
      "r2_score:  -0.9688366651535034\n",
      "Epoch 132:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987472891807556\n",
      "Epoch 132:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987948536872864\n",
      "Epoch 132:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.9760e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989327192306519\n",
      "Epoch 132:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997628390789032\n",
      "Epoch 132:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.5760e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991224408149719\n",
      "Epoch 132:  45%|████▌     | 5/11 [00:03<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997772753238678\n",
      "Epoch 132:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985739588737488\n",
      "Epoch 132:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.9600e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987819790840149\n",
      "Epoch 132:  73%|███████▎  | 8/11 [00:05<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.7970e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989559054374695\n",
      "Epoch 132:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985439777374268\n",
      "Epoch 132:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.997468113899231\n",
      "Epoch 132: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1478, device='cuda:0')\n",
      "r2_score:  -0.9954707622528076\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1343, device='cuda:0')\n",
      "r2_score:  -0.9637863636016846\n",
      "Epoch 133:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984397888183594\n",
      "Epoch 133:   9%|▉         | 1/11 [00:00<00:07,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985288381576538\n",
      "Epoch 133:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986087083816528\n",
      "Epoch 133:  27%|██▋       | 3/11 [00:02<00:05,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980857968330383\n",
      "Epoch 133:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985849857330322\n",
      "Epoch 133:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9530e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990964531898499\n",
      "Epoch 133:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3500e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989421367645264\n",
      "Epoch 133:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981626272201538\n",
      "Epoch 133:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.5627e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999448835849762\n",
      "Epoch 133:  82%|████████▏ | 9/11 [00:06<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.7883e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988856315612793\n",
      "Epoch 133:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9968560934066772\n",
      "Epoch 133: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1482, device='cuda:0')\n",
      "r2_score:  -0.9996938705444336\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1349, device='cuda:0')\n",
      "r2_score:  -0.9716691970825195\n",
      "Epoch 134:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983816742897034\n",
      "Epoch 134:   9%|▉         | 1/11 [00:00<00:07,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6557e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991117119789124\n",
      "Epoch 134:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985581636428833\n",
      "Epoch 134:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3573e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990653395652771\n",
      "Epoch 134:  36%|███▋      | 4/11 [00:02<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9980506300926208\n",
      "Epoch 134:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1923e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994036555290222\n",
      "Epoch 134:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.9178e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989964365959167\n",
      "Epoch 134:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9977248311042786\n",
      "Epoch 134:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985345602035522\n",
      "Epoch 134:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981635808944702\n",
      "Epoch 134:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.4273e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992353916168213\n",
      "Epoch 134: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1480, device='cuda:0')\n",
      "r2_score:  -0.9970401525497437\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1348, device='cuda:0')\n",
      "r2_score:  -0.9708871841430664\n",
      "Epoch 135:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983152747154236\n",
      "Epoch 135:   9%|▉         | 1/11 [00:00<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.0241e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994226098060608\n",
      "Epoch 135:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978280663490295\n",
      "Epoch 135:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985227584838867\n",
      "Epoch 135:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.4902e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998965859413147\n",
      "Epoch 135:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985866546630859\n",
      "Epoch 135:  55%|█████▍    | 6/11 [00:04<00:03,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6648e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987969398498535\n",
      "Epoch 135:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3774e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991620182991028\n",
      "Epoch 135:  73%|███████▎  | 8/11 [00:05<00:01,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6230e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999032735824585\n",
      "Epoch 135:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9978405833244324\n",
      "Epoch 135:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.7431e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992531538009644\n",
      "Epoch 135: 100%|██████████| 11/11 [00:07<00:00,  1.54it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1479, device='cuda:0')\n",
      "r2_score:  -0.9968268871307373\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1348, device='cuda:0')\n",
      "r2_score:  -0.9706635475158691\n",
      "Epoch 136:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982260465621948\n",
      "Epoch 136:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986140131950378\n",
      "Epoch 136:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983087778091431\n",
      "Epoch 136:  27%|██▋       | 3/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.6244e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989729523658752\n",
      "Epoch 136:  36%|███▋      | 4/11 [00:02<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.9807e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989312291145325\n",
      "Epoch 136:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987363219261169\n",
      "Epoch 136:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.0597e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991649389266968\n",
      "Epoch 136:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.9202e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989932179450989\n",
      "Epoch 136:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985544085502625\n",
      "Epoch 136:  82%|████████▏ | 9/11 [00:06<00:01,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.4369e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989761114120483\n",
      "Epoch 136:  91%|█████████ | 10/11 [00:06<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984880685806274\n",
      "Epoch 136: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1480, device='cuda:0')\n",
      "r2_score:  -0.9980931282043457\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1351, device='cuda:0')\n",
      "r2_score:  -0.9746383428573608\n",
      "Epoch 137:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9884e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990853071212769\n",
      "Epoch 137:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987520575523376\n",
      "Epoch 137:  18%|█▊        | 2/11 [00:01<00:06,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3430e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990761876106262\n",
      "Epoch 137:  27%|██▋       | 3/11 [00:02<00:05,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3891e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990118145942688\n",
      "Epoch 137:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9979248046875\n",
      "Epoch 137:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998575747013092\n",
      "Epoch 137:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.9218e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988489151000977\n",
      "Epoch 137:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.8770e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991710186004639\n",
      "Epoch 137:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998193621635437\n",
      "Epoch 137:  82%|████████▏ | 9/11 [00:06<00:01,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9999e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991228580474854\n",
      "Epoch 137:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982680678367615\n",
      "Epoch 137: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1483, device='cuda:0')\n",
      "r2_score:  -1.0018999576568604\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1352, device='cuda:0')\n",
      "r2_score:  -0.9765446186065674\n",
      "Epoch 138:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.3737e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989444017410278\n",
      "Epoch 138:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987615346908569\n",
      "Epoch 138:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4996e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993801116943359\n",
      "Epoch 138:  27%|██▋       | 3/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9581e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989807605743408\n",
      "Epoch 138:  36%|███▋      | 4/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982584118843079\n",
      "Epoch 138:  45%|████▌     | 5/11 [00:03<00:04,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3077e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993631839752197\n",
      "Epoch 138:  55%|█████▍    | 6/11 [00:04<00:03,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.7012e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987596869468689\n",
      "Epoch 138:  64%|██████▎   | 7/11 [00:04<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6873e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988849759101868\n",
      "Epoch 138:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986289739608765\n",
      "Epoch 138:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.7892e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989948272705078\n",
      "Epoch 138:  91%|█████████ | 10/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.996819794178009\n",
      "Epoch 138: 100%|██████████| 11/11 [00:07<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1480, device='cuda:0')\n",
      "r2_score:  -0.9975860118865967\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1352, device='cuda:0')\n",
      "r2_score:  -0.9762122631072998\n",
      "Epoch 139:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4342e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993076324462891\n",
      "Epoch 139:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.5251e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990081787109375\n",
      "Epoch 139:  18%|█▊        | 2/11 [00:01<00:07,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3055e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990948438644409\n",
      "Epoch 139:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.0127e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999352216720581\n",
      "Epoch 139:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998248815536499\n",
      "Epoch 139:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.4588e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990418553352356\n",
      "Epoch 139:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.3199e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988895654678345\n",
      "Epoch 139:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.7192e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988763332366943\n",
      "Epoch 139:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981035590171814\n",
      "Epoch 139:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989128112792969\n",
      "Epoch 139:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.0727e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999268651008606\n",
      "Epoch 139: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1482, device='cuda:0')\n",
      "r2_score:  -1.000326156616211\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1351, device='cuda:0')\n",
      "r2_score:  -0.9746434688568115\n",
      "Epoch 140:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986980557441711\n",
      "Epoch 140:   9%|▉         | 1/11 [00:00<00:07,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6994e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991517066955566\n",
      "Epoch 140:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9472e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991998076438904\n",
      "Epoch 140:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9096e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992129802703857\n",
      "Epoch 140:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7007e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999363124370575\n",
      "Epoch 140:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6347e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990454316139221\n",
      "Epoch 140:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.2416e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988407492637634\n",
      "Epoch 140:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984505772590637\n",
      "Epoch 140:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988021850585938\n",
      "Epoch 140:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986231327056885\n",
      "Epoch 140:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(7.9716e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999079167842865\n",
      "Epoch 140: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1481, device='cuda:0')\n",
      "r2_score:  -0.999366044998169\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1353, device='cuda:0')\n",
      "r2_score:  -0.9777488708496094\n",
      "Epoch 141:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4868e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995005130767822\n",
      "Epoch 141:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.1773e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988889098167419\n",
      "Epoch 141:  18%|█▊        | 2/11 [00:01<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982619285583496\n",
      "Epoch 141:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987198114395142\n",
      "Epoch 141:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.7748e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990242719650269\n",
      "Epoch 141:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.1673e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999054491519928\n",
      "Epoch 141:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.7035e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993467926979065\n",
      "Epoch 141:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.5323e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988484382629395\n",
      "Epoch 141:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.7529e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989610910415649\n",
      "Epoch 141:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.0482e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992326498031616\n",
      "Epoch 141:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.0801e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990259408950806\n",
      "Epoch 141: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1483, device='cuda:0')\n",
      "r2_score:  -1.0013458728790283\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1354, device='cuda:0')\n",
      "r2_score:  -0.9787912368774414\n",
      "Epoch 142:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.2792e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990417957305908\n",
      "Epoch 142:   9%|▉         | 1/11 [00:00<00:06,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3327e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992765188217163\n",
      "Epoch 142:  18%|█▊        | 2/11 [00:01<00:06,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9956e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999066174030304\n",
      "Epoch 142:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.1519e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990960955619812\n",
      "Epoch 142:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9983063340187073\n",
      "Epoch 142:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4678e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993813633918762\n",
      "Epoch 142:  55%|█████▍    | 6/11 [00:04<00:03,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.2743e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988916516304016\n",
      "Epoch 142:  64%|██████▎   | 7/11 [00:04<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.8841e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994816780090332\n",
      "Epoch 142:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.7844e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998990535736084\n",
      "Epoch 142:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986552596092224\n",
      "Epoch 142:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985872507095337\n",
      "Epoch 142: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1482, device='cuda:0')\n",
      "r2_score:  -1.0004334449768066\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1351, device='cuda:0')\n",
      "r2_score:  -0.974860668182373\n",
      "Epoch 143:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.7658e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989778995513916\n",
      "Epoch 143:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2508e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995089173316956\n",
      "Epoch 143:  18%|█▊        | 2/11 [00:01<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.8198e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998992383480072\n",
      "Epoch 143:  27%|██▋       | 3/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.0228e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989176988601685\n",
      "Epoch 143:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981389045715332\n",
      "Epoch 143:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.9494e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998863160610199\n",
      "Epoch 143:  55%|█████▍    | 6/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3650e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993115663528442\n",
      "Epoch 143:  64%|██████▎   | 7/11 [00:04<00:02,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5180e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992415308952332\n",
      "Epoch 143:  73%|███████▎  | 8/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.8546e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992700815200806\n",
      "Epoch 143:  82%|████████▏ | 9/11 [00:05<00:01,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5678e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992466568946838\n",
      "Epoch 143:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(7.7104e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990582466125488\n",
      "Epoch 143: 100%|██████████| 11/11 [00:06<00:00,  1.58it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1481, device='cuda:0')\n",
      "r2_score:  -0.9991025924682617\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1352, device='cuda:0')\n",
      "r2_score:  -0.9757744073867798\n",
      "Epoch 144:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9984619617462158\n",
      "Epoch 144:   9%|▉         | 1/11 [00:00<00:06,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3328e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990954399108887\n",
      "Epoch 144:  18%|█▊        | 2/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3151e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990881085395813\n",
      "Epoch 144:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.9754e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99929279088974\n",
      "Epoch 144:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3729e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993799328804016\n",
      "Epoch 144:  45%|████▌     | 5/11 [00:03<00:03,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.0444e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999048113822937\n",
      "Epoch 144:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.0966e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999189555644989\n",
      "Epoch 144:  64%|██████▎   | 7/11 [00:04<00:02,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4289e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991705417633057\n",
      "Epoch 144:  73%|███████▎  | 8/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982253313064575\n",
      "Epoch 144:  82%|████████▏ | 9/11 [00:05<00:01,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4482e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995590448379517\n",
      "Epoch 144:  91%|█████████ | 10/11 [00:06<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.2185e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992478489875793\n",
      "Epoch 144: 100%|██████████| 11/11 [00:06<00:00,  1.59it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1483, device='cuda:0')\n",
      "r2_score:  -1.0015413761138916\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1354, device='cuda:0')\n",
      "r2_score:  -0.9798499345779419\n",
      "Epoch 145:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.2096e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999015748500824\n",
      "Epoch 145:   9%|▉         | 1/11 [00:00<00:07,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988019466400146\n",
      "Epoch 145:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.8272e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991909265518188\n",
      "Epoch 145:  27%|██▋       | 3/11 [00:02<00:05,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.6524e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993229508399963\n",
      "Epoch 145:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.8829e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993321895599365\n",
      "Epoch 145:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7387e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991916418075562\n",
      "Epoch 145:  55%|█████▍    | 6/11 [00:04<00:03,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3455e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993640780448914\n",
      "Epoch 145:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9982674717903137\n",
      "Epoch 145:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9121e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996346831321716\n",
      "Epoch 145:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4722e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993634819984436\n",
      "Epoch 145:  91%|█████████ | 10/11 [00:06<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.7522e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993977546691895\n",
      "Epoch 145: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1483, device='cuda:0')\n",
      "r2_score:  -1.0016865730285645\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1356, device='cuda:0')\n",
      "r2_score:  -0.9821591377258301\n",
      "Epoch 146:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.5758e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995227456092834\n",
      "Epoch 146:   9%|▉         | 1/11 [00:00<00:06,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4332e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993917346000671\n",
      "Epoch 146:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9985355734825134\n",
      "Epoch 146:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6856e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990663528442383\n",
      "Epoch 146:  36%|███▋      | 4/11 [00:02<00:04,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.8326e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999482274055481\n",
      "Epoch 146:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.9899e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992473125457764\n",
      "Epoch 146:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.0295e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991899132728577\n",
      "Epoch 146:  64%|██████▎   | 7/11 [00:04<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5978e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992232322692871\n",
      "Epoch 146:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.8477e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992030262947083\n",
      "Epoch 146:  82%|████████▏ | 9/11 [00:06<00:01,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.8109e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992794394493103\n",
      "Epoch 146:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.9515e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989067316055298\n",
      "Epoch 146: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1484, device='cuda:0')\n",
      "r2_score:  -1.0031042098999023\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1357, device='cuda:0')\n",
      "r2_score:  -0.984175443649292\n",
      "Epoch 147:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4215e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995055794715881\n",
      "Epoch 147:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0672e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996039271354675\n",
      "Epoch 147:  18%|█▊        | 2/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.9061e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989407062530518\n",
      "Epoch 147:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9992e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990341067314148\n",
      "Epoch 147:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.7685e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993643164634705\n",
      "Epoch 147:  45%|████▌     | 5/11 [00:03<00:04,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3799e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993584156036377\n",
      "Epoch 147:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.6484e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995642900466919\n",
      "Epoch 147:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.998568594455719\n",
      "Epoch 147:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987477660179138\n",
      "Epoch 147:  82%|████████▏ | 9/11 [00:06<00:01,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2468e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994641542434692\n",
      "Epoch 147:  91%|█████████ | 10/11 [00:06<00:00,  1.49it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.5228e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991099834442139\n",
      "Epoch 147: 100%|██████████| 11/11 [00:07<00:00,  1.55it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1482, device='cuda:0')\n",
      "r2_score:  -1.000105857849121\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1355, device='cuda:0')\n",
      "r2_score:  -0.9808104038238525\n",
      "Epoch 148:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.1552e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992055296897888\n",
      "Epoch 148:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.1781e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991128444671631\n",
      "Epoch 148:  18%|█▊        | 2/11 [00:01<00:06,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3515e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991060495376587\n",
      "Epoch 148:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.7814e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993501305580139\n",
      "Epoch 148:  36%|███▋      | 4/11 [00:02<00:04,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3720e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990476965904236\n",
      "Epoch 148:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.6360e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991365075111389\n",
      "Epoch 148:  55%|█████▍    | 6/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3862e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994476437568665\n",
      "Epoch 148:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8920e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995235800743103\n",
      "Epoch 148:  73%|███████▎  | 8/11 [00:05<00:02,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.8319e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993405342102051\n",
      "Epoch 148:  82%|████████▏ | 9/11 [00:06<00:01,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986557364463806\n",
      "Epoch 148:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.0281e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992798566818237\n",
      "Epoch 148: 100%|██████████| 11/11 [00:07<00:00,  1.53it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1483, device='cuda:0')\n",
      "r2_score:  -1.0015122890472412\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1354, device='cuda:0')\n",
      "r2_score:  -0.979232907295227\n",
      "Epoch 149:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.9847e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99871826171875\n",
      "Epoch 149:   9%|▉         | 1/11 [00:00<00:07,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987329840660095\n",
      "Epoch 149:  18%|█▊        | 2/11 [00:01<00:06,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1488e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993605017662048\n",
      "Epoch 149:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2307e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993875026702881\n",
      "Epoch 149:  36%|███▋      | 4/11 [00:02<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0347e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996880292892456\n",
      "Epoch 149:  45%|████▌     | 5/11 [00:03<00:04,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.1348e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990562200546265\n",
      "Epoch 149:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4403e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994666576385498\n",
      "Epoch 149:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2442e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995097517967224\n",
      "Epoch 149:  73%|███████▎  | 8/11 [00:05<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7967e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995657801628113\n",
      "Epoch 149:  82%|████████▏ | 9/11 [00:06<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.1259e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989535212516785\n",
      "Epoch 149:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.4054e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994509220123291\n",
      "Epoch 149: 100%|██████████| 11/11 [00:07<00:00,  1.57it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1483, device='cuda:0')\n",
      "r2_score:  -1.0021021366119385\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1358, device='cuda:0')\n",
      "r2_score:  -0.9850744009017944\n",
      "Epoch 150:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3228e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992756843566895\n",
      "Epoch 150:   9%|▉         | 1/11 [00:00<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.6194e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992474317550659\n",
      "Epoch 150:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2061e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993634819984436\n",
      "Epoch 150:  27%|██▋       | 3/11 [00:01<00:05,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6767e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991086721420288\n",
      "Epoch 150:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3518e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994080066680908\n",
      "Epoch 150:  45%|████▌     | 5/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.2333e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992058873176575\n",
      "Epoch 150:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.6690e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995781779289246\n",
      "Epoch 150:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986957311630249\n",
      "Epoch 150:  73%|███████▎  | 8/11 [00:05<00:02,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.9003e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999414324760437\n",
      "Epoch 150:  82%|████████▏ | 9/11 [00:06<00:01,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7363e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994025826454163\n",
      "Epoch 150:  91%|█████████ | 10/11 [00:06<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.4262e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995161294937134\n",
      "Epoch 150: 100%|██████████| 11/11 [00:07<00:00,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1485, device='cuda:0')\n",
      "r2_score:  -1.0040338039398193\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1358, device='cuda:0')\n",
      "r2_score:  -0.9846944808959961\n",
      "Epoch 151:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.6542e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995482563972473\n",
      "Epoch 151:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3340e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992711544036865\n",
      "Epoch 151:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4487e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993481636047363\n",
      "Epoch 151:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5019e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999204158782959\n",
      "Epoch 151:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.5636e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993573427200317\n",
      "Epoch 151:  45%|████▌     | 5/11 [00:03<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.5754e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995537400245667\n",
      "Epoch 151:  55%|█████▍    | 6/11 [00:04<00:03,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0234e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996311068534851\n",
      "Epoch 151:  64%|██████▎   | 7/11 [00:04<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.9027e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993629455566406\n",
      "Epoch 151:  73%|███████▎  | 8/11 [00:05<00:02,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6195e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988416433334351\n",
      "Epoch 151:  82%|████████▏ | 9/11 [00:06<00:01,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.8548e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990981221199036\n",
      "Epoch 151:  91%|█████████ | 10/11 [00:06<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.7822e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996036887168884\n",
      "Epoch 151: 100%|██████████| 11/11 [00:07<00:00,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1482, device='cuda:0')\n",
      "r2_score:  -1.0006256103515625\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1360, device='cuda:0')\n",
      "r2_score:  -0.987970232963562\n",
      "Epoch 152:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.0063e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992926120758057\n",
      "Epoch 152:   9%|▉         | 1/11 [00:00<00:06,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7336e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994322657585144\n",
      "Epoch 152:  18%|█▊        | 2/11 [00:01<00:06,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1895e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994568824768066\n",
      "Epoch 152:  27%|██▋       | 3/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4834e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99961256980896\n",
      "Epoch 152:  36%|███▋      | 4/11 [00:02<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1372e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994982481002808\n",
      "Epoch 152:  45%|████▌     | 5/11 [00:03<00:04,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.1664e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992344975471497\n",
      "Epoch 152:  55%|█████▍    | 6/11 [00:04<00:03,  1.49it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3957e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993667602539062\n",
      "Epoch 152:  64%|██████▎   | 7/11 [00:04<00:02,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8495e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995033144950867\n",
      "Epoch 152:  73%|███████▎  | 8/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9987669587135315\n",
      "Epoch 152:  82%|████████▏ | 9/11 [00:05<00:01,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9847e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995407462120056\n",
      "Epoch 152:  91%|█████████ | 10/11 [00:06<00:00,  1.50it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.6399e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989818930625916\n",
      "Epoch 152: 100%|██████████| 11/11 [00:07<00:00,  1.56it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1484, device='cuda:0')\n",
      "r2_score:  -1.0036556720733643\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1355, device='cuda:0')\n",
      "r2_score:  -0.980582594871521\n",
      "Epoch 153:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9981331825256348\n",
      "Epoch 153:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2180e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994264841079712\n",
      "Epoch 153:  18%|█▊        | 2/11 [00:01<00:05,  1.50it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1423e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994194507598877\n",
      "Epoch 153:  27%|██▋       | 3/11 [00:01<00:05,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3095e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995918273925781\n",
      "Epoch 153:  36%|███▋      | 4/11 [00:02<00:04,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.5659e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994285106658936\n",
      "Epoch 153:  45%|████▌     | 5/11 [00:03<00:03,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2669e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995166659355164\n",
      "Epoch 153:  55%|█████▍    | 6/11 [00:03<00:03,  1.52it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3637e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990127682685852\n",
      "Epoch 153:  64%|██████▎   | 7/11 [00:04<00:02,  1.51it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7934e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999512791633606\n",
      "Epoch 153:  73%|███████▎  | 8/11 [00:05<00:02,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8513e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995759725570679\n",
      "Epoch 153:  82%|████████▏ | 9/11 [00:07<00:01,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.2237e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996134042739868\n",
      "Epoch 153:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.5081e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996258020401001\n",
      "Epoch 153: 100%|██████████| 11/11 [00:08<00:00,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1484, device='cuda:0')\n",
      "r2_score:  -1.003286600112915\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9900878667831421\n",
      "Epoch 154:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.8511e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992376565933228\n",
      "Epoch 154:   9%|▉         | 1/11 [00:00<00:07,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6415e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999114990234375\n",
      "Epoch 154:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3226e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993628859519958\n",
      "Epoch 154:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1929e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999629020690918\n",
      "Epoch 154:  36%|███▋      | 4/11 [00:03<00:05,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3723e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996314644813538\n",
      "Epoch 154:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.8239e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996926784515381\n",
      "Epoch 154:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9986998438835144\n",
      "Epoch 154:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.5607e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994686841964722\n",
      "Epoch 154:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.6962e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993032813072205\n",
      "Epoch 154:  82%|████████▏ | 9/11 [00:06<00:01,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0553e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995872378349304\n",
      "Epoch 154:  91%|█████████ | 10/11 [00:07<00:00,  1.33it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.4932e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997079968452454\n",
      "Epoch 154: 100%|██████████| 11/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1484, device='cuda:0')\n",
      "r2_score:  -1.0033094882965088\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1359, device='cuda:0')\n",
      "r2_score:  -0.9861264228820801\n",
      "Epoch 155:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.6505e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989789724349976\n",
      "Epoch 155:   9%|▉         | 1/11 [00:00<00:07,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.7991e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996659755706787\n",
      "Epoch 155:  18%|█▊        | 2/11 [00:01<00:06,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2539e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995066523551941\n",
      "Epoch 155:  27%|██▋       | 3/11 [00:02<00:05,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1985e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996192455291748\n",
      "Epoch 155:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.7198e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996761679649353\n",
      "Epoch 155:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7329e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994418621063232\n",
      "Epoch 155:  55%|█████▍    | 6/11 [00:04<00:03,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4942e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995654821395874\n",
      "Epoch 155:  64%|██████▎   | 7/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5142e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992749094963074\n",
      "Epoch 155:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1564e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994016885757446\n",
      "Epoch 155:  82%|████████▏ | 9/11 [00:06<00:01,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6554e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988899230957031\n",
      "Epoch 155:  91%|█████████ | 10/11 [00:07<00:00,  1.37it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.4815e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995729327201843\n",
      "Epoch 155: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1485, device='cuda:0')\n",
      "r2_score:  -1.0044116973876953\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1356, device='cuda:0')\n",
      "r2_score:  -0.9825625419616699\n",
      "Epoch 156:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.5273e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989482164382935\n",
      "Epoch 156:   9%|▉         | 1/11 [00:00<00:07,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.8780e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993124604225159\n",
      "Epoch 156:  18%|█▊        | 2/11 [00:01<00:06,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6663e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996833801269531\n",
      "Epoch 156:  27%|██▋       | 3/11 [00:02<00:06,  1.19it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3164e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999398410320282\n",
      "Epoch 156:  36%|███▋      | 4/11 [00:03<00:05,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.6351e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994623064994812\n",
      "Epoch 156:  45%|████▌     | 5/11 [00:04<00:04,  1.22it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.9333e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994238018989563\n",
      "Epoch 156:  55%|█████▍    | 6/11 [00:04<00:04,  1.22it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0833e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996373653411865\n",
      "Epoch 156:  64%|██████▎   | 7/11 [00:05<00:03,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6305e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997022747993469\n",
      "Epoch 156:  73%|███████▎  | 8/11 [00:06<00:02,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7469e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992218613624573\n",
      "Epoch 156:  82%|████████▏ | 9/11 [00:07<00:01,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4534e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994533061981201\n",
      "Epoch 156:  91%|█████████ | 10/11 [00:07<00:00,  1.29it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.0560e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995864629745483\n",
      "Epoch 156: 100%|██████████| 11/11 [00:08<00:00,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1486, device='cuda:0')\n",
      "r2_score:  -1.0057008266448975\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9894396066665649\n",
      "Epoch 157:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9358e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997705221176147\n",
      "Epoch 157:   9%|▉         | 1/11 [00:00<00:08,  1.15it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.2928e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996335506439209\n",
      "Epoch 157:  18%|█▊        | 2/11 [00:01<00:06,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.6421e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991898536682129\n",
      "Epoch 157:  27%|██▋       | 3/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7136e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995404481887817\n",
      "Epoch 157:  36%|███▋      | 4/11 [00:02<00:05,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.3629e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989692568778992\n",
      "Epoch 157:  45%|████▌     | 5/11 [00:03<00:04,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7286e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994478225708008\n",
      "Epoch 157:  55%|█████▍    | 6/11 [00:04<00:03,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.3743e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997063875198364\n",
      "Epoch 157:  64%|██████▎   | 7/11 [00:05<00:02,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4416e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991953372955322\n",
      "Epoch 157:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9523e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995154142379761\n",
      "Epoch 157:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6900e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996832609176636\n",
      "Epoch 157:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.0610e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99973064661026\n",
      "Epoch 157: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1485, device='cuda:0')\n",
      "r2_score:  -1.0040080547332764\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9890272617340088\n",
      "Epoch 158:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5294e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997050166130066\n",
      "Epoch 158:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.6391e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995667338371277\n",
      "Epoch 158:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.4075e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999691903591156\n",
      "Epoch 158:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4614e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994693994522095\n",
      "Epoch 158:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.6728e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993133544921875\n",
      "Epoch 158:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2554e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995161294937134\n",
      "Epoch 158:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1759e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997328519821167\n",
      "Epoch 158:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.7884e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999125599861145\n",
      "Epoch 158:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2641e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995086193084717\n",
      "Epoch 158:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.0778e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992599487304688\n",
      "Epoch 158:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.1862e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999673068523407\n",
      "Epoch 158: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1487, device='cuda:0')\n",
      "r2_score:  -1.0072050094604492\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1362, device='cuda:0')\n",
      "r2_score:  -0.991561770439148\n",
      "Epoch 159:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4243e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990785121917725\n",
      "Epoch 159:   9%|▉         | 1/11 [00:00<00:07,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5322e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999706506729126\n",
      "Epoch 159:  18%|█▊        | 2/11 [00:01<00:06,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.3099e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997329115867615\n",
      "Epoch 159:  27%|██▋       | 3/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.0489e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991844892501831\n",
      "Epoch 159:  36%|███▋      | 4/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7833e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995549321174622\n",
      "Epoch 159:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2455e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997432827949524\n",
      "Epoch 159:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6891e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996840357780457\n",
      "Epoch 159:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.6015e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999479353427887\n",
      "Epoch 159:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3352e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992320537567139\n",
      "Epoch 159:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.8816e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999655544757843\n",
      "Epoch 159:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.0666e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997541904449463\n",
      "Epoch 159: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1484, device='cuda:0')\n",
      "r2_score:  -1.0025403499603271\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.989452600479126\n",
      "Epoch 160:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.3841e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997373223304749\n",
      "Epoch 160:   9%|▉         | 1/11 [00:00<00:07,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9973e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996618032455444\n",
      "Epoch 160:  18%|█▊        | 2/11 [00:01<00:07,  1.20it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.4945e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996909499168396\n",
      "Epoch 160:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.0558e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995126128196716\n",
      "Epoch 160:  36%|███▋      | 4/11 [00:03<00:05,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6417e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997151494026184\n",
      "Epoch 160:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4116e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999441385269165\n",
      "Epoch 160:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8786e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999545156955719\n",
      "Epoch 160:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7632e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992265105247498\n",
      "Epoch 160:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8857e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997472167015076\n",
      "Epoch 160:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3034e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991257190704346\n",
      "Epoch 160:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.4433e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999636173248291\n",
      "Epoch 160: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1487, device='cuda:0')\n",
      "r2_score:  -1.007056713104248\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9891639947891235\n",
      "Epoch 161:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3269e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999600887298584\n",
      "Epoch 161:   9%|▉         | 1/11 [00:00<00:07,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4259e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995990991592407\n",
      "Epoch 161:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0581e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996291995048523\n",
      "Epoch 161:  27%|██▋       | 3/11 [00:02<00:05,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4085e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993481040000916\n",
      "Epoch 161:  36%|███▋      | 4/11 [00:02<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.7888e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996620416641235\n",
      "Epoch 161:  45%|████▌     | 5/11 [00:03<00:04,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4418e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991658329963684\n",
      "Epoch 161:  55%|█████▍    | 6/11 [00:04<00:03,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3746e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999578058719635\n",
      "Epoch 161:  64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2307e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997420907020569\n",
      "Epoch 161:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5630e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999668300151825\n",
      "Epoch 161:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2186e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995526075363159\n",
      "Epoch 161:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.2791e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996581077575684\n",
      "Epoch 161: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1486, device='cuda:0')\n",
      "r2_score:  -1.0051369667053223\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9900089502334595\n",
      "Epoch 162:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9758e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9991442561149597\n",
      "Epoch 162:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6491e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996926188468933\n",
      "Epoch 162:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9067e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997761249542236\n",
      "Epoch 162:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1909e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994291663169861\n",
      "Epoch 162:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8668e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997695088386536\n",
      "Epoch 162:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4278e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995109438896179\n",
      "Epoch 162:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.8203e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992918372154236\n",
      "Epoch 162:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9999e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997541904449463\n",
      "Epoch 162:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8421e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995391368865967\n",
      "Epoch 162:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1129e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997658133506775\n",
      "Epoch 162:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.1509e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997320771217346\n",
      "Epoch 162: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1485, device='cuda:0')\n",
      "r2_score:  -1.0050067901611328\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9889742136001587\n",
      "Epoch 163:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5532e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998146891593933\n",
      "Epoch 163:   9%|▉         | 1/11 [00:00<00:07,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4893e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995793700218201\n",
      "Epoch 163:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.0198e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999068021774292\n",
      "Epoch 163:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.9330e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993833899497986\n",
      "Epoch 163:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1226e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997537136077881\n",
      "Epoch 163:  45%|████▌     | 5/11 [00:03<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4247e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999609649181366\n",
      "Epoch 163:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.7365e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996903538703918\n",
      "Epoch 163:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.0811e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994850158691406\n",
      "Epoch 163:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7107e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995644688606262\n",
      "Epoch 163:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.5165e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996216297149658\n",
      "Epoch 163:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.9546e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999761700630188\n",
      "Epoch 163: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1486, device='cuda:0')\n",
      "r2_score:  -1.0056421756744385\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1362, device='cuda:0')\n",
      "r2_score:  -0.9914736747741699\n",
      "Epoch 164:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7358e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997950792312622\n",
      "Epoch 164:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.6418e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995667934417725\n",
      "Epoch 164:  18%|█▊        | 2/11 [00:01<00:07,  1.21it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7471e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997843503952026\n",
      "Epoch 164:  27%|██▋       | 3/11 [00:02<00:06,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.8745e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996830224990845\n",
      "Epoch 164:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.0493e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994704127311707\n",
      "Epoch 164:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2305e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995454549789429\n",
      "Epoch 164:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.4862e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996702671051025\n",
      "Epoch 164:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9609e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999767541885376\n",
      "Epoch 164:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5543e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997079372406006\n",
      "Epoch 164:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.5176e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9990608096122742\n",
      "Epoch 164:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.0341e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998852610588074\n",
      "Epoch 164: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1487, device='cuda:0')\n",
      "r2_score:  -1.0064795017242432\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1363, device='cuda:0')\n",
      "r2_score:  -0.9921092987060547\n",
      "Epoch 165:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9620e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996486902236938\n",
      "Epoch 165:   9%|▉         | 1/11 [00:00<00:07,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1264e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996354579925537\n",
      "Epoch 165:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3296e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996200799942017\n",
      "Epoch 165:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5678e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997097849845886\n",
      "Epoch 165:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3520e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995966553688049\n",
      "Epoch 165:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.9344e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992945790290833\n",
      "Epoch 165:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9213e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996495842933655\n",
      "Epoch 165:  64%|██████▎   | 7/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9970e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997625350952148\n",
      "Epoch 165:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2717e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997372627258301\n",
      "Epoch 165:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6264e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996825456619263\n",
      "Epoch 165:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.1841e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994861483573914\n",
      "Epoch 165: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1485, device='cuda:0')\n",
      "r2_score:  -1.004899024963379\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1363, device='cuda:0')\n",
      "r2_score:  -0.9922788143157959\n",
      "Epoch 166:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0159e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996413588523865\n",
      "Epoch 166:   9%|▉         | 1/11 [00:00<00:07,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1596e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994828104972839\n",
      "Epoch 166:  18%|█▊        | 2/11 [00:01<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.4760e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997228980064392\n",
      "Epoch 166:  27%|██▋       | 3/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9317e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999773383140564\n",
      "Epoch 166:  36%|███▋      | 4/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4558e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996365308761597\n",
      "Epoch 166:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1550e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999736487865448\n",
      "Epoch 166:  55%|█████▍    | 6/11 [00:04<00:03,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8743e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9989550113677979\n",
      "Epoch 166:  64%|██████▎   | 7/11 [00:04<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9981e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997472167015076\n",
      "Epoch 166:  73%|███████▎  | 8/11 [00:05<00:02,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9500e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997690916061401\n",
      "Epoch 166:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9161e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997736811637878\n",
      "Epoch 166:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.1332e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997467398643494\n",
      "Epoch 166: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1488, device='cuda:0')\n",
      "r2_score:  -1.008662223815918\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1363, device='cuda:0')\n",
      "r2_score:  -0.992162823677063\n",
      "Epoch 167:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6503e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999704122543335\n",
      "Epoch 167:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4522e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994804859161377\n",
      "Epoch 167:  18%|█▊        | 2/11 [00:01<00:07,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7567e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998121857643127\n",
      "Epoch 167:  27%|██▋       | 3/11 [00:02<00:06,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.3539e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997079968452454\n",
      "Epoch 167:  36%|███▋      | 4/11 [00:02<00:05,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.3239e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999709963798523\n",
      "Epoch 167:  45%|████▌     | 5/11 [00:03<00:04,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4098e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999825119972229\n",
      "Epoch 167:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9386e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996448755264282\n",
      "Epoch 167:  64%|██████▎   | 7/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7311e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995518922805786\n",
      "Epoch 167:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8513e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997863173484802\n",
      "Epoch 167:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4498e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992704391479492\n",
      "Epoch 167:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.7134e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997789263725281\n",
      "Epoch 167: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1485, device='cuda:0')\n",
      "r2_score:  -1.0044374465942383\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1362, device='cuda:0')\n",
      "r2_score:  -0.9914505481719971\n",
      "Epoch 168:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5368e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996776580810547\n",
      "Epoch 168:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.3465e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997161626815796\n",
      "Epoch 168:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4472e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998430609703064\n",
      "Epoch 168:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.8466e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996523261070251\n",
      "Epoch 168:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7720e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997967481613159\n",
      "Epoch 168:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1310e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998665452003479\n",
      "Epoch 168:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6677e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998230338096619\n",
      "Epoch 168:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.9294e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992424845695496\n",
      "Epoch 168:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2681e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994970560073853\n",
      "Epoch 168:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0308e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996599555015564\n",
      "Epoch 168:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.8214e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993818998336792\n",
      "Epoch 168: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1488, device='cuda:0')\n",
      "r2_score:  -1.0082728862762451\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1363, device='cuda:0')\n",
      "r2_score:  -0.9928170442581177\n",
      "Epoch 169:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.5980e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993621110916138\n",
      "Epoch 169:   9%|▉         | 1/11 [00:00<00:09,  1.04it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2284e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995049834251404\n",
      "Epoch 169:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8895e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999771773815155\n",
      "Epoch 169:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9688e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997835159301758\n",
      "Epoch 169:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6587e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998002052307129\n",
      "Epoch 169:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7674e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997819662094116\n",
      "Epoch 169:  55%|█████▍    | 6/11 [00:04<00:03,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2861e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995042681694031\n",
      "Epoch 169:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.5579e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995615482330322\n",
      "Epoch 169:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.2213e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996046423912048\n",
      "Epoch 169:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4029e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999839186668396\n",
      "Epoch 169:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.3309e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999847948551178\n",
      "Epoch 169: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1488, device='cuda:0')\n",
      "r2_score:  -1.0083284378051758\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1363, device='cuda:0')\n",
      "r2_score:  -0.9928038120269775\n",
      "Epoch 170:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6686e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997952580451965\n",
      "Epoch 170:   9%|▉         | 1/11 [00:00<00:07,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3997e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998441934585571\n",
      "Epoch 170:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5504e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998211860656738\n",
      "Epoch 170:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4843e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992132782936096\n",
      "Epoch 170:  36%|███▋      | 4/11 [00:03<00:05,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7059e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999546229839325\n",
      "Epoch 170:  45%|████▌     | 5/11 [00:03<00:04,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5542e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997063875198364\n",
      "Epoch 170:  55%|█████▍    | 6/11 [00:04<00:03,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3538e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998323321342468\n",
      "Epoch 170:  64%|██████▎   | 7/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4067e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998334050178528\n",
      "Epoch 170:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5654e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999823272228241\n",
      "Epoch 170:  82%|████████▏ | 9/11 [00:06<00:01,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7709e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995650053024292\n",
      "Epoch 170:  91%|█████████ | 10/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.4607e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995932579040527\n",
      "Epoch 170: 100%|██████████| 11/11 [00:07<00:00,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1488, device='cuda:0')\n",
      "r2_score:  -1.008171796798706\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1362, device='cuda:0')\n",
      "r2_score:  -0.9913545846939087\n",
      "Epoch 171:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.0647e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997527003288269\n",
      "Epoch 171:   9%|▉         | 1/11 [00:00<00:07,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.9812e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998981356620789\n",
      "Epoch 171:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2687e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993612170219421\n",
      "Epoch 171:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1415e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999857485294342\n",
      "Epoch 171:  36%|███▋      | 4/11 [00:02<00:04,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5022e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998202323913574\n",
      "Epoch 171:  45%|████▌     | 5/11 [00:03<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6303e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996920824050903\n",
      "Epoch 171:  55%|█████▍    | 6/11 [00:04<00:03,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1493e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999643862247467\n",
      "Epoch 171:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2124e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999853253364563\n",
      "Epoch 171:  73%|███████▎  | 8/11 [00:05<00:02,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5162e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996960163116455\n",
      "Epoch 171:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.5587e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994043111801147\n",
      "Epoch 171:  91%|█████████ | 10/11 [00:07<00:00,  1.40it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.7339e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997985363006592\n",
      "Epoch 171: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1486, device='cuda:0')\n",
      "r2_score:  -1.0064311027526855\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1361, device='cuda:0')\n",
      "r2_score:  -0.9899082183837891\n",
      "Epoch 172:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.4179e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996933341026306\n",
      "Epoch 172:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.3375e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995617270469666\n",
      "Epoch 172:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7910e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997937083244324\n",
      "Epoch 172:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8311e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998025894165039\n",
      "Epoch 172:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0764e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998814463615417\n",
      "Epoch 172:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0582e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998795986175537\n",
      "Epoch 172:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6337e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997091293334961\n",
      "Epoch 172:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6006e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996739029884338\n",
      "Epoch 172:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.6713e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995586276054382\n",
      "Epoch 172:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7513e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999797523021698\n",
      "Epoch 172:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.4846e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9988656640052795\n",
      "Epoch 172: 100%|██████████| 11/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1487, device='cuda:0')\n",
      "r2_score:  -1.0075874328613281\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9949440956115723\n",
      "Epoch 173:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6319e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998056888580322\n",
      "Epoch 173:   9%|▉         | 1/11 [00:00<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9155e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996585249900818\n",
      "Epoch 173:  18%|█▊        | 2/11 [00:01<00:06,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3209e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992945790290833\n",
      "Epoch 173:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6976e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997850656509399\n",
      "Epoch 173:  36%|███▋      | 4/11 [00:02<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9173e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997732639312744\n",
      "Epoch 173:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5217e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999701201915741\n",
      "Epoch 173:  55%|█████▍    | 6/11 [00:04<00:03,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4877e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999830961227417\n",
      "Epoch 173:  64%|██████▎   | 7/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9484e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995020627975464\n",
      "Epoch 173:  73%|███████▎  | 8/11 [00:05<00:02,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9581e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999789297580719\n",
      "Epoch 173:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1031e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998668432235718\n",
      "Epoch 173:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.8539e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997857809066772\n",
      "Epoch 173: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.010953426361084\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9954438209533691\n",
      "Epoch 174:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8069e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997794032096863\n",
      "Epoch 174:   9%|▉         | 1/11 [00:00<00:07,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1735e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997623562812805\n",
      "Epoch 174:  18%|█▊        | 2/11 [00:01<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4961e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998167753219604\n",
      "Epoch 174:  27%|██▋       | 3/11 [00:02<00:05,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5875e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998215436935425\n",
      "Epoch 174:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2521e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995251297950745\n",
      "Epoch 174:  45%|████▌     | 5/11 [00:03<00:04,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2325e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997307062149048\n",
      "Epoch 174:  55%|█████▍    | 6/11 [00:04<00:03,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5904e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998153448104858\n",
      "Epoch 174:  64%|██████▎   | 7/11 [00:04<00:02,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.8930e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999384343624115\n",
      "Epoch 174:  73%|███████▎  | 8/11 [00:05<00:02,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3166e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998331069946289\n",
      "Epoch 174:  82%|████████▏ | 9/11 [00:06<00:01,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2176e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997401237487793\n",
      "Epoch 174:  91%|█████████ | 10/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.1892e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998729228973389\n",
      "Epoch 174: 100%|██████████| 11/11 [00:07<00:00,  1.48it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1489, device='cuda:0')\n",
      "r2_score:  -1.0099060535430908\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1363, device='cuda:0')\n",
      "r2_score:  -0.992666482925415\n",
      "Epoch 175:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4961e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998264908790588\n",
      "Epoch 175:   9%|▉         | 1/11 [00:00<00:06,  1.47it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0420e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996463656425476\n",
      "Epoch 175:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9622e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996460676193237\n",
      "Epoch 175:  27%|██▋       | 3/11 [00:02<00:06,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1141e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996281862258911\n",
      "Epoch 175:  36%|███▋      | 4/11 [00:02<00:05,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3331e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998401403427124\n",
      "Epoch 175:  45%|████▌     | 5/11 [00:03<00:04,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2807e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997374415397644\n",
      "Epoch 175:  55%|█████▍    | 6/11 [00:04<00:03,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1948e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998513460159302\n",
      "Epoch 175:  64%|██████▎   | 7/11 [00:04<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.5128e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994491934776306\n",
      "Epoch 175:  73%|███████▎  | 8/11 [00:05<00:02,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4783e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999160170555115\n",
      "Epoch 175:  82%|████████▏ | 9/11 [00:06<00:01,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2083e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998582601547241\n",
      "Epoch 175:  91%|█████████ | 10/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(7.4696e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999157786369324\n",
      "Epoch 175: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1489, device='cuda:0')\n",
      "r2_score:  -1.009162425994873\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9950488805770874\n",
      "Epoch 176:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1332e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995247721672058\n",
      "Epoch 176:   9%|▉         | 1/11 [00:00<00:07,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2490e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998512268066406\n",
      "Epoch 176:  18%|█▊        | 2/11 [00:01<00:07,  1.22it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9363e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997449517250061\n",
      "Epoch 176:  27%|██▋       | 3/11 [00:02<00:06,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7161e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993897080421448\n",
      "Epoch 176:  36%|███▋      | 4/11 [00:03<00:05,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.0224e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999337792396545\n",
      "Epoch 176:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0283e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998680353164673\n",
      "Epoch 176:  55%|█████▍    | 6/11 [00:04<00:03,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5009e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998266100883484\n",
      "Epoch 176:  64%|██████▎   | 7/11 [00:05<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6862e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998207092285156\n",
      "Epoch 176:  73%|███████▎  | 8/11 [00:06<00:02,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5761e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998213052749634\n",
      "Epoch 176:  82%|████████▏ | 9/11 [00:06<00:01,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2046e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998612999916077\n",
      "Epoch 176:  91%|█████████ | 10/11 [00:07<00:00,  1.36it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.0278e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998762011528015\n",
      "Epoch 176: 100%|██████████| 11/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1489, device='cuda:0')\n",
      "r2_score:  -1.0097219944000244\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.9936974048614502\n",
      "Epoch 177:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5684e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998120069503784\n",
      "Epoch 177:   9%|▉         | 1/11 [00:00<00:08,  1.14it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2022e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998623728752136\n",
      "Epoch 177:  18%|█▊        | 2/11 [00:02<00:10,  0.86it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9108e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995488524436951\n",
      "Epoch 177:  27%|██▋       | 3/11 [00:03<00:08,  0.95it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1733e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997455477714539\n",
      "Epoch 177:  36%|███▋      | 4/11 [00:04<00:07,  0.99it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4669e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999829113483429\n",
      "Epoch 177:  45%|████▌     | 5/11 [00:04<00:05,  1.04it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1403e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999864935874939\n",
      "Epoch 177:  55%|█████▍    | 6/11 [00:05<00:04,  1.08it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4568e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996153116226196\n",
      "Epoch 177:  64%|██████▎   | 7/11 [00:06<00:03,  1.12it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4426e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999105930328369\n",
      "Epoch 177:  73%|███████▎  | 8/11 [00:07<00:02,  1.11it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0216e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998645782470703\n",
      "Epoch 177:  82%|████████▏ | 9/11 [00:07<00:01,  1.14it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2334e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999751091003418\n",
      "Epoch 177:  91%|█████████ | 10/11 [00:08<00:00,  1.15it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.5516e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998064637184143\n",
      "Epoch 177: 100%|██████████| 11/11 [00:09<00:00,  1.21it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1488, device='cuda:0')\n",
      "r2_score:  -1.0089972019195557\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.995580792427063\n",
      "Epoch 178:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6274e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997966289520264\n",
      "Epoch 178:   9%|▉         | 1/11 [00:01<00:10,  0.99it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1161e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994679689407349\n",
      "Epoch 178:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.1142e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998911023139954\n",
      "Epoch 178:  27%|██▋       | 3/11 [00:02<00:06,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1283e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998713731765747\n",
      "Epoch 178:  36%|███▋      | 4/11 [00:03<00:05,  1.22it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1949e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997544884681702\n",
      "Epoch 178:  45%|████▌     | 5/11 [00:03<00:04,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7035e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998005628585815\n",
      "Epoch 178:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.0388e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997615814208984\n",
      "Epoch 178:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2349e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997350573539734\n",
      "Epoch 178:  73%|███████▎  | 8/11 [00:06<00:02,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.7058e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998936057090759\n",
      "Epoch 178:  82%|████████▏ | 9/11 [00:07<00:01,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7999e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997958540916443\n",
      "Epoch 178:  91%|█████████ | 10/11 [00:07<00:00,  1.30it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.9733e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999131560325623\n",
      "Epoch 178: 100%|██████████| 11/11 [00:08<00:00,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.0106143951416016\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9959574937820435\n",
      "Epoch 179:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.5731e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998859167098999\n",
      "Epoch 179:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.7392e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999932587146759\n",
      "Epoch 179:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2305e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997346997261047\n",
      "Epoch 179:  27%|██▋       | 3/11 [00:02<00:06,  1.16it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.0429e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998924136161804\n",
      "Epoch 179:  36%|███▋      | 4/11 [00:03<00:05,  1.21it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8473e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998851418495178\n",
      "Epoch 179:  45%|████▌     | 5/11 [00:04<00:04,  1.23it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9954e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995262026786804\n",
      "Epoch 179:  55%|█████▍    | 6/11 [00:04<00:03,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6636e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996879696846008\n",
      "Epoch 179:  64%|██████▎   | 7/11 [00:05<00:03,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4524e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999835193157196\n",
      "Epoch 179:  73%|███████▎  | 8/11 [00:06<00:02,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.5908e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999001026153564\n",
      "Epoch 179:  82%|████████▏ | 9/11 [00:07<00:01,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9938e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997804760932922\n",
      "Epoch 179:  91%|█████████ | 10/11 [00:07<00:00,  1.27it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.5186e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996034502983093\n",
      "Epoch 179: 100%|██████████| 11/11 [00:08<00:00,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1488, device='cuda:0')\n",
      "r2_score:  -1.0079739093780518\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.9941160678863525\n",
      "Epoch 180:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1811e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998571872711182\n",
      "Epoch 180:   9%|▉         | 1/11 [00:01<00:12,  0.81it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1941e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998599290847778\n",
      "Epoch 180:  18%|█▊        | 2/11 [00:02<00:09,  0.99it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3467e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999119639396667\n",
      "Epoch 180:  27%|██▋       | 3/11 [00:02<00:07,  1.07it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4826e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998273849487305\n",
      "Epoch 180:  36%|███▋      | 4/11 [00:03<00:06,  1.11it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4896e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996041655540466\n",
      "Epoch 180:  45%|████▌     | 5/11 [00:04<00:05,  1.07it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9140e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995291829109192\n",
      "Epoch 180:  55%|█████▍    | 6/11 [00:05<00:04,  1.12it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6513e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998093843460083\n",
      "Epoch 180:  64%|██████▎   | 7/11 [00:06<00:03,  1.15it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6840e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996629357337952\n",
      "Epoch 180:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0961e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998776912689209\n",
      "Epoch 180:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.7090e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999927818775177\n",
      "Epoch 180:  91%|█████████ | 10/11 [00:08<00:00,  1.22it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.7896e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997159242630005\n",
      "Epoch 180: 100%|██████████| 11/11 [00:08<00:00,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.011540174484253\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9959515333175659\n",
      "Epoch 181:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6581e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998012781143188\n",
      "Epoch 181:   9%|▉         | 1/11 [00:00<00:07,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.4350e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999127984046936\n",
      "Epoch 181:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2721e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999841570854187\n",
      "Epoch 181:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.0678e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997524619102478\n",
      "Epoch 181:  36%|███▋      | 4/11 [00:02<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0353e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998773336410522\n",
      "Epoch 181:  45%|████▌     | 5/11 [00:03<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2547e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998539090156555\n",
      "Epoch 181:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8721e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997866749763489\n",
      "Epoch 181:  64%|██████▎   | 7/11 [00:05<00:02,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9177e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997535347938538\n",
      "Epoch 181:  73%|███████▎  | 8/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8367e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995884895324707\n",
      "Epoch 181:  82%|████████▏ | 9/11 [00:06<00:01,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1124e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998700618743896\n",
      "Epoch 181:  91%|█████████ | 10/11 [00:07<00:00,  1.35it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.0388e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997749924659729\n",
      "Epoch 181: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1489, device='cuda:0')\n",
      "r2_score:  -1.0092835426330566\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.9936437606811523\n",
      "Epoch 182:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7532e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997913241386414\n",
      "Epoch 182:   9%|▉         | 1/11 [00:00<00:07,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.1925e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998931884765625\n",
      "Epoch 182:  18%|█▊        | 2/11 [00:01<00:06,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.0728e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998904466629028\n",
      "Epoch 182:  27%|██▋       | 3/11 [00:02<00:05,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5601e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998206496238708\n",
      "Epoch 182:  36%|███▋      | 4/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9146e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997572898864746\n",
      "Epoch 182:  45%|████▌     | 5/11 [00:03<00:04,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2359e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998446106910706\n",
      "Epoch 182:  55%|█████▍    | 6/11 [00:04<00:03,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.8374e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995774030685425\n",
      "Epoch 182:  64%|██████▎   | 7/11 [00:04<00:02,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.2823e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999078512191772\n",
      "Epoch 182:  73%|███████▎  | 8/11 [00:05<00:02,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.9103e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996986389160156\n",
      "Epoch 182:  82%|████████▏ | 9/11 [00:06<00:01,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.1193e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998946189880371\n",
      "Epoch 182:  91%|█████████ | 10/11 [00:07<00:00,  1.36it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(9.9271e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998805522918701\n",
      "Epoch 182: 100%|██████████| 11/11 [00:07<00:00,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.0128366947174072\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1368, device='cuda:0')\n",
      "r2_score:  -0.9994373321533203\n",
      "Epoch 183:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7571e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999809205532074\n",
      "Epoch 183:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4008e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995759725570679\n",
      "Epoch 183:  18%|█▊        | 2/11 [00:01<00:07,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2700e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998540878295898\n",
      "Epoch 183:  27%|██▋       | 3/11 [00:02<00:06,  1.27it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2273e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998654723167419\n",
      "Epoch 183:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6008e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998793601989746\n",
      "Epoch 183:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3463e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998286366462708\n",
      "Epoch 183:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9339e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999023675918579\n",
      "Epoch 183:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0868e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998744130134583\n",
      "Epoch 183:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5364e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999281764030457\n",
      "Epoch 183:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.4571e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999072551727295\n",
      "Epoch 183:  91%|█████████ | 10/11 [00:07<00:00,  1.35it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.4885e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9993487596511841\n",
      "Epoch 183: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.0110440254211426\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9950079917907715\n",
      "Epoch 184:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.1759e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999079704284668\n",
      "Epoch 184:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.6469e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999203085899353\n",
      "Epoch 184:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6365e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997915625572205\n",
      "Epoch 184:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4504e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996116757392883\n",
      "Epoch 184:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5506e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998229146003723\n",
      "Epoch 184:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3481e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998300075531006\n",
      "Epoch 184:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3131e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998442530632019\n",
      "Epoch 184:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1941e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998698234558105\n",
      "Epoch 184:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.5355e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999023079872131\n",
      "Epoch 184:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.9198e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997812509536743\n",
      "Epoch 184:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(9.8207e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998894333839417\n",
      "Epoch 184: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1489, device='cuda:0')\n",
      "r2_score:  -1.0101258754730225\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9966295957565308\n",
      "Epoch 185:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.1964e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999901294708252\n",
      "Epoch 185:   9%|▉         | 1/11 [00:00<00:07,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.3931e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999094605445862\n",
      "Epoch 185:  18%|█▊        | 2/11 [00:01<00:06,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.4572e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9995646476745605\n",
      "Epoch 185:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6533e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998936653137207\n",
      "Epoch 185:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.7988e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998997449874878\n",
      "Epoch 185:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6724e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997878074645996\n",
      "Epoch 185:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4073e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999294877052307\n",
      "Epoch 185:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1553e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997511506080627\n",
      "Epoch 185:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.6533e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999463558197021\n",
      "Epoch 185:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6604e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999682605266571\n",
      "Epoch 185:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(5.7662e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999302625656128\n",
      "Epoch 185: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1489, device='cuda:0')\n",
      "r2_score:  -1.0093979835510254\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9962621927261353\n",
      "Epoch 186:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.2996e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999129176139832\n",
      "Epoch 186:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3630e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998220801353455\n",
      "Epoch 186:  18%|█▊        | 2/11 [00:01<00:06,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9676e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999039769172668\n",
      "Epoch 186:  27%|██▋       | 3/11 [00:02<00:05,  1.40it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4381e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999226927757263\n",
      "Epoch 186:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1850e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996341466903687\n",
      "Epoch 186:  45%|████▌     | 5/11 [00:03<00:04,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4370e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998293519020081\n",
      "Epoch 186:  55%|█████▍    | 6/11 [00:04<00:03,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0707e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998814463615417\n",
      "Epoch 186:  64%|██████▎   | 7/11 [00:05<00:03,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7473e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998047351837158\n",
      "Epoch 186:  73%|███████▎  | 8/11 [00:06<00:02,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6131e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99990314245224\n",
      "Epoch 186:  82%|████████▏ | 9/11 [00:06<00:01,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6710e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998161792755127\n",
      "Epoch 186:  91%|█████████ | 10/11 [00:07<00:00,  1.34it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.3449e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999063611030579\n",
      "Epoch 186: 100%|██████████| 11/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.0111949443817139\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9947413206100464\n",
      "Epoch 187:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6489e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998188018798828\n",
      "Epoch 187:   9%|▉         | 1/11 [00:00<00:07,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2633e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998325705528259\n",
      "Epoch 187:  18%|█▊        | 2/11 [00:01<00:06,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7398e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997891783714294\n",
      "Epoch 187:  27%|██▋       | 3/11 [00:02<00:05,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4050e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999300241470337\n",
      "Epoch 187:  36%|███▋      | 4/11 [00:02<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.8416e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999405145645142\n",
      "Epoch 187:  45%|████▌     | 5/11 [00:03<00:04,  1.42it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0089e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999894917011261\n",
      "Epoch 187:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7538e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998007416725159\n",
      "Epoch 187:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9834e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999116659164429\n",
      "Epoch 187:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.3700e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998779892921448\n",
      "Epoch 187:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8509e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998920559883118\n",
      "Epoch 187:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(5.7303e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9992666244506836\n",
      "Epoch 187: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.012044906616211\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1367, device='cuda:0')\n",
      "r2_score:  -0.998381495475769\n",
      "Epoch 188:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5960e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998118877410889\n",
      "Epoch 188:   9%|▉         | 1/11 [00:00<00:07,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8269e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997392296791077\n",
      "Epoch 188:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7356e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999452233314514\n",
      "Epoch 188:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3996e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999344944953918\n",
      "Epoch 188:  36%|███▋      | 4/11 [00:02<00:04,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6679e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999192953109741\n",
      "Epoch 188:  45%|████▌     | 5/11 [00:03<00:04,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9844e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999525547027588\n",
      "Epoch 188:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3270e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999923586845398\n",
      "Epoch 188:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0041e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996219277381897\n",
      "Epoch 188:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1337e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997280836105347\n",
      "Epoch 188:  82%|████████▏ | 9/11 [00:06<00:01,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1247e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998689293861389\n",
      "Epoch 188:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(7.1079e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999293684959412\n",
      "Epoch 188: 100%|██████████| 11/11 [00:07<00:00,  1.46it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.011777639389038\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.9945088624954224\n",
      "Epoch 189:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.4734e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998831748962402\n",
      "Epoch 189:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0958e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998570680618286\n",
      "Epoch 189:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.7522e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996741414070129\n",
      "Epoch 189:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.8278e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997828602790833\n",
      "Epoch 189:  36%|███▋      | 4/11 [00:02<00:05,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.9097e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999091029167175\n",
      "Epoch 189:  45%|████▌     | 5/11 [00:03<00:04,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3331e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998459815979004\n",
      "Epoch 189:  55%|█████▍    | 6/11 [00:04<00:03,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2985e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998513460159302\n",
      "Epoch 189:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4870e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999355673789978\n",
      "Epoch 189:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.5821e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999329447746277\n",
      "Epoch 189:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0012e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998882412910461\n",
      "Epoch 189:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.4790e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999303221702576\n",
      "Epoch 189: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.0114240646362305\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9975194931030273\n",
      "Epoch 190:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4996e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998223781585693\n",
      "Epoch 190:   9%|▉         | 1/11 [00:00<00:09,  1.02it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3531e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998319149017334\n",
      "Epoch 190:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7063e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999469518661499\n",
      "Epoch 190:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4532e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999285936355591\n",
      "Epoch 190:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.4777e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998161792755127\n",
      "Epoch 190:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.4559e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999381303787231\n",
      "Epoch 190:  55%|█████▍    | 6/11 [00:04<00:03,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.8306e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999181032180786\n",
      "Epoch 190:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.0708e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996484518051147\n",
      "Epoch 190:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.0358e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999414682388306\n",
      "Epoch 190:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.0775e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999940037727356\n",
      "Epoch 190:  91%|█████████ | 10/11 [00:07<00:00,  1.33it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(8.0134e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999001026153564\n",
      "Epoch 190: 100%|██████████| 11/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.0119702816009521\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1365, device='cuda:0')\n",
      "r2_score:  -0.9960122108459473\n",
      "Epoch 191:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.6383e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999144673347473\n",
      "Epoch 191:   9%|▉         | 1/11 [00:00<00:09,  1.00it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1478e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999355673789978\n",
      "Epoch 191:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6595e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998119473457336\n",
      "Epoch 191:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.8486e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996609687805176\n",
      "Epoch 191:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.1563e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999925434589386\n",
      "Epoch 191:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.6979e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997975826263428\n",
      "Epoch 191:  55%|█████▍    | 6/11 [00:04<00:03,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.3224e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999479055404663\n",
      "Epoch 191:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0142e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998852610588074\n",
      "Epoch 191:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.5815e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999072551727295\n",
      "Epoch 191:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.2236e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999520182609558\n",
      "Epoch 191:  91%|█████████ | 10/11 [00:07<00:00,  1.36it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.7915e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999403953552246\n",
      "Epoch 191: 100%|██████████| 11/11 [00:08<00:00,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.010866641998291\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9961962699890137\n",
      "Epoch 192:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.7772e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998891353607178\n",
      "Epoch 192:   9%|▉         | 1/11 [00:00<00:09,  1.03it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7490e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997993111610413\n",
      "Epoch 192:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4763e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999254941940308\n",
      "Epoch 192:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8233e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999033808708191\n",
      "Epoch 192:  36%|███▋      | 4/11 [00:03<00:05,  1.29it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.4114e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999462366104126\n",
      "Epoch 192:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7123e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999440908432007\n",
      "Epoch 192:  55%|█████▍    | 6/11 [00:04<00:03,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4565e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.99992436170578\n",
      "Epoch 192:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7494e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999789297580719\n",
      "Epoch 192:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1639e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999513626098633\n",
      "Epoch 192:  82%|████████▏ | 9/11 [00:06<00:01,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.1445e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999276995658875\n",
      "Epoch 192:  91%|█████████ | 10/11 [00:07<00:00,  1.35it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.5137e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994667172431946\n",
      "Epoch 192: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.0125775337219238\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9962949752807617\n",
      "Epoch 193:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2718e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999419450759888\n",
      "Epoch 193:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0429e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998830556869507\n",
      "Epoch 193:  18%|█▊        | 2/11 [00:01<00:07,  1.15it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5404e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999261498451233\n",
      "Epoch 193:  27%|██▋       | 3/11 [00:02<00:06,  1.24it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2387e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998579025268555\n",
      "Epoch 193:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.6983e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999308586120605\n",
      "Epoch 193:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7697e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999923050403595\n",
      "Epoch 193:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3771e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999317526817322\n",
      "Epoch 193:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.5629e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999538660049438\n",
      "Epoch 193:  73%|███████▎  | 8/11 [00:05<00:02,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.8599e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999657928943634\n",
      "Epoch 193:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.7456e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999790370464325\n",
      "Epoch 193:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(3.4768e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999596476554871\n",
      "Epoch 193: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.0112130641937256\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9969251155853271\n",
      "Epoch 194:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2790e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999338984489441\n",
      "Epoch 194:   9%|▉         | 1/11 [00:00<00:06,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.5385e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999397397041321\n",
      "Epoch 194:  18%|█▊        | 2/11 [00:01<00:07,  1.17it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.6569e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999685287475586\n",
      "Epoch 194:  27%|██▋       | 3/11 [00:02<00:06,  1.25it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5067e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998123645782471\n",
      "Epoch 194:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2112e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998605251312256\n",
      "Epoch 194:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.5510e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999269247055054\n",
      "Epoch 194:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.3644e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998303651809692\n",
      "Epoch 194:  64%|██████▎   | 7/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.4826e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997169971466064\n",
      "Epoch 194:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.2146e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999198913574219\n",
      "Epoch 194:  82%|████████▏ | 9/11 [00:06<00:01,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.0368e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999541640281677\n",
      "Epoch 194:  91%|█████████ | 10/11 [00:07<00:00,  1.35it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(7.2871e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999184012413025\n",
      "Epoch 194: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.0125787258148193\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.994041919708252\n",
      "Epoch 195:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8577e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998886585235596\n",
      "Epoch 195:   9%|▉         | 1/11 [00:00<00:09,  1.05it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4992e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999236464500427\n",
      "Epoch 195:  18%|█▊        | 2/11 [00:01<00:07,  1.18it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.4719e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999281167984009\n",
      "Epoch 195:  27%|██▋       | 3/11 [00:02<00:06,  1.26it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5565e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998164772987366\n",
      "Epoch 195:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.9714e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999528527259827\n",
      "Epoch 195:  45%|████▌     | 5/11 [00:03<00:04,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.2292e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997159242630005\n",
      "Epoch 195:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.5423e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999464750289917\n",
      "Epoch 195:  64%|██████▎   | 7/11 [00:05<00:02,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9753e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999222755432129\n",
      "Epoch 195:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.3852e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999913215637207\n",
      "Epoch 195:  82%|████████▏ | 9/11 [00:06<00:01,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2419e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998487234115601\n",
      "Epoch 195:  91%|█████████ | 10/11 [00:07<00:00,  1.37it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.4968e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998435378074646\n",
      "Epoch 195: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1492, device='cuda:0')\n",
      "r2_score:  -1.0144190788269043\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1368, device='cuda:0')\n",
      "r2_score:  -0.9989895820617676\n",
      "Epoch 196:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.3789e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999325275421143\n",
      "Epoch 196:   9%|▉         | 1/11 [00:00<00:07,  1.43it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.0445e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999167323112488\n",
      "Epoch 196:  18%|█▊        | 2/11 [00:01<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.5847e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999563694000244\n",
      "Epoch 196:  27%|██▋       | 3/11 [00:02<00:05,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.6172e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999251961708069\n",
      "Epoch 196:  36%|███▋      | 4/11 [00:02<00:04,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2454e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999408721923828\n",
      "Epoch 196:  45%|████▌     | 5/11 [00:03<00:04,  1.32it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.5442e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998890161514282\n",
      "Epoch 196:  55%|█████▍    | 6/11 [00:04<00:03,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7561e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999213814735413\n",
      "Epoch 196:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2883e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998528361320496\n",
      "Epoch 196:  73%|███████▎  | 8/11 [00:05<00:02,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.7494e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9994960427284241\n",
      "Epoch 196:  82%|████████▏ | 9/11 [00:06<00:01,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(3.1619e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999613761901855\n",
      "Epoch 196:  91%|█████████ | 10/11 [00:07<00:00,  1.39it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(4.6244e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999406933784485\n",
      "Epoch 196: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1490, device='cuda:0')\n",
      "r2_score:  -1.0114400386810303\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1366, device='cuda:0')\n",
      "r2_score:  -0.9972748756408691\n",
      "Epoch 197:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(9.6906e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998924136161804\n",
      "Epoch 197:   9%|▉         | 1/11 [00:00<00:07,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.6072e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999058842658997\n",
      "Epoch 197:  18%|█▊        | 2/11 [00:01<00:06,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.1817e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997357130050659\n",
      "Epoch 197:  27%|██▋       | 3/11 [00:02<00:05,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.3398e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999381899833679\n",
      "Epoch 197:  36%|███▋      | 4/11 [00:03<00:05,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.0589e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999291896820068\n",
      "Epoch 197:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.1524e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999396800994873\n",
      "Epoch 197:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(7.6070e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999010562896729\n",
      "Epoch 197:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.0257e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999426007270813\n",
      "Epoch 197:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1169e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998635649681091\n",
      "Epoch 197:  82%|████████▏ | 9/11 [00:06<00:01,  1.34it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1128e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999484419822693\n",
      "Epoch 197:  91%|█████████ | 10/11 [00:07<00:00,  1.35it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(1.8632e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997923374176025\n",
      "Epoch 197: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.0128140449523926\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1364, device='cuda:0')\n",
      "r2_score:  -0.9944443702697754\n",
      "Epoch 198:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1924e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998628497123718\n",
      "Epoch 198:   9%|▉         | 1/11 [00:00<00:07,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5049e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9997013807296753\n",
      "Epoch 198:  18%|█▊        | 2/11 [00:01<00:06,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.9365e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999206066131592\n",
      "Epoch 198:  27%|██▋       | 3/11 [00:02<00:05,  1.38it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.6186e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999135136604309\n",
      "Epoch 198:  36%|███▋      | 4/11 [00:03<00:05,  1.28it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7491e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999240040779114\n",
      "Epoch 198:  45%|████▌     | 5/11 [00:03<00:04,  1.31it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.0658e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998802542686462\n",
      "Epoch 198:  55%|█████▍    | 6/11 [00:04<00:03,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(6.7007e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999202489852905\n",
      "Epoch 198:  64%|██████▎   | 7/11 [00:05<00:02,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.5608e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998248219490051\n",
      "Epoch 198:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.3116e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999459385871887\n",
      "Epoch 198:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7220e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999416470527649\n",
      "Epoch 198:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(6.7244e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999237656593323\n",
      "Epoch 198: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1491, device='cuda:0')\n",
      "r2_score:  -1.0127651691436768\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1367, device='cuda:0')\n",
      "r2_score:  -0.9985611438751221\n",
      "Epoch 199:   0%|          | 0/11 [00:00<?, ?it/s, v_num=16]         y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8258e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.999889612197876\n",
      "Epoch 199:   9%|▉         | 1/11 [00:00<00:06,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.2562e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999414682388306\n",
      "Epoch 199:  18%|█▊        | 2/11 [00:01<00:06,  1.41it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.1073e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998741745948792\n",
      "Epoch 199:  27%|██▋       | 3/11 [00:02<00:05,  1.39it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(5.6271e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999316334724426\n",
      "Epoch 199:  36%|███▋      | 4/11 [00:03<00:05,  1.30it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(1.2980e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998451471328735\n",
      "Epoch 199:  45%|████▌     | 5/11 [00:03<00:04,  1.33it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.7360e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999454617500305\n",
      "Epoch 199:  55%|█████▍    | 6/11 [00:04<00:03,  1.35it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(8.8623e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9998984336853027\n",
      "Epoch 199:  64%|██████▎   | 7/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.8328e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999405741691589\n",
      "Epoch 199:  73%|███████▎  | 8/11 [00:05<00:02,  1.36it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(4.1410e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999485015869141\n",
      "Epoch 199:  82%|████████▏ | 9/11 [00:06<00:01,  1.37it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(2.5324e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9996994733810425\n",
      "Epoch 199:  91%|█████████ | 10/11 [00:07<00:00,  1.38it/s, v_num=16]y.shape:  torch.Size([139, 1])\n",
      "y_hat.shape:  torch.Size([139, 1])\n",
      "loss:  tensor(2.5376e-06, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "r2_score:  0.9999721050262451\n",
      "Epoch 199: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, v_num=16]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1492, device='cuda:0')\n",
      "r2_score:  -1.013335943222046\n",
      "y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1368, device='cuda:0')\n",
      "r2_score:  -1.0004048347473145\n",
      "Epoch 199: 100%|██████████| 11/11 [00:08<00:00,  1.25it/s, v_num=16]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 11/11 [00:08<00:00,  1.25it/s, v_num=16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\jayor\\miniconda3\\envs\\synth-reconstruct\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model\n",
      "Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]y.shape:  torch.Size([256, 1])\n",
      "y_hat.shape:  torch.Size([256, 1])\n",
      "loss:  tensor(0.1492, device='cuda:0')\n",
      "r2_score:  -1.013335943222046\n",
      "Testing DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 21.30it/s]y.shape:  torch.Size([44, 1])\n",
      "y_hat.shape:  torch.Size([44, 1])\n",
      "loss:  tensor(0.1368, device='cuda:0')\n",
      "r2_score:  -1.0004048347473145\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 11.94it/s]\n"
     ]
    }
   ],
   "source": [
    "autoencoder_checkpoint = \"C:\\\\Users\\\\jayor\\\\Documents\\\\repos\\\\synth-reconstruct\\\\demo\\\\autoencoder\\\\saved_models\\\\audio_test\\\\final_model_dim_128\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=199-step=2200.ckpt\"\n",
    "num_classes = 1\n",
    "latent_dim = 128\n",
    "model_ld, result_ld = train_classifier(latent_dim, num_classes, max_epochs=200, encoder_model_checkpoint=autoencoder_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, preset_name):\n",
    "    # Put model in evaluation mode\n",
    "    model.to(device).eval()\n",
    "\n",
    "    image = torchvision.io.read_image(f'C:\\\\Users\\\\jayor\\\\Documents\\\\repos\\\\synth-reconstruct\\\\demo\\\\spectrograms_small\\\\{preset_name}.png')\n",
    "    image = image.float() / 255\n",
    "    # put on cuda\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "\n",
    "    print('image shape: ', image.shape)\n",
    "\n",
    "    # Make prediction\n",
    "    outputs = model(image)\n",
    "\n",
    "    true = pd.read_csv('../presets.csv')\n",
    "    # add column names\n",
    "    true.columns = ['preset'] + [f'param_{i}' for i in range(89)]\n",
    "    # Get the true values for the preset\n",
    "    true = true.loc[true['preset'] == preset_name].values[0][1:-1]\n",
    "    # convert eachv value to a float\n",
    "    true = [float(i) for i in true]\n",
    "    print('true: ', true)\n",
    "\n",
    "    # remove outputs dimension\n",
    "    \n",
    "    print('outputs: ', outputs)\n",
    "    outputs = outputs.squeeze().cpu().detach().numpy()\n",
    "    # Compare difference between true and predicted values\n",
    "    diff = numpy.subtract(true, outputs)\n",
    "    print('diff: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape:  torch.Size([1, 4, 128, 128])\n",
      "true:  [0.1128138127399065, 0.5200412343305395, 0.5048691076285318, 0.0098827374404064, 0.4772178795809715, 0.3488458046957011, 0.183505796322272, 0.3968369440561221, 0.6945592819389794, 0.9378262666849476, 0.6411993774368219, 0.5091637260096223, 0.1697929968357902, 0.9824074326248594, 0.0395036241251579, 0.542074222745996, 0.1334788097457471, 0.6815959430836447, 0.5460944800568336, 0.2981876381147958, 0.4996742123917477, 0.4040111580053628, 0.2657535266387455, 0.3810113867874748, 0.9467943466948706, 0.8345796400867546, 0.6186174672661281, 0.1138328860685606, 0.288204690520314, 0.5296385118662379, 0.1404540087475387, 0.3565403072834314, 0.4598743762441755, 0.8915992751517887, 0.405066379256584, 0.0039768757249234, 0.6975559617956802, 0.5242822477626187, 0.2416376932942164, 0.6048245719420646, 0.2560140778332006, 0.6419355024530109, 0.0380844677095567, 0.6717362138548425, 0.8425245601629546, 0.1023571953117167, 0.8196847660378422, 0.1055024568401072, 0.1385104500946979, 0.1948652709561426, 0.6219107363269863, 0.2352478111063053, 0.4687706152290036, 0.0153224911882089, 0.5829675610722876, 0.4647076719238115, 0.0135782366812172, 0.3649272893450538, 0.5005393053063596, 0.1834076206320888, 0.3995366236650095, 0.6973480127498931, 0.1457826062839496, 0.9966454524271958, 0.8750027186463544, 0.7171260121053862, 0.9114859759242184, 0.9386964923570282, 0.0966728437632671, 0.4133690173276103, 0.7063439681448845, 0.0755762309560894, 0.0988570441765144, 0.3618769222184634, 0.4116829698110327, 0.9606583416526044, 0.0895490524849732, 0.2699997767670847, 0.5626761249354777, 0.6621147647908799, 0.0244535458216597, 0.4346045425662926, 0.6525732501094379, 0.8742473199349984, 0.0073750196498799, 0.5262040044251731, 0.3890294014651541, 0.4555963565269478]\n",
      "outputs:  tensor([[0.1119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "diff:  [ 0.00089402  0.40812144  0.39294932 -0.10203705  0.36529809  0.23692601\n",
      "  0.07158601  0.28491715  0.58263949  0.82590648  0.52927959  0.39724394\n",
      "  0.05787321  0.87048764 -0.07241617  0.43015443  0.02155902  0.56967615\n",
      "  0.43417469  0.18626785  0.38775442  0.29209137  0.15383374  0.2690916\n",
      "  0.83487456  0.72265985  0.50669768  0.0019131   0.1762849   0.41771872\n",
      "  0.02853422  0.24462052  0.34795459  0.77967948  0.29314659 -0.10794291\n",
      "  0.58563617  0.41236246  0.1297179   0.49290478  0.14409429  0.53001571\n",
      " -0.07383532  0.55981642  0.73060477 -0.0095626   0.70776498 -0.00641733\n",
      "  0.02659066  0.08294548  0.50999095  0.12332802  0.35685082 -0.0965973\n",
      "  0.47104777  0.35278788 -0.09834155  0.2530075   0.38861951  0.07148783\n",
      "  0.28761683  0.58542822  0.03386282  0.88472566  0.76308293  0.60520622\n",
      "  0.79956619  0.8267767  -0.01524695  0.30144923  0.59442418 -0.03634356\n",
      " -0.01306275  0.24995713  0.29976318  0.84873855 -0.02237074  0.15807999\n",
      "  0.45075633  0.55019497 -0.08746624  0.32268475  0.54065346  0.76232753\n",
      " -0.10454477  0.41428421  0.27710961  0.34367657]\n"
     ]
    }
   ],
   "source": [
    "predict(model_ld, 'preset_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth-reconstruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
